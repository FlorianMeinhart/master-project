{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of different Parameters (Features: Section Means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T07:23:05.308931Z",
     "start_time": "2019-01-14T07:23:02.960797Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pivottablejs import pivot_ui\n",
    "import sys\n",
    "sys.path.append('..')  # in order to import modules from my own package\n",
    "\n",
    "# my package\n",
    "from packageMeinhart import PhysioDataHandler as PDH\n",
    "from packageMeinhart.functionsMasterProjectMeinhart import print_precision_recall_accuracy\n",
    "from packageMeinhart.functionsMasterProjectMeinhart import print_misclassified_data_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the class *PhysioData_SectionFeatures* for feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T07:23:05.333933Z",
     "start_time": "2019-01-14T07:23:05.311932Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class PhysioData_SectionFeatures in module packageMeinhart.PhysioDataHandler:\n",
      "\n",
      "class PhysioData_SectionFeatures(builtins.object)\n",
      " |  Class for feature generation using section means.\n",
      " |  There are various selectable options --> see Parameters. \n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  num_sections : int\n",
      " |      Number of equally partitioned sections to split the single repetitions of the signals.\n",
      " |      \n",
      " |  test_subject_ids : int or list (of int)\n",
      " |      Subject IDs to select for testing (e.g. [1, 2, 3]).\n",
      " |      --> default -1: Select all subjects.\n",
      " |      --> if test_subject_ids is an empty list: empty DataFrame is returned by corresponding method.\n",
      " |      \n",
      " |  train_subject_ids : int or list\n",
      " |      Subject IDs to select for training (e.g. [1, 2, 3]).\n",
      " |      --> default -1: Select all subjects not in test_subject_ids.\n",
      " |      --> if train_subject_ids is an empty list: empty DataFrame is returned by corresponding method.\n",
      " |      \n",
      " |  test_rep_nums : int or list\n",
      " |      Repetition numbers to select for testing (e.g. [5, 10]).\n",
      " |      --> default -1: Select all repetitions.\n",
      " |      \n",
      " |  train_rep_nums : int or list\n",
      " |      Repetition numbers to select for training (e.g. [5, 10]).\n",
      " |      --> default -1: Select all repetitions.\n",
      " |      \n",
      " |  test_ex_abbrs : int or list\n",
      " |      Exercise abbreviations to select for testing (e.g. ['RF', 'SA']).\n",
      " |      --> default -1: Select all exercise abbreviations.\n",
      " |      \n",
      " |  train_ex_abbrs : int or list\n",
      " |      Exercise abbreviations to select for training (e.g. ['RF', 'SA']).\n",
      " |      --> default -1: Select all exercise abbreviations.\n",
      " |  \n",
      " |  with_non_Ex : boolean\n",
      " |      If False --> omit non exercise data (data points with zero repetitions).\n",
      " |      \n",
      " |  rot_axis_test_data : int or list of int\n",
      " |      Axis (axes) for rotation:\n",
      " |      0, 1 or 2 --> x, y or z\n",
      " |      --> if list: sequence of rotations\n",
      " |      (Length of list has to match with the length of rot_angle,\n",
      " |      otherwise the shorter list of the two is taken and all other values are omitted.)\n",
      " |      \n",
      " |  rot_angle_test_data : int or float or list of int or float\n",
      " |      Rotation angle(s) in degree.\n",
      " |      --> if list: sequence of rotations\n",
      " |      (Length of list has to match with the length of rot_axis,\n",
      " |      otherwise the shorter list of the two is taken and all other values are omitted.)\n",
      " |  \n",
      " |  add_noise_test_data : boolean\n",
      " |      If True --> Additive White Gaussian Noise (AWGN) is added to signals of data for testing.\n",
      " |  \n",
      " |  snr_db : int or float\n",
      " |      Desired signal to noise ratio in db for the generated noisy test signals.\n",
      " |  \n",
      " |  csv_data_dir : string\n",
      " |      Directory of signal data csv-files.\n",
      " |      \n",
      " |  csv_skiprows : int\n",
      " |      Number of rows to skip for signal data csv-files.\n",
      " |      \n",
      " |  csv_separator : string\n",
      " |      Separator for signal data csv-files.\n",
      " |  \n",
      " |  data_base_path : string\n",
      " |      Path to data base (containing at least the following):\n",
      " |          - subject IDs\n",
      " |          - exercise abbreviations\n",
      " |          - number of repetitions\n",
      " |          - sequence numbers\n",
      " |          - start times\n",
      " |          - stop times\n",
      " |          - csv-file name\n",
      " |      \n",
      " |  print_progress : boolean\n",
      " |      If True --> print progress at feature generation.\n",
      " |  \n",
      " |  signal_abbrs : list of strings\n",
      " |      Abbreviations of the signals (e.g. ['Acc','Gyr']).\n",
      " |  \n",
      " |  signal_orientations : list of strings\n",
      " |      Orientations of the signals (e.g. ['x','y','z']).\n",
      " |      \n",
      " |  labels_abbr2num_dict : dict\n",
      " |      Dictionary to convert exercise abbreviations to number (e.g. ={'RF':0,'RO':1,'RS':2, ... }).\n",
      " |  \n",
      " |  sub_id_key : string\n",
      " |      Key of the DataFrame for subject IDs.\n",
      " |      \n",
      " |  num_rep_key : string\n",
      " |      Key of the DataFrame for repetition numbers.\n",
      " |      \n",
      " |  abbreviation_key : string\n",
      " |      Key of the DataFrame for exercise abbreviations.\n",
      " |      \n",
      " |  start_time_key : strings\n",
      " |      Start time key for DataFrame which contains data base entries.\n",
      " |      \n",
      " |  stop_time_key : strings\n",
      " |      Stop time key for DataFrame which contains data base entries.\n",
      " |      \n",
      " |  csv_file_key : strings\n",
      " |      csv-file key for DataFrame which contains data base entries.\n",
      " |      \n",
      " |  sampling_rate : int or float\n",
      " |      Sampling rate of the signals in Hz.\n",
      " |      \n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  X_test_df : DataFrame\n",
      " |      Features for testing.\n",
      " |  \n",
      " |  y_test_df : DataFrame\n",
      " |      Labels for testing.\n",
      " |  \n",
      " |  X_train_df : DataFrame\n",
      " |      Features for training.\n",
      " |  \n",
      " |  y_train_df : DataFrame\n",
      " |      Labels for testing.\n",
      " |  \n",
      " |  \n",
      " |  test_data_points_df : DataFrame\n",
      " |      Data points for testing from data base.\n",
      " |  \n",
      " |  train_data_points_df : DataFrame\n",
      " |      Data points for training from data base.\n",
      " |  \n",
      " |  all_data_points_df : DataFrame\n",
      " |      All data points from data base.\n",
      " |  \n",
      " |  \n",
      " |  Methods\n",
      " |  -------\n",
      " |  get_X_test_df()\n",
      " |      Returns features for testing as DataFrame.\n",
      " |  \n",
      " |  get_y_test_df() :\n",
      " |      Returns labels for testing as DataFrame.\n",
      " |  \n",
      " |  get_X_train_df() :\n",
      " |      Returns features for training as DataFrame.\n",
      " |  \n",
      " |  get_y_train_df() :\n",
      " |      Returns labels for testing as DataFrame.\n",
      " |  \n",
      " |  \n",
      " |  X_test():\n",
      " |      Returns feature matrix for testing as np.array.\n",
      " |  \n",
      " |  y_test():\n",
      " |      Returns numeric labels for testing as np.array.\n",
      " |  \n",
      " |  X_train():\n",
      " |      Returns feature matrix for training as np.array.\n",
      " |  \n",
      " |  y_train():\n",
      " |      Returns numeric labels for training as np.array.\n",
      " |  \n",
      " |  \n",
      " |  get_test_data_points()\n",
      " |      Returns data points for testing from data base as DataFrame.\n",
      " |  \n",
      " |  get_train_data_points()\n",
      " |      Returns data points for training from data base as DataFrame.\n",
      " |  \n",
      " |  get_all_data_points()\n",
      " |      Returns all data points from data base as DataFrame.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  X_test(self)\n",
      " |      # methods to get feature values only\n",
      " |  \n",
      " |  X_train(self)\n",
      " |  \n",
      " |  __init__(self, num_sections=10, test_subject_ids=-1, train_subject_ids=-1, test_rep_nums=-1, train_rep_nums=-1, test_ex_abbrs=-1, train_ex_abbrs=-1, with_non_Ex=True, rot_axis_test_data=0, rot_angle_test_data=0, add_noise_test_data=False, add_noise_train_data=False, snr_db=20, csv_data_dir='E:\\\\Physio_Data_Split_Ex_and_NonEx', csv_skiprows=0, csv_separator=',', data_base_path='E:\\\\Physio_Data\\\\DataBase_Physio_with_nonEx.db', print_progress=True, signal_abbrs=['Acc', 'Gyr'], signal_orientations=['x', 'y', 'z'], labels_abbr2num_dict={'RF': 0, 'RO': 1, 'RS': 2, 'LR': 3, 'BC': 4, 'TC': 5, 'MP': 6, 'SA': 7, 'P1': 8, 'P2': 9, 'NE': 10}, sub_id_key='subject_id', num_rep_key='num_rep', abbreviation_key='abbreviation', start_time_key='start_time', stop_time_key='stop_time', csv_file_key='csv_file', sampling_rate=256)\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      --> See class docstring.\n",
      " |  \n",
      " |  get_X_test_df(self)\n",
      " |      # methods to get features\n",
      " |  \n",
      " |  get_X_train_df(self)\n",
      " |  \n",
      " |  get_all_data_points(self)\n",
      " |  \n",
      " |  get_test_data_points(self)\n",
      " |      # methods to get data points (DataFrames)\n",
      " |  \n",
      " |  get_train_data_points(self)\n",
      " |  \n",
      " |  get_y_test_df(self)\n",
      " |  \n",
      " |  get_y_train_df(self)\n",
      " |  \n",
      " |  y_test(self)\n",
      " |  \n",
      " |  y_train(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(PDH.PhysioData_SectionFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create instance of physio data class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T07:24:00.294076Z",
     "start_time": "2019-01-14T07:23:05.339933Z"
    }
   },
   "outputs": [],
   "source": [
    "PD1 = PDH.PhysioData_SectionFeatures(num_sections=10,\n",
    "                                     test_subject_ids=1,\n",
    "                                     train_subject_ids=-1,\n",
    "                                     test_rep_nums=-1,\n",
    "                                     train_rep_nums=-1,\n",
    "                                     test_ex_abbrs=-1,\n",
    "                                     train_ex_abbrs=-1,\n",
    "                                     with_non_Ex=True,\n",
    "                                     rot_axis_test_data=0,\n",
    "                                     rot_angle_test_data=0,\n",
    "                                     add_noise_test_data=False,\n",
    "                                     add_noise_train_data=False,\n",
    "                                     snr_db=20,\n",
    "                                     csv_data_dir='E:\\Physio_Data_Split_Ex_and_NonEx',\n",
    "                                     csv_skiprows=0,\n",
    "                                     csv_separator=',',\n",
    "                                     data_base_path='E:\\Physio_Data\\DataBase_Physio_with_nonEx.db',\n",
    "                                     print_progress=True,\n",
    "                                     signal_abbrs=['Acc','Gyr'],\n",
    "                                     signal_orientations=['x','y','z'],\n",
    "                                     labels_abbr2num_dict={'RF':0,'RO':1,'RS':2,'LR':3,'BC':4,'TC':5,\n",
    "                                                           'MP':6,'SA':7,'P1':8,'P2':9,'NE':10},\n",
    "                                     sub_id_key='subject_id',\n",
    "                                     num_rep_key='num_rep',\n",
    "                                     abbreviation_key='abbreviation',\n",
    "                                     start_time_key='start_time',\n",
    "                                     stop_time_key='stop_time',\n",
    "                                     csv_file_key='csv_file',\n",
    "                                     sampling_rate=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting selected data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T07:24:00.335079Z",
     "start_time": "2019-01-14T07:24:00.299077Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500\"\n",
       "            src=\"PD1_test.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1ac84c88>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_ui(PD1.get_test_data_points(), \n",
    "         rows=['abbreviation'], \n",
    "         cols=['subject_id', 'num_rep'], \n",
    "         outfile_path=\"PD1_test.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting selected data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T07:24:00.591093Z",
     "start_time": "2019-01-14T07:24:00.342079Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500\"\n",
       "            src=\"PD1_train.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1bb77320>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_ui(PD1.get_train_data_points(), \n",
    "         rows=['abbreviation'], \n",
    "         cols=['subject_id', 'num_rep'], \n",
    "         outfile_path=\"PD1_train.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification (ML part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T07:24:05.627381Z",
     "start_time": "2019-01-14T07:24:00.603094Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "# StandardScaler raises the following warning:\n",
    "# --> DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
    "# if we want to ignore that:\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try it with different ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T07:24:06.859452Z",
     "start_time": "2019-01-14T07:24:05.631382Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestClassifier\n",
      "\n",
      "Total Accuracy: 98.87%\n",
      "\n",
      "Exercise\tPrecision [%]\tRecall [%]\tAccuracy [%]\n",
      "  RF\t\t  100.00\t   93.33\t   99.72\n",
      "  RO\t\t   93.75\t  100.00\t   99.72\n",
      "  RS\t\t  100.00\t  100.00\t  100.00\n",
      "  LR\t\t  100.00\t  100.00\t  100.00\n",
      "  BC\t\t  100.00\t  100.00\t  100.00\n",
      "  TC\t\t  100.00\t  100.00\t  100.00\n",
      "  MP\t\t   85.71\t  100.00\t   99.29\n",
      "  SA\t\t  100.00\t  100.00\t  100.00\n",
      "  P1\t\t  100.00\t   96.67\t   99.86\n",
      "  P2\t\t  100.00\t  100.00\t  100.00\n",
      "  NE\t\t   99.75\t   98.77\t   99.15\n",
      "\n",
      "8 misclassified (709 test data points):\n",
      "RF classified as RO\n",
      "RF classified as RO\n",
      "P1 classified as NE\n",
      "NE classified as MP\n",
      "NE classified as MP\n",
      "NE classified as MP\n",
      "NE classified as MP\n",
      "NE classified as MP\n"
     ]
    }
   ],
   "source": [
    "# create ML model\n",
    "ML_model = RandomForestClassifier(n_estimators=50, max_leaf_nodes=40, n_jobs=-1, random_state=42)\n",
    "#ML_model = make_pipeline(StandardScaler(), SVC(random_state=42)) # Support Vector Classifier with input scaling\n",
    "\n",
    "# train the model\n",
    "ML_model.fit(PD1.X_train(), PD1.y_train())\n",
    "\n",
    "# predict labels\n",
    "y_pred = ML_model.predict(PD1.X_test())\n",
    "\n",
    "# show results\n",
    "print('Model: ' + type(ML_model).__name__ + '\\n')\n",
    "print('Total Accuracy: {:.2f}%\\n'.format((accuracy_score(PD1.y_test(), y_pred))*100))\n",
    "print_precision_recall_accuracy(y_pred, PD1.y_test())\n",
    "print('')\n",
    "print_misclassified_data_points(y_pred, PD1.y_test())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search and Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T07:44:59.109140Z",
     "start_time": "2019-01-11T07:44:59.090139Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "pipe_elements = [('scale', StandardScaler()), ('clf', SVC())]\n",
    "#pipe_elements = [('scale', StandardScaler()), ('reduce_dim', PCA()), ('clf', SVC())]\n",
    "pipe = Pipeline(pipe_elements)\n",
    "\n",
    "param_grid = {'clf__C': [0.1, 1, 10],\n",
    "              'clf__gamma': ['scale', 0.01, 0.1]}\n",
    "\n",
    "# include PCA\n",
    "#param_grid = {'reduce_dim__n_components': [10, 20, 30],\n",
    "#              'clf__C': [1, 10, 100],\n",
    "#              'clf__gamma': [1, 10, 100]}\n",
    "\n",
    "# C: Penalty parameter C of the error term. (Regularisation parameter)\n",
    "# gamma: Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’. (Bandwidth of kernel)\n",
    "\n",
    "# splitting strategy for grid search: stratified CV with 5 folds\n",
    "grid_search = GridSearchCV(pipe, \n",
    "                           param_grid=param_grid, \n",
    "                           cv=5, scoring='accuracy', \n",
    "                           verbose=10, \n",
    "                           n_jobs=-1, \n",
    "                           return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T07:46:18.240666Z",
     "start_time": "2019-01-11T07:44:59.112140Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   32.6s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   36.0s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   53.0s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  45 | elapsed:  1.1min remaining:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('scale', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'clf__C': [0.1, 1, 10], 'clf__gamma': ['scale', 0.01, 0.1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply grid search and cross validation\n",
    "grid_search.fit(PD1.X_train(), PD1.y_train())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T07:46:18.360673Z",
     "start_time": "2019-01-11T07:46:18.244666Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.73%\n"
     ]
    }
   ],
   "source": [
    "# show score (test data)\n",
    "print('Accuracy: {:.2f}%'.format(grid_search.score(PD1.X_test(), PD1.y_test())*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T07:46:18.446678Z",
     "start_time": "2019-01-11T07:46:18.365673Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'clf__C': 1, 'clf__gamma': 'scale'}\n"
     ]
    }
   ],
   "source": [
    "# show best parameters\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T07:46:18.575685Z",
     "start_time": "2019-01-11T07:46:18.455678Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score at cross validatoin: 98.95%\n"
     ]
    }
   ],
   "source": [
    "# show best score of cross validation\n",
    "print('Best score at cross validatoin: {:.2f}%'.format(grid_search.best_score_*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T07:46:18.708693Z",
     "start_time": "2019-01-11T07:46:18.580685Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scale', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n"
     ]
    }
   ],
   "source": [
    "# show best estimator\n",
    "print('Best estimator: {}'.format(grid_search.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T07:46:18.897703Z",
     "start_time": "2019-01-11T07:46:18.714693Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_clf__C</th>\n",
       "      <th>param_clf__gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.849506</td>\n",
       "      <td>0.466027</td>\n",
       "      <td>0.977288</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.1</td>\n",
       "      <td>scale</td>\n",
       "      <td>{'clf__C': 0.1, 'clf__gamma': 'scale'}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.978013</td>\n",
       "      <td>0.981603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.982829</td>\n",
       "      <td>0.978763</td>\n",
       "      <td>0.971358</td>\n",
       "      <td>0.976929</td>\n",
       "      <td>0.985246</td>\n",
       "      <td>0.978776</td>\n",
       "      <td>0.092449</td>\n",
       "      <td>0.024683</td>\n",
       "      <td>0.006289</td>\n",
       "      <td>0.001524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.956912</td>\n",
       "      <td>0.724841</td>\n",
       "      <td>0.955392</td>\n",
       "      <td>0.957676</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'clf__C': 0.1, 'clf__gamma': 0.01}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.945440</td>\n",
       "      <td>0.956051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.953393</td>\n",
       "      <td>0.960588</td>\n",
       "      <td>0.943535</td>\n",
       "      <td>0.947121</td>\n",
       "      <td>0.986885</td>\n",
       "      <td>0.975714</td>\n",
       "      <td>0.278778</td>\n",
       "      <td>0.256786</td>\n",
       "      <td>0.016059</td>\n",
       "      <td>0.010245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.369793</td>\n",
       "      <td>0.678239</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.934069</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'clf__C': 0.1, 'clf__gamma': 0.1}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.909609</td>\n",
       "      <td>0.933974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.921504</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.930176</td>\n",
       "      <td>0.876230</td>\n",
       "      <td>0.936939</td>\n",
       "      <td>0.559981</td>\n",
       "      <td>0.021199</td>\n",
       "      <td>0.015592</td>\n",
       "      <td>0.002675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.672039</td>\n",
       "      <td>0.191011</td>\n",
       "      <td>0.989542</td>\n",
       "      <td>0.991748</td>\n",
       "      <td>1</td>\n",
       "      <td>scale</td>\n",
       "      <td>{'clf__C': 1, 'clf__gamma': 'scale'}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.985342</td>\n",
       "      <td>0.992845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995094</td>\n",
       "      <td>0.990811</td>\n",
       "      <td>0.988543</td>\n",
       "      <td>0.991833</td>\n",
       "      <td>0.988525</td>\n",
       "      <td>0.992449</td>\n",
       "      <td>0.080828</td>\n",
       "      <td>0.012602</td>\n",
       "      <td>0.003193</td>\n",
       "      <td>0.000834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.503829</td>\n",
       "      <td>0.168010</td>\n",
       "      <td>0.987908</td>\n",
       "      <td>0.990849</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'clf__C': 1, 'clf__gamma': 0.01}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.984528</td>\n",
       "      <td>0.991619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.994276</td>\n",
       "      <td>0.990402</td>\n",
       "      <td>0.985270</td>\n",
       "      <td>0.991017</td>\n",
       "      <td>0.988525</td>\n",
       "      <td>0.991837</td>\n",
       "      <td>0.029480</td>\n",
       "      <td>0.006293</td>\n",
       "      <td>0.003470</td>\n",
       "      <td>0.000892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.578405</td>\n",
       "      <td>0.489828</td>\n",
       "      <td>0.965523</td>\n",
       "      <td>0.995180</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'clf__C': 1, 'clf__gamma': 0.1}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.967427</td>\n",
       "      <td>0.996934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973017</td>\n",
       "      <td>0.994895</td>\n",
       "      <td>0.970540</td>\n",
       "      <td>0.994079</td>\n",
       "      <td>0.945082</td>\n",
       "      <td>0.995306</td>\n",
       "      <td>0.429613</td>\n",
       "      <td>0.027171</td>\n",
       "      <td>0.010362</td>\n",
       "      <td>0.000962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.660238</td>\n",
       "      <td>0.160809</td>\n",
       "      <td>0.987092</td>\n",
       "      <td>0.994567</td>\n",
       "      <td>10</td>\n",
       "      <td>scale</td>\n",
       "      <td>{'clf__C': 10, 'clf__gamma': 'scale'}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.986971</td>\n",
       "      <td>0.995707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988553</td>\n",
       "      <td>0.994282</td>\n",
       "      <td>0.987725</td>\n",
       "      <td>0.993671</td>\n",
       "      <td>0.979508</td>\n",
       "      <td>0.995306</td>\n",
       "      <td>0.079750</td>\n",
       "      <td>0.012140</td>\n",
       "      <td>0.004266</td>\n",
       "      <td>0.000802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.441025</td>\n",
       "      <td>0.116407</td>\n",
       "      <td>0.988072</td>\n",
       "      <td>0.993750</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'clf__C': 10, 'clf__gamma': 0.01}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.988599</td>\n",
       "      <td>0.994890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987735</td>\n",
       "      <td>0.992649</td>\n",
       "      <td>0.988543</td>\n",
       "      <td>0.993467</td>\n",
       "      <td>0.982787</td>\n",
       "      <td>0.994898</td>\n",
       "      <td>0.015850</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.000972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.438597</td>\n",
       "      <td>0.471627</td>\n",
       "      <td>0.961765</td>\n",
       "      <td>0.999591</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'clf__C': 10, 'clf__gamma': 0.1}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.963355</td>\n",
       "      <td>0.999387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968903</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.938525</td>\n",
       "      <td>0.999184</td>\n",
       "      <td>0.484676</td>\n",
       "      <td>0.109767</td>\n",
       "      <td>0.011846</td>\n",
       "      <td>0.000342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       1.849506         0.466027         0.977288          0.979167   \n",
       "1       1.956912         0.724841         0.955392          0.957676   \n",
       "2      10.369793         0.678239         0.901961          0.934069   \n",
       "3       0.672039         0.191011         0.989542          0.991748   \n",
       "4       0.503829         0.168010         0.987908          0.990849   \n",
       "5      10.578405         0.489828         0.965523          0.995180   \n",
       "6       0.660238         0.160809         0.987092          0.994567   \n",
       "7       0.441025         0.116407         0.988072          0.993750   \n",
       "8      10.438597         0.471627         0.961765          0.999591   \n",
       "\n",
       "  param_clf__C param_clf__gamma                                  params  \\\n",
       "0          0.1            scale  {'clf__C': 0.1, 'clf__gamma': 'scale'}   \n",
       "1          0.1             0.01     {'clf__C': 0.1, 'clf__gamma': 0.01}   \n",
       "2          0.1              0.1      {'clf__C': 0.1, 'clf__gamma': 0.1}   \n",
       "3            1            scale    {'clf__C': 1, 'clf__gamma': 'scale'}   \n",
       "4            1             0.01       {'clf__C': 1, 'clf__gamma': 0.01}   \n",
       "5            1              0.1        {'clf__C': 1, 'clf__gamma': 0.1}   \n",
       "6           10            scale   {'clf__C': 10, 'clf__gamma': 'scale'}   \n",
       "7           10             0.01      {'clf__C': 10, 'clf__gamma': 0.01}   \n",
       "8           10              0.1       {'clf__C': 10, 'clf__gamma': 0.1}   \n",
       "\n",
       "   rank_test_score  split0_test_score  split0_train_score       ...         \\\n",
       "0                5           0.978013            0.981603       ...          \n",
       "1                8           0.945440            0.956051       ...          \n",
       "2                9           0.909609            0.933974       ...          \n",
       "3                1           0.985342            0.992845       ...          \n",
       "4                3           0.984528            0.991619       ...          \n",
       "5                6           0.967427            0.996934       ...          \n",
       "6                4           0.986971            0.995707       ...          \n",
       "7                2           0.988599            0.994890       ...          \n",
       "8                7           0.963355            0.999387       ...          \n",
       "\n",
       "   split2_test_score  split2_train_score  split3_test_score  \\\n",
       "0           0.982829            0.978763           0.971358   \n",
       "1           0.953393            0.960588           0.943535   \n",
       "2           0.921504            0.932203           0.893617   \n",
       "3           0.995094            0.990811           0.988543   \n",
       "4           0.994276            0.990402           0.985270   \n",
       "5           0.973017            0.994895           0.970540   \n",
       "6           0.988553            0.994282           0.987725   \n",
       "7           0.987735            0.992649           0.988543   \n",
       "8           0.967294            1.000000           0.968903   \n",
       "\n",
       "   split3_train_score  split4_test_score  split4_train_score  std_fit_time  \\\n",
       "0            0.976929           0.985246            0.978776      0.092449   \n",
       "1            0.947121           0.986885            0.975714      0.278778   \n",
       "2            0.930176           0.876230            0.936939      0.559981   \n",
       "3            0.991833           0.988525            0.992449      0.080828   \n",
       "4            0.991017           0.988525            0.991837      0.029480   \n",
       "5            0.994079           0.945082            0.995306      0.429613   \n",
       "6            0.993671           0.979508            0.995306      0.079750   \n",
       "7            0.993467           0.982787            0.994898      0.015850   \n",
       "8            1.000000           0.938525            0.999184      0.484676   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.024683        0.006289         0.001524  \n",
       "1        0.256786        0.016059         0.010245  \n",
       "2        0.021199        0.015592         0.002675  \n",
       "3        0.012602        0.003193         0.000834  \n",
       "4        0.006293        0.003470         0.000892  \n",
       "5        0.027171        0.010362         0.000962  \n",
       "6        0.012140        0.004266         0.000802  \n",
       "7        0.002728        0.003150         0.000972  \n",
       "8        0.109767        0.011846         0.000342  \n",
       "\n",
       "[9 rows x 22 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_results = pd.DataFrame(grid_search.cv_results_)\n",
    "grid_search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters and evaluate directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T07:37:38.477874Z",
     "start_time": "2019-01-14T07:37:35.414699Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestClassifier\n",
      "\n",
      "Total Accuracy: 95.00%\n",
      "\n",
      "Exercise\tPrecision [%]\tRecall [%]\tAccuracy [%]\n",
      "  RF\t\t  100.00\t   80.00\t   95.00\n",
      "  RO\t\t   83.33\t  100.00\t   95.00\n",
      "  RS\t\t  100.00\t  100.00\t  100.00\n",
      "  LR\t\t  100.00\t  100.00\t  100.00\n",
      "  BC\t\t     nan\t     nan\t  100.00\n",
      "  TC\t\t     nan\t     nan\t  100.00\n",
      "  MP\t\t     nan\t     nan\t  100.00\n",
      "  SA\t\t     nan\t     nan\t  100.00\n",
      "  P1\t\t     nan\t     nan\t  100.00\n",
      "  P2\t\t     nan\t     nan\t  100.00\n",
      "  NE\t\t     nan\t     nan\t  100.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\packageMeinhart\\functionsMasterProjectMeinhart.py:895: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = TP / (TP+FP)\n",
      "..\\packageMeinhart\\functionsMasterProjectMeinhart.py:896: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  recall = TP / (TP+FN)\n",
      "E:\\Programme\\WinPython-64bit-3.6.2.0Qt5\\python-3.6.2.amd64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "E:\\Programme\\WinPython-64bit-3.6.2.0Qt5\\python-3.6.2.amd64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BC</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MP</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NE</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RO</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SA</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TC</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.348485</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>0.345271</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.949495</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score  support\n",
       "BC             0.000000  0.000000  0.000000        0\n",
       "LR             1.000000  1.000000  1.000000       30\n",
       "MP             0.000000  0.000000  0.000000        0\n",
       "NE             0.000000  0.000000  0.000000        0\n",
       "P1             0.000000  0.000000  0.000000        0\n",
       "P2             0.000000  0.000000  0.000000        0\n",
       "RF             1.000000  0.800000  0.888889       30\n",
       "RO             0.833333  1.000000  0.909091       30\n",
       "RS             1.000000  1.000000  1.000000       30\n",
       "SA             0.000000  0.000000  0.000000        0\n",
       "TC             0.000000  0.000000  0.000000        0\n",
       "macro avg      0.348485  0.345455  0.345271      120\n",
       "micro avg      0.950000  0.950000  0.950000      120\n",
       "weighted avg   0.958333  0.950000  0.949495      120"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6 misclassified (120 test data points):\n",
      "RF classified as RO\n",
      "RF classified as RO\n",
      "RF classified as RO\n",
      "RF classified as RO\n",
      "RF classified as RO\n",
      "RF classified as RO\n"
     ]
    }
   ],
   "source": [
    "PD2 = PDH.PhysioData_SectionFeatures(num_sections=10,\n",
    "                                     test_subject_ids=1,\n",
    "                                     train_subject_ids=[2,3],\n",
    "                                     test_rep_nums=-1,\n",
    "                                     train_rep_nums=[10, 15],\n",
    "                                     test_ex_abbrs=['RF','RO','RS','LR'],\n",
    "                                     train_ex_abbrs=['RF','RO','RS','LR'],\n",
    "                                     with_non_Ex=True,\n",
    "                                     rot_axis_test_data=[0,1],\n",
    "                                     rot_angle_test_data=[10,5],\n",
    "                                     add_noise_test_data=True,\n",
    "                                     add_noise_train_data=False,\n",
    "                                     snr_db=20)\n",
    "\n",
    "# create ML model\n",
    "ML_model = RandomForestClassifier(n_estimators=50, max_leaf_nodes=40, n_jobs=-1, random_state=42)\n",
    "#ML_model = make_pipeline(StandardScaler(), SVC(random_state=42)) # Support Vector Classifier with input scaling\n",
    "\n",
    "# train the model\n",
    "ML_model.fit(PD2.X_train(), PD2.y_train())\n",
    "\n",
    "# predict labels\n",
    "y_pred = ML_model.predict(PD2.X_test())\n",
    "\n",
    "# show results\n",
    "print('Model: ' + type(ML_model).__name__ + '\\n')\n",
    "\n",
    "print('Total Accuracy: {:.2f}%\\n'.format((accuracy_score(PD2.y_test(), y_pred))*100))\n",
    "print_precision_recall_accuracy(y_pred, PD2.y_test())\n",
    "\n",
    "report = classification_report(PD2.y_test(), y_pred, \n",
    "                               labels=np.arange(0,11),\n",
    "                               target_names=['RF','RO','RS','LR','BC','TC','MP','SA','P1','P2','NE'],\n",
    "                               sample_weight=None, output_dict=True)\n",
    "\n",
    "report_df = pd.DataFrame.from_dict(report, orient='index')\n",
    "display(report_df)\n",
    "\n",
    "print('')\n",
    "print_misclassified_data_points(y_pred, PD2.y_test())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T07:25:02.496634Z",
     "start_time": "2019-01-14T07:25:02.465632Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programme\\WinPython-64bit-3.6.2.0Qt5\\python-3.6.2.amd64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BC</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MP</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NE</th>\n",
       "      <td>0.983010</td>\n",
       "      <td>0.995086</td>\n",
       "      <td>0.989011</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RO</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SA</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TC</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.881572</td>\n",
       "      <td>0.872281</td>\n",
       "      <td>0.870213</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.980306</td>\n",
       "      <td>0.980306</td>\n",
       "      <td>0.980306</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.970802</td>\n",
       "      <td>0.980306</td>\n",
       "      <td>0.974714</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score  support\n",
       "BC             1.000000  1.000000  1.000000        5\n",
       "LR             0.000000  0.000000  0.000000        5\n",
       "MP             0.714286  1.000000  0.833333        5\n",
       "NE             0.983010  0.995086  0.989011      407\n",
       "P1             1.000000  1.000000  1.000000        5\n",
       "P2             1.000000  1.000000  1.000000        5\n",
       "RF             1.000000  1.000000  1.000000        5\n",
       "RO             1.000000  0.600000  0.750000        5\n",
       "RS             1.000000  1.000000  1.000000        5\n",
       "SA             1.000000  1.000000  1.000000        5\n",
       "TC             1.000000  1.000000  1.000000        5\n",
       "macro avg      0.881572  0.872281  0.870213      457\n",
       "micro avg      0.980306  0.980306  0.980306      457\n",
       "weighted avg   0.970802  0.980306  0.974714      457"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "report = classification_report(PD2.y_test(), y_pred, \n",
    "                               labels=np.arange(0,11),\n",
    "                               target_names=['RF','RO','RS','LR','BC','TC','MP','SA','P1','P2','NE'],\n",
    "                               sample_weight=None, output_dict=True)\n",
    "\n",
    "report_df = pd.DataFrame.from_dict(report, orient='index')\n",
    "display(report_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T07:24:18.872139Z",
     "start_time": "2019-01-14T07:24:18.103095Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-b546d2a13963>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpipe\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pipe' is not defined"
     ]
    }
   ],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T07:24:18.874139Z",
     "start_time": "2019-01-14T07:23:03.099Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe.steps[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T07:24:18.877139Z",
     "start_time": "2019-01-14T07:23:03.110Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe.named_steps['clf'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T07:24:18.880139Z",
     "start_time": "2019-01-14T07:23:03.116Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "## set number of principal components\n",
    "#number_principal_comp = 30\n",
    "#\n",
    "## make pca model\n",
    "#pca = PCA(n_components=number_principal_comp)\n",
    "#\n",
    "## create new features from PCA projections\n",
    "#X_train_pca = pca.fit_transform(X_train_for_pca)\n",
    "#X_test_pca = pca.transform(X_test_for_pca)\n",
    "#\n",
    "#\n",
    "## make LDA model\n",
    "#lda = LDA()\n",
    "## create new features from LDA projections\n",
    "#X_train_lda = lda.fit_transform(X_train_for_lda, y_train_lda)\n",
    "#X_test_lda = lda.transform(X_test_for_lda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$accuracy = \\frac{TP + TN}{TP + TN + FP + FN}$\n",
    "\n",
    "$precision = \\frac{TP}{TP + FP}$\n",
    "\n",
    "$recall = \\frac{TP}{TP + FN}$\n",
    "\n",
    "$f{\\text-}score = \\frac{precision \\cdot recall}{precision + recall}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
