{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of different Parameters (Features: Section Means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T14:43:12.500599Z",
     "start_time": "2019-01-12T14:43:09.926452Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pivottablejs import pivot_ui\n",
    "import sys\n",
    "sys.path.append('..')  # in order to import modules from my own package\n",
    "\n",
    "# my package\n",
    "from packageMeinhart import PhysioDataHandler as PDH\n",
    "from packageMeinhart.functionsMasterProjectMeinhart import print_precision_recall_accuracy\n",
    "from packageMeinhart.functionsMasterProjectMeinhart import print_misclassified_data_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the class *PhysioData_SectionFeatures* for feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T14:43:12.598605Z",
     "start_time": "2019-01-12T14:43:12.513600Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class PhysioData_SectionFeatures in module packageMeinhart.PhysioDataHandler:\n",
      "\n",
      "class PhysioData_SectionFeatures(builtins.object)\n",
      " |  Class for feature generation using section means.\n",
      " |  There are various selectable options --> see Parameters. \n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  num_sections : int\n",
      " |      Number of equally partitioned sections to split the single repetitions of the signals.\n",
      " |      \n",
      " |  test_subject_ids : int or list (of int)\n",
      " |      Subject IDs to select for testing (e.g. [1, 2, 3]).\n",
      " |      --> default -1: Select all subjects.\n",
      " |      --> if test_subject_ids is an empty list: empty DataFrame is returned by corresponding method.\n",
      " |      \n",
      " |  train_subject_ids : int or list\n",
      " |      Subject IDs to select for training (e.g. [1, 2, 3]).\n",
      " |      --> default -1: Select all subjects not in test_subject_ids.\n",
      " |      --> if train_subject_ids is an empty list: empty DataFrame is returned by corresponding method.\n",
      " |      \n",
      " |  test_rep_nums : int or list\n",
      " |      Repetition numbers to select for testing (e.g. [5, 10]).\n",
      " |      --> default -1: Select all repetitions.\n",
      " |      \n",
      " |  train_rep_nums : int or list\n",
      " |      Repetition numbers to select for training (e.g. [5, 10]).\n",
      " |      --> default -1: Select all repetitions.\n",
      " |      \n",
      " |  test_ex_abbrs : int or list\n",
      " |      Exercise abbreviations to select for testing (e.g. ['RF', 'SA']).\n",
      " |      --> default -1: Select all exercise abbreviations.\n",
      " |      \n",
      " |  train_ex_abbrs : int or list\n",
      " |      Exercise abbreviations to select for training (e.g. ['RF', 'SA']).\n",
      " |      --> default -1: Select all exercise abbreviations.\n",
      " |  \n",
      " |  with_non_Ex : boolean\n",
      " |      If False --> omit non exercise data (data points with zero repetitions).\n",
      " |      \n",
      " |  rot_axis_test_data : int\n",
      " |      Axis for rotation:\n",
      " |      0, 1 or 2 --> x, y or z\n",
      " |  \n",
      " |  rot_angle_test_data : int or float\n",
      " |      Rotation angle in degree.\n",
      " |  \n",
      " |  add_noise_test_data : boolean\n",
      " |      If True --> Additive White Gaussian Noise (AWGN) is added to signals of data for testing.\n",
      " |  \n",
      " |  snr_db : int or float\n",
      " |      Desired signal to noise ratio in db for the generated noisy test signals.\n",
      " |  \n",
      " |  csv_data_dir : string\n",
      " |      Directory of signal data csv-files.\n",
      " |      \n",
      " |  csv_skiprows : int\n",
      " |      Number of rows to skip for signal data csv-files.\n",
      " |      \n",
      " |  csv_separator : string\n",
      " |      Separator for signal data csv-files.\n",
      " |  \n",
      " |  data_base_path : string\n",
      " |      Path to data base (containing at least the following):\n",
      " |          - subject IDs\n",
      " |          - exercise abbreviations\n",
      " |          - number of repetitions\n",
      " |          - sequence numbers\n",
      " |          - start times\n",
      " |          - stop times\n",
      " |          - csv-file name\n",
      " |      \n",
      " |  print_progress : boolean\n",
      " |      If True --> print progress at feature generation.\n",
      " |  \n",
      " |  signal_abbrs : list of strings\n",
      " |      Abbreviations of the signals (e.g. ['Acc','Gyr']).\n",
      " |  \n",
      " |  signal_orientations : list of strings\n",
      " |      Orientations of the signals (e.g. ['x','y','z']).\n",
      " |      \n",
      " |  labels_abbr2num_dict : dict\n",
      " |      Dictionary to convert exercise abbreviations to number (e.g. ={'RF':0,'RO':1,'RS':2, ... }).\n",
      " |  \n",
      " |  sub_id_key : string\n",
      " |      Key of the DataFrame for subject IDs.\n",
      " |      \n",
      " |  num_rep_key : string\n",
      " |      Key of the DataFrame for repetition numbers.\n",
      " |      \n",
      " |  abbreviation_key : string\n",
      " |      Key of the DataFrame for exercise abbreviations.\n",
      " |      \n",
      " |  start_time_key : strings\n",
      " |      Start time key for DataFrame which contains data base entries.\n",
      " |      \n",
      " |  stop_time_key : strings\n",
      " |      Stop time key for DataFrame which contains data base entries.\n",
      " |      \n",
      " |  csv_file_key : strings\n",
      " |      csv-file key for DataFrame which contains data base entries.\n",
      " |      \n",
      " |  sampling_rate : int or float\n",
      " |      Sampling rate of the signals in Hz.\n",
      " |      \n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  X_test_df : DataFrame\n",
      " |      Features for testing.\n",
      " |  \n",
      " |  y_test_df : DataFrame\n",
      " |      Labels for testing.\n",
      " |  \n",
      " |  X_train_df : DataFrame\n",
      " |      Features for training.\n",
      " |  \n",
      " |  y_train_df : DataFrame\n",
      " |      Labels for testing.\n",
      " |  \n",
      " |  \n",
      " |  test_data_points_df : DataFrame\n",
      " |      Data points for testing from data base.\n",
      " |  \n",
      " |  train_data_points_df : DataFrame\n",
      " |      Data points for training from data base.\n",
      " |  \n",
      " |  all_data_points_df : DataFrame\n",
      " |      All data points from data base.\n",
      " |  \n",
      " |  \n",
      " |  Methods\n",
      " |  -------\n",
      " |  get_X_test_df()\n",
      " |      Returns features for testing as DataFrame.\n",
      " |  \n",
      " |  get_y_test_df() :\n",
      " |      Returns labels for testing as DataFrame.\n",
      " |  \n",
      " |  get_X_train_df() :\n",
      " |      Returns features for training as DataFrame.\n",
      " |  \n",
      " |  get_y_train_df() :\n",
      " |      Returns labels for testing as DataFrame.\n",
      " |  \n",
      " |  \n",
      " |  X_test():\n",
      " |      Returns feature matrix for testing as np.array.\n",
      " |  \n",
      " |  y_test():\n",
      " |      Returns numeric labels for testing as np.array.\n",
      " |  \n",
      " |  X_train():\n",
      " |      Returns feature matrix for training as np.array.\n",
      " |  \n",
      " |  y_train():\n",
      " |      Returns numeric labels for training as np.array.\n",
      " |  \n",
      " |  \n",
      " |  get_test_data_points()\n",
      " |      Returns data points for testing from data base as DataFrame.\n",
      " |  \n",
      " |  get_train_data_points()\n",
      " |      Returns data points for training from data base as DataFrame.\n",
      " |  \n",
      " |  get_all_data_points()\n",
      " |      Returns all data points from data base as DataFrame.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  X_test(self)\n",
      " |      # methods to get feature values only\n",
      " |  \n",
      " |  X_train(self)\n",
      " |  \n",
      " |  __init__(self, num_sections=10, test_subject_ids=-1, train_subject_ids=-1, test_rep_nums=-1, train_rep_nums=-1, test_ex_abbrs=-1, train_ex_abbrs=-1, with_non_Ex=True, rot_axis_test_data=0, rot_angle_test_data=0, add_noise_test_data=False, add_noise_train_data=False, snr_db=20, csv_data_dir='E:\\\\Physio_Data_Split_Ex_and_NonEx', csv_skiprows=0, csv_separator=',', data_base_path='E:\\\\Physio_Data\\\\DataBase_Physio_with_nonEx.db', print_progress=True, signal_abbrs=['Acc', 'Gyr'], signal_orientations=['x', 'y', 'z'], labels_abbr2num_dict={'RF': 0, 'RO': 1, 'RS': 2, 'LR': 3, 'BC': 4, 'TC': 5, 'MP': 6, 'SA': 7, 'P1': 8, 'P2': 9, 'NE': 10}, sub_id_key='subject_id', num_rep_key='num_rep', abbreviation_key='abbreviation', start_time_key='start_time', stop_time_key='stop_time', csv_file_key='csv_file', sampling_rate=256)\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      --> See class docstring.\n",
      " |  \n",
      " |  get_X_test_df(self)\n",
      " |      # methods to get features\n",
      " |  \n",
      " |  get_X_train_df(self)\n",
      " |  \n",
      " |  get_all_data_points(self)\n",
      " |  \n",
      " |  get_test_data_points(self)\n",
      " |      # methods to get data points (DataFrames)\n",
      " |  \n",
      " |  get_train_data_points(self)\n",
      " |  \n",
      " |  get_y_test_df(self)\n",
      " |  \n",
      " |  get_y_train_df(self)\n",
      " |  \n",
      " |  y_test(self)\n",
      " |  \n",
      " |  y_train(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(PDH.PhysioData_SectionFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create instance of physio data class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T14:45:31.083526Z",
     "start_time": "2019-01-12T14:45:14.175559Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate features for training...  23%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4d067f3573b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m                                      \u001b[0mstop_time_key\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'stop_time'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                                      \u001b[0mcsv_file_key\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csv_file'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m                                      sampling_rate=256)\n\u001b[0m",
      "\u001b[1;32mE:\\Jupyter_Notebooks\\Master_Project_private_repo\\packageMeinhart\\PhysioDataHandler.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, num_sections, test_subject_ids, train_subject_ids, test_rep_nums, train_rep_nums, test_ex_abbrs, train_ex_abbrs, with_non_Ex, rot_axis_test_data, rot_angle_test_data, add_noise_test_data, add_noise_train_data, snr_db, csv_data_dir, csv_skiprows, csv_separator, data_base_path, print_progress, signal_abbrs, signal_orientations, labels_abbr2num_dict, sub_id_key, num_rep_key, abbreviation_key, start_time_key, stop_time_key, csv_file_key, sampling_rate)\u001b[0m\n\u001b[0;32m    835\u001b[0m                                                \u001b[0mcsv_file_key\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcsv_file_key\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    836\u001b[0m                                                \u001b[0mprint_progress\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 837\u001b[1;33m                                                progress_info='Generate features for training...')\n\u001b[0m\u001b[0;32m    838\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m         \u001b[1;31m# otherwise create empty DataFrames for train features and labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Jupyter_Notebooks\\Master_Project_private_repo\\packageMeinhart\\PhysioDataHandler.py\u001b[0m in \u001b[0;36mgenerate_section_features_from_separate_repetitions\u001b[1;34m(data_points_df, num_sections, csv_data_dir, csv_skiprows, csv_separator, signal_abbrs, rot_axis, rot_angle, add_noise, target_snr_db, signal_orientations, labels_abbr2num_dict, sampling_rate, abbreviation_key, start_time_key, stop_time_key, csv_file_key, print_progress, progress_info)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m         \u001b[1;31m# load the signal data of the current file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m         \u001b[0mselected_data_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcsv_skiprows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcsv_separator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    505\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m         \u001b[1;31m# write data with selected signals to dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programme\\WinPython-64bit-3.6.2.0Qt5\\python-3.6.2.amd64\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programme\\WinPython-64bit-3.6.2.0Qt5\\python-3.6.2.amd64\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programme\\WinPython-64bit-3.6.2.0Qt5\\python-3.6.2.amd64\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1003\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'skipfooter not supported for iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1005\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1007\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'as_recarray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programme\\WinPython-64bit-3.6.2.0Qt5\\python-3.6.2.amd64\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1746\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1747\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1748\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1749\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1750\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read (pandas\\_libs\\parsers.c:10862)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory (pandas\\_libs\\parsers.c:11138)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows (pandas\\_libs\\parsers.c:12175)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data (pandas\\_libs\\parsers.c:14136)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens (pandas\\_libs\\parsers.c:14858)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype (pandas\\_libs\\parsers.c:15629)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mE:\\Programme\\WinPython-64bit-3.6.2.0Qt5\\python-3.6.2.amd64\\lib\\site-packages\\pandas\\core\\dtypes\\common.py\u001b[0m in \u001b[0;36mis_integer_dtype\u001b[1;34m(arr_or_dtype)\u001b[0m\n\u001b[0;32m    738\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mis_integer_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m     \"\"\"\n\u001b[0;32m    742\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "PD1 = PDH.PhysioData_SectionFeatures(num_sections=10,\n",
    "                                     test_subject_ids=1,\n",
    "                                     train_subject_ids=-1,\n",
    "                                     test_rep_nums=-1,\n",
    "                                     train_rep_nums=-1,\n",
    "                                     test_ex_abbrs=-1,\n",
    "                                     train_ex_abbrs=-1,\n",
    "                                     with_non_Ex=True,\n",
    "                                     rot_axis_test_data=0,\n",
    "                                     rot_angle_test_data=0,\n",
    "                                     add_noise_test_data=False,\n",
    "                                     add_noise_train_data=False,\n",
    "                                     snr_db=20,\n",
    "                                     csv_data_dir='E:\\Physio_Data_Split_Ex_and_NonEx',\n",
    "                                     csv_skiprows=0,\n",
    "                                     csv_separator=',',\n",
    "                                     data_base_path='E:\\Physio_Data\\DataBase_Physio_with_nonEx.db',\n",
    "                                     print_progress=True,\n",
    "                                     signal_abbrs=['Acc','Gyr'],\n",
    "                                     signal_orientations=['x','y','z'],\n",
    "                                     labels_abbr2num_dict={'RF':0,'RO':1,'RS':2,'LR':3,'BC':4,'TC':5,\n",
    "                                                           'MP':6,'SA':7,'P1':8,'P2':9,'NE':10},\n",
    "                                     sub_id_key='subject_id',\n",
    "                                     num_rep_key='num_rep',\n",
    "                                     abbreviation_key='abbreviation',\n",
    "                                     start_time_key='start_time',\n",
    "                                     stop_time_key='stop_time',\n",
    "                                     csv_file_key='csv_file',\n",
    "                                     sampling_rate=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting selected data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T14:45:35.057753Z",
     "start_time": "2019-01-12T14:45:35.027752Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500\"\n",
       "            src=\"PD1_test.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1c73fb70>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_ui(PD1.get_test_data_points(), \n",
    "         rows=['abbreviation'], \n",
    "         cols=['subject_id', 'num_rep'], \n",
    "         outfile_path=\"PD1_test.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting selected data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T14:45:37.701904Z",
     "start_time": "2019-01-12T14:45:37.595898Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500\"\n",
       "            src=\"PD1_train.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1c70bac8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_ui(PD1.get_train_data_points(), \n",
    "         rows=['abbreviation'], \n",
    "         cols=['subject_id', 'num_rep'], \n",
    "         outfile_path=\"PD1_train.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification (ML part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T14:46:04.313427Z",
     "start_time": "2019-01-12T14:46:03.551383Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "# StandardScaler raises the following warning:\n",
    "# --> DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
    "# if we want to ignore that:\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try it with different ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T09:06:23.946627Z",
     "start_time": "2019-01-11T09:06:22.945570Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestClassifier\n",
      "\n",
      "Total Accuracy: 98.87%\n",
      "\n",
      "Exercise\tPrecision [%]\tRecall [%]\tAccuracy [%]\n",
      "  RF\t\t  100.00\t   93.33\t   99.72\n",
      "  RO\t\t   93.75\t  100.00\t   99.72\n",
      "  RS\t\t  100.00\t  100.00\t  100.00\n",
      "  LR\t\t  100.00\t  100.00\t  100.00\n",
      "  BC\t\t  100.00\t  100.00\t  100.00\n",
      "  TC\t\t  100.00\t  100.00\t  100.00\n",
      "  MP\t\t   85.71\t  100.00\t   99.29\n",
      "  SA\t\t  100.00\t  100.00\t  100.00\n",
      "  P1\t\t  100.00\t   96.67\t   99.86\n",
      "  P2\t\t  100.00\t  100.00\t  100.00\n",
      "  NE\t\t   99.75\t   98.77\t   99.15\n",
      "\n",
      "8 misclassified (709 test data points):\n",
      "RF classified as RO\n",
      "RF classified as RO\n",
      "P1 classified as NE\n",
      "NE classified as MP\n",
      "NE classified as MP\n",
      "NE classified as MP\n",
      "NE classified as MP\n",
      "NE classified as MP\n"
     ]
    }
   ],
   "source": [
    "# create ML model\n",
    "ML_model = RandomForestClassifier(n_estimators=50, max_leaf_nodes=40, n_jobs=-1, random_state=42)\n",
    "#ML_model = make_pipeline(StandardScaler(), SVC(random_state=42)) # Support Vector Classifier with input scaling\n",
    "\n",
    "# train the model\n",
    "ML_model.fit(PD1.X_train(), PD1.y_train())\n",
    "\n",
    "# predict labels\n",
    "y_pred = ML_model.predict(PD1.X_test())\n",
    "\n",
    "# show results\n",
    "print('Model: ' + type(ML_model).__name__ + '\\n')\n",
    "print('Total Accuracy: {:.2f}%\\n'.format((accuracy_score(PD1.y_test(), y_pred))*100))\n",
    "print_precision_recall_accuracy(y_pred, PD1.y_test())\n",
    "print('')\n",
    "print_misclassified_data_points(y_pred, PD1.y_test())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search and Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T07:44:59.109140Z",
     "start_time": "2019-01-11T07:44:59.090139Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "pipe_elements = [('scale', StandardScaler()), ('clf', SVC())]\n",
    "#pipe_elements = [('scale', StandardScaler()), ('reduce_dim', PCA()), ('clf', SVC())]\n",
    "pipe = Pipeline(pipe_elements)\n",
    "\n",
    "param_grid = {'clf__C': [0.1, 1, 10],\n",
    "              'clf__gamma': ['scale', 0.01, 0.1]}\n",
    "\n",
    "# include PCA\n",
    "#param_grid = {'reduce_dim__n_components': [10, 20, 30],\n",
    "#              'clf__C': [1, 10, 100],\n",
    "#              'clf__gamma': [1, 10, 100]}\n",
    "\n",
    "# C: Penalty parameter C of the error term. (Regularisation parameter)\n",
    "# gamma: Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’. (Bandwidth of kernel)\n",
    "\n",
    "# splitting strategy for grid search: stratified CV with 5 folds\n",
    "grid_search = GridSearchCV(pipe, \n",
    "                           param_grid=param_grid, \n",
    "                           cv=5, scoring='accuracy', \n",
    "                           verbose=10, \n",
    "                           n_jobs=-1, \n",
    "                           return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T07:46:18.240666Z",
     "start_time": "2019-01-11T07:44:59.112140Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   32.6s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   36.0s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   53.0s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  45 | elapsed:  1.1min remaining:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('scale', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'clf__C': [0.1, 1, 10], 'clf__gamma': ['scale', 0.01, 0.1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply grid search and cross validation\n",
    "grid_search.fit(PD1.X_train(), PD1.y_train())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T07:46:18.360673Z",
     "start_time": "2019-01-11T07:46:18.244666Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.73%\n"
     ]
    }
   ],
   "source": [
    "# show score (test data)\n",
    "print('Accuracy: {:.2f}%'.format(grid_search.score(PD1.X_test(), PD1.y_test())*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T07:46:18.446678Z",
     "start_time": "2019-01-11T07:46:18.365673Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'clf__C': 1, 'clf__gamma': 'scale'}\n"
     ]
    }
   ],
   "source": [
    "# show best parameters\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T07:46:18.575685Z",
     "start_time": "2019-01-11T07:46:18.455678Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score at cross validatoin: 98.95%\n"
     ]
    }
   ],
   "source": [
    "# show best score of cross validation\n",
    "print('Best score at cross validatoin: {:.2f}%'.format(grid_search.best_score_*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T07:46:18.708693Z",
     "start_time": "2019-01-11T07:46:18.580685Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scale', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n"
     ]
    }
   ],
   "source": [
    "# show best estimator\n",
    "print('Best estimator: {}'.format(grid_search.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T07:46:18.897703Z",
     "start_time": "2019-01-11T07:46:18.714693Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_clf__C</th>\n",
       "      <th>param_clf__gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.849506</td>\n",
       "      <td>0.466027</td>\n",
       "      <td>0.977288</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.1</td>\n",
       "      <td>scale</td>\n",
       "      <td>{'clf__C': 0.1, 'clf__gamma': 'scale'}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.978013</td>\n",
       "      <td>0.981603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.982829</td>\n",
       "      <td>0.978763</td>\n",
       "      <td>0.971358</td>\n",
       "      <td>0.976929</td>\n",
       "      <td>0.985246</td>\n",
       "      <td>0.978776</td>\n",
       "      <td>0.092449</td>\n",
       "      <td>0.024683</td>\n",
       "      <td>0.006289</td>\n",
       "      <td>0.001524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.956912</td>\n",
       "      <td>0.724841</td>\n",
       "      <td>0.955392</td>\n",
       "      <td>0.957676</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'clf__C': 0.1, 'clf__gamma': 0.01}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.945440</td>\n",
       "      <td>0.956051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.953393</td>\n",
       "      <td>0.960588</td>\n",
       "      <td>0.943535</td>\n",
       "      <td>0.947121</td>\n",
       "      <td>0.986885</td>\n",
       "      <td>0.975714</td>\n",
       "      <td>0.278778</td>\n",
       "      <td>0.256786</td>\n",
       "      <td>0.016059</td>\n",
       "      <td>0.010245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.369793</td>\n",
       "      <td>0.678239</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.934069</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'clf__C': 0.1, 'clf__gamma': 0.1}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.909609</td>\n",
       "      <td>0.933974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.921504</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.930176</td>\n",
       "      <td>0.876230</td>\n",
       "      <td>0.936939</td>\n",
       "      <td>0.559981</td>\n",
       "      <td>0.021199</td>\n",
       "      <td>0.015592</td>\n",
       "      <td>0.002675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.672039</td>\n",
       "      <td>0.191011</td>\n",
       "      <td>0.989542</td>\n",
       "      <td>0.991748</td>\n",
       "      <td>1</td>\n",
       "      <td>scale</td>\n",
       "      <td>{'clf__C': 1, 'clf__gamma': 'scale'}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.985342</td>\n",
       "      <td>0.992845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995094</td>\n",
       "      <td>0.990811</td>\n",
       "      <td>0.988543</td>\n",
       "      <td>0.991833</td>\n",
       "      <td>0.988525</td>\n",
       "      <td>0.992449</td>\n",
       "      <td>0.080828</td>\n",
       "      <td>0.012602</td>\n",
       "      <td>0.003193</td>\n",
       "      <td>0.000834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.503829</td>\n",
       "      <td>0.168010</td>\n",
       "      <td>0.987908</td>\n",
       "      <td>0.990849</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'clf__C': 1, 'clf__gamma': 0.01}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.984528</td>\n",
       "      <td>0.991619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.994276</td>\n",
       "      <td>0.990402</td>\n",
       "      <td>0.985270</td>\n",
       "      <td>0.991017</td>\n",
       "      <td>0.988525</td>\n",
       "      <td>0.991837</td>\n",
       "      <td>0.029480</td>\n",
       "      <td>0.006293</td>\n",
       "      <td>0.003470</td>\n",
       "      <td>0.000892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.578405</td>\n",
       "      <td>0.489828</td>\n",
       "      <td>0.965523</td>\n",
       "      <td>0.995180</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'clf__C': 1, 'clf__gamma': 0.1}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.967427</td>\n",
       "      <td>0.996934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973017</td>\n",
       "      <td>0.994895</td>\n",
       "      <td>0.970540</td>\n",
       "      <td>0.994079</td>\n",
       "      <td>0.945082</td>\n",
       "      <td>0.995306</td>\n",
       "      <td>0.429613</td>\n",
       "      <td>0.027171</td>\n",
       "      <td>0.010362</td>\n",
       "      <td>0.000962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.660238</td>\n",
       "      <td>0.160809</td>\n",
       "      <td>0.987092</td>\n",
       "      <td>0.994567</td>\n",
       "      <td>10</td>\n",
       "      <td>scale</td>\n",
       "      <td>{'clf__C': 10, 'clf__gamma': 'scale'}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.986971</td>\n",
       "      <td>0.995707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988553</td>\n",
       "      <td>0.994282</td>\n",
       "      <td>0.987725</td>\n",
       "      <td>0.993671</td>\n",
       "      <td>0.979508</td>\n",
       "      <td>0.995306</td>\n",
       "      <td>0.079750</td>\n",
       "      <td>0.012140</td>\n",
       "      <td>0.004266</td>\n",
       "      <td>0.000802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.441025</td>\n",
       "      <td>0.116407</td>\n",
       "      <td>0.988072</td>\n",
       "      <td>0.993750</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'clf__C': 10, 'clf__gamma': 0.01}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.988599</td>\n",
       "      <td>0.994890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987735</td>\n",
       "      <td>0.992649</td>\n",
       "      <td>0.988543</td>\n",
       "      <td>0.993467</td>\n",
       "      <td>0.982787</td>\n",
       "      <td>0.994898</td>\n",
       "      <td>0.015850</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.000972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.438597</td>\n",
       "      <td>0.471627</td>\n",
       "      <td>0.961765</td>\n",
       "      <td>0.999591</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'clf__C': 10, 'clf__gamma': 0.1}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.963355</td>\n",
       "      <td>0.999387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968903</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.938525</td>\n",
       "      <td>0.999184</td>\n",
       "      <td>0.484676</td>\n",
       "      <td>0.109767</td>\n",
       "      <td>0.011846</td>\n",
       "      <td>0.000342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       1.849506         0.466027         0.977288          0.979167   \n",
       "1       1.956912         0.724841         0.955392          0.957676   \n",
       "2      10.369793         0.678239         0.901961          0.934069   \n",
       "3       0.672039         0.191011         0.989542          0.991748   \n",
       "4       0.503829         0.168010         0.987908          0.990849   \n",
       "5      10.578405         0.489828         0.965523          0.995180   \n",
       "6       0.660238         0.160809         0.987092          0.994567   \n",
       "7       0.441025         0.116407         0.988072          0.993750   \n",
       "8      10.438597         0.471627         0.961765          0.999591   \n",
       "\n",
       "  param_clf__C param_clf__gamma                                  params  \\\n",
       "0          0.1            scale  {'clf__C': 0.1, 'clf__gamma': 'scale'}   \n",
       "1          0.1             0.01     {'clf__C': 0.1, 'clf__gamma': 0.01}   \n",
       "2          0.1              0.1      {'clf__C': 0.1, 'clf__gamma': 0.1}   \n",
       "3            1            scale    {'clf__C': 1, 'clf__gamma': 'scale'}   \n",
       "4            1             0.01       {'clf__C': 1, 'clf__gamma': 0.01}   \n",
       "5            1              0.1        {'clf__C': 1, 'clf__gamma': 0.1}   \n",
       "6           10            scale   {'clf__C': 10, 'clf__gamma': 'scale'}   \n",
       "7           10             0.01      {'clf__C': 10, 'clf__gamma': 0.01}   \n",
       "8           10              0.1       {'clf__C': 10, 'clf__gamma': 0.1}   \n",
       "\n",
       "   rank_test_score  split0_test_score  split0_train_score       ...         \\\n",
       "0                5           0.978013            0.981603       ...          \n",
       "1                8           0.945440            0.956051       ...          \n",
       "2                9           0.909609            0.933974       ...          \n",
       "3                1           0.985342            0.992845       ...          \n",
       "4                3           0.984528            0.991619       ...          \n",
       "5                6           0.967427            0.996934       ...          \n",
       "6                4           0.986971            0.995707       ...          \n",
       "7                2           0.988599            0.994890       ...          \n",
       "8                7           0.963355            0.999387       ...          \n",
       "\n",
       "   split2_test_score  split2_train_score  split3_test_score  \\\n",
       "0           0.982829            0.978763           0.971358   \n",
       "1           0.953393            0.960588           0.943535   \n",
       "2           0.921504            0.932203           0.893617   \n",
       "3           0.995094            0.990811           0.988543   \n",
       "4           0.994276            0.990402           0.985270   \n",
       "5           0.973017            0.994895           0.970540   \n",
       "6           0.988553            0.994282           0.987725   \n",
       "7           0.987735            0.992649           0.988543   \n",
       "8           0.967294            1.000000           0.968903   \n",
       "\n",
       "   split3_train_score  split4_test_score  split4_train_score  std_fit_time  \\\n",
       "0            0.976929           0.985246            0.978776      0.092449   \n",
       "1            0.947121           0.986885            0.975714      0.278778   \n",
       "2            0.930176           0.876230            0.936939      0.559981   \n",
       "3            0.991833           0.988525            0.992449      0.080828   \n",
       "4            0.991017           0.988525            0.991837      0.029480   \n",
       "5            0.994079           0.945082            0.995306      0.429613   \n",
       "6            0.993671           0.979508            0.995306      0.079750   \n",
       "7            0.993467           0.982787            0.994898      0.015850   \n",
       "8            1.000000           0.938525            0.999184      0.484676   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.024683        0.006289         0.001524  \n",
       "1        0.256786        0.016059         0.010245  \n",
       "2        0.021199        0.015592         0.002675  \n",
       "3        0.012602        0.003193         0.000834  \n",
       "4        0.006293        0.003470         0.000892  \n",
       "5        0.027171        0.010362         0.000962  \n",
       "6        0.012140        0.004266         0.000802  \n",
       "7        0.002728        0.003150         0.000972  \n",
       "8        0.109767        0.011846         0.000342  \n",
       "\n",
       "[9 rows x 22 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_results = pd.DataFrame(grid_search.cv_results_)\n",
    "grid_search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters and evaluate directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T14:46:46.177821Z",
     "start_time": "2019-01-12T14:46:35.772226Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestClassifier\n",
      "\n",
      "Total Accuracy: 98.25%\n",
      "\n",
      "Exercise\tPrecision [%]\tRecall [%]\tAccuracy [%]\n",
      "  RF\t\t  100.00\t  100.00\t  100.00\n",
      "  RO\t\t  100.00\t   60.00\t   99.56\n",
      "  RS\t\t  100.00\t  100.00\t  100.00\n",
      "  LR\t\t     nan\t    0.00\t   98.91\n",
      "  BC\t\t  100.00\t  100.00\t  100.00\n",
      "  TC\t\t  100.00\t  100.00\t  100.00\n",
      "  MP\t\t   83.33\t  100.00\t   99.78\n",
      "  SA\t\t  100.00\t  100.00\t  100.00\n",
      "  P1\t\t  100.00\t  100.00\t  100.00\n",
      "  P2\t\t  100.00\t  100.00\t  100.00\n",
      "  NE\t\t   98.31\t   99.75\t   98.25\n",
      "\n",
      "8 misclassified (457 test data points):\n",
      "RO classified as NE\n",
      "RO classified as NE\n",
      "LR classified as NE\n",
      "LR classified as NE\n",
      "LR classified as NE\n",
      "LR classified as NE\n",
      "LR classified as NE\n",
      "NE classified as MP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\packageMeinhart\\functionsMasterProjectMeinhart.py:895: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = TP / (TP+FP)\n"
     ]
    }
   ],
   "source": [
    "PD2 = PDH.PhysioData_SectionFeatures(num_sections=10,\n",
    "                                     test_subject_ids=1,\n",
    "                                     train_subject_ids=1,\n",
    "                                     test_rep_nums=5,\n",
    "                                     train_rep_nums=[10, 15],\n",
    "                                     test_ex_abbrs=-1,\n",
    "                                     train_ex_abbrs=-1,\n",
    "                                     with_non_Ex=True,\n",
    "                                     rot_axis_test_data=0,\n",
    "                                     rot_angle_test_data=20,\n",
    "                                     add_noise_test_data=True,\n",
    "                                     add_noise_train_data=False,\n",
    "                                     snr_db=15)\n",
    "\n",
    "# create ML model\n",
    "ML_model = RandomForestClassifier(n_estimators=50, max_leaf_nodes=40, n_jobs=-1, random_state=42)\n",
    "#ML_model = make_pipeline(StandardScaler(), SVC(random_state=42)) # Support Vector Classifier with input scaling\n",
    "\n",
    "# train the model\n",
    "ML_model.fit(PD2.X_train(), PD2.y_train())\n",
    "\n",
    "# predict labels\n",
    "y_pred = ML_model.predict(PD2.X_test())\n",
    "\n",
    "# show results\n",
    "print('Model: ' + type(ML_model).__name__ + '\\n')\n",
    "print('Total Accuracy: {:.2f}%\\n'.format((accuracy_score(PD2.y_test(), y_pred))*100))\n",
    "print_precision_recall_accuracy(y_pred, PD2.y_test())\n",
    "print('')\n",
    "print_misclassified_data_points(y_pred, PD2.y_test())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-12T14:47:26.767143Z",
     "start_time": "2019-01-12T14:47:26.352119Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programme\\WinPython-64bit-3.6.2.0Qt5\\python-3.6.2.amd64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BC</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MP</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NE</th>\n",
       "      <td>0.983051</td>\n",
       "      <td>0.997543</td>\n",
       "      <td>0.990244</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RO</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SA</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TC</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.892399</td>\n",
       "      <td>0.872504</td>\n",
       "      <td>0.877212</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.982495</td>\n",
       "      <td>0.982495</td>\n",
       "      <td>0.982495</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.972141</td>\n",
       "      <td>0.982495</td>\n",
       "      <td>0.976641</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score  support\n",
       "BC             1.000000  1.000000  1.000000        5\n",
       "LR             0.000000  0.000000  0.000000        5\n",
       "MP             0.833333  1.000000  0.909091        5\n",
       "NE             0.983051  0.997543  0.990244      407\n",
       "P1             1.000000  1.000000  1.000000        5\n",
       "P2             1.000000  1.000000  1.000000        5\n",
       "RF             1.000000  1.000000  1.000000        5\n",
       "RO             1.000000  0.600000  0.750000        5\n",
       "RS             1.000000  1.000000  1.000000        5\n",
       "SA             1.000000  1.000000  1.000000        5\n",
       "TC             1.000000  1.000000  1.000000        5\n",
       "macro avg      0.892399  0.872504  0.877212      457\n",
       "micro avg      0.982495  0.982495  0.982495      457\n",
       "weighted avg   0.972141  0.982495  0.976641      457"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = classification_report(PD2.y_test(), y_pred, \n",
    "                               labels=np.arange(0,11),\n",
    "                               target_names=['RF','RO','RS','LR','BC','TC','MP','SA','P1','P2','NE'],\n",
    "                               sample_weight=None, output_dict=True)\n",
    "\n",
    "report_df = pd.DataFrame.from_dict(report, orient='index')\n",
    "report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T09:07:07.415113Z",
     "start_time": "2019-01-11T09:07:06.874082Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-b546d2a13963>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpipe\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pipe' is not defined"
     ]
    }
   ],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T09:07:07.416113Z",
     "start_time": "2019-01-11T09:05:35.704Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe.steps[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T09:07:07.420114Z",
     "start_time": "2019-01-11T09:05:35.710Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe.named_steps['clf'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T09:07:07.423114Z",
     "start_time": "2019-01-11T09:05:35.715Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "## set number of principal components\n",
    "#number_principal_comp = 30\n",
    "#\n",
    "## make pca model\n",
    "#pca = PCA(n_components=number_principal_comp)\n",
    "#\n",
    "## create new features from PCA projections\n",
    "#X_train_pca = pca.fit_transform(X_train_for_pca)\n",
    "#X_test_pca = pca.transform(X_test_for_pca)\n",
    "#\n",
    "#\n",
    "## make LDA model\n",
    "#lda = LDA()\n",
    "## create new features from LDA projections\n",
    "#X_train_lda = lda.fit_transform(X_train_for_lda, y_train_lda)\n",
    "#X_test_lda = lda.transform(X_test_for_lda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
