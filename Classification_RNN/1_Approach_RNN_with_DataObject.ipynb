{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Approach - Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T22:23:24.163545Z",
     "start_time": "2019-02-18T22:23:22.784466Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from pivottablejs import pivot_ui\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from matplotlib.widgets import Slider, TextBox, Button\n",
    "from sklearn.metrics import classification_report\n",
    "import sqlite3\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append('..') # in order to import modules from my own package\n",
    "from packageMeinhart import functionsMasterProjectMeinhart as fmpm\n",
    "from packageMeinhart.functionsMasterProjectMeinhart import print_precision_recall_accuracy\n",
    "from packageMeinhart.functionsMasterProjectMeinhart import print_misclassified_data_points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class to handle data for RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:38:26.853359Z",
     "start_time": "2019-02-18T20:38:26.837359Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data_from_database(data_base_path='DataBase_Physio_with_nonEx.db'):\n",
    "    '''\n",
    "    Function to load the following data from data base:\n",
    "        - subject IDs\n",
    "        - exercise abbreviations\n",
    "        - number of repetitions\n",
    "        - sequence numbers\n",
    "        - start times\n",
    "        - stop times\n",
    "        - csv-file name\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_base_path : string\n",
    "        Path to data base.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        DataFrame with the listet information (see above).\n",
    "    '''\n",
    "    # Connect to an existing database\n",
    "    conn = sqlite3.connect(data_base_path)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # sql command to extract data\n",
    "    query_sql = \"\"\"\n",
    "        SELECT e.subject_id,\n",
    "        p.abbreviation,\n",
    "        e.num_rep,\n",
    "        r.sequence_num,\n",
    "        r.start_time, r.stop_time,\n",
    "        e.csv_file\n",
    "        FROM subjects s\n",
    "        INNER JOIN exercises e\n",
    "        ON s.id = e.subject_id\n",
    "        INNER JOIN paradigms p\n",
    "        ON p.id = e.paradigm_id\n",
    "        INNER JOIN repetitions r\n",
    "        ON e.id = r.exercise_id\n",
    "        \"\"\"\n",
    "    \n",
    "    # get data from data base and close connection\n",
    "    all_data_points_df = pd.read_sql_query(query_sql, conn)\n",
    "    conn.close()\n",
    "    \n",
    "    return all_data_points_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:38:27.032370Z",
     "start_time": "2019-02-18T20:38:26.858360Z"
    }
   },
   "outputs": [],
   "source": [
    "def select_data_points_from_df(all_data_points_df,\n",
    "                               subject_ids=-1,\n",
    "                               subject_ids_complementary=[],\n",
    "                               reps=-1,\n",
    "                               abbrs=-1,\n",
    "                               with_non_Ex=True,\n",
    "                               sub_id_key='subject_id',\n",
    "                               num_rep_key='num_rep',\n",
    "                               abbreviation_key='abbreviation'):\n",
    "    '''\n",
    "    Function to select data points from a DataFrame based on subject IDs,\n",
    "    number of repetitions and exercise abbreviations.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    all_data_points_df : pandas DataFrame\n",
    "        DataFrame with all data points.\n",
    "    \n",
    "    subject_ids : int or list\n",
    "        Subject IDs to select (e.g. [1, 2, 3]).\n",
    "        --> default -1: Select all subjects.\n",
    "        \n",
    "    subject_ids_complementary : int or list\n",
    "        If subject_ids is -1 --> select only subjects not in subject_ids_complementary.\n",
    "        \n",
    "    reps : int or list\n",
    "        Repetition numbers to select (e.g. [5, 10]).\n",
    "        --> default -1: Select all repetitions.\n",
    "        \n",
    "    abbrs : int or list\n",
    "        Exercise abbreviations to select (e.g. ['RF', 'SA']).\n",
    "        --> default -1: Select all exercise abbreviations.\n",
    "    \n",
    "    with_non_Ex : boolean\n",
    "        If False --> omit non exercise data (data points with zero repetitions).\n",
    "        \n",
    "    sub_id_key : string\n",
    "        Key of the DataFrame for subject IDs.\n",
    "        \n",
    "    num_rep_key : string\n",
    "        Key of the DataFrame for repetition numbers.\n",
    "        \n",
    "    abbreviation_key : string\n",
    "        Key of the DataFrame for exercise abbreviations.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        DataFrame with selected data points.\n",
    "    '''\n",
    "    \n",
    "    data_points_df = all_data_points_df.copy()\n",
    "    \n",
    "    # select the subject IDs\n",
    "    if subject_ids is -1 and subject_ids_complementary:\n",
    "        if not isinstance(subject_ids_complementary, list): # if not list --> make list\n",
    "            subject_ids_complementary = [subject_ids_complementary]\n",
    "        data_points_df = data_points_df.loc[~data_points_df[sub_id_key].isin(subject_ids_complementary)]\n",
    "        \n",
    "    elif subject_ids is not -1:\n",
    "        if not isinstance(subject_ids, list): # if not list --> make list\n",
    "            subject_ids = [subject_ids]\n",
    "        data_points_df = data_points_df.loc[data_points_df[sub_id_key].isin(subject_ids)]\n",
    "\n",
    "    # select the repetition numbers\n",
    "    if reps is not -1:\n",
    "        if not isinstance(reps, list): # if not list --> make list\n",
    "            reps = [reps]\n",
    "        if with_non_Ex is True:\n",
    "            reps.append(0) # zero repetitions correspond to non exercise data\n",
    "        data_points_df = data_points_df.loc[data_points_df[num_rep_key].isin(reps)]\n",
    "\n",
    "    elif with_non_Ex is False:\n",
    "        data_points_df = data_points_df.loc[data_points_df[num_rep_key] != 0]\n",
    "        \n",
    "    # select the exercise abbreviations\n",
    "    if abbrs is not -1:\n",
    "        if not isinstance(abbrs, list): # if not list --> make list\n",
    "            abbrs = [abbrs]\n",
    "        data_points_df = data_points_df.loc[data_points_df[abbreviation_key].isin(abbrs)]\n",
    "\n",
    "    return data_points_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:38:27.194379Z",
     "start_time": "2019-02-18T20:38:27.039370Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_progress_func(current_num, max_num, prev_prog, add_info=None):\n",
    "    '''\n",
    "    Function to print progress [%] in a loop.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    current_num : int\n",
    "        Number of the current run in a loop.\n",
    "        \n",
    "    max_num : int\n",
    "        Maximum number of runs in a loop.\n",
    "        \n",
    "    prev_prog : int\n",
    "        Previous progress, to print only if necessary.\n",
    "        \n",
    "    add_info : str\n",
    "        Additional information to print instead of \"Progress\".\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        Previous progress, important for next run.\n",
    "    '''\n",
    "    new_prog = int(current_num/max_num*100)\n",
    "    \n",
    "    if new_prog > prev_prog:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        if isinstance(add_info, str):\n",
    "            print(add_info + ' {:3d}%'.format(new_prog))\n",
    "        else:\n",
    "            print('Progress: {:3d}%'.format(new_prog))\n",
    "        \n",
    "    return new_prog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:38:27.689407Z",
     "start_time": "2019-02-18T20:38:27.201379Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_sequences_from_separate_repetitions(data_points_df,\n",
    "                   max_sequence_length=6,\n",
    "                   orig_sampling_rate=256,\n",
    "                   new_sampling_rate=8,\n",
    "                   cutoff=10,\n",
    "                   order=6,\n",
    "                   csv_data_dir='E:\\Physio_Data_Split_Ex_and_NonEx',\n",
    "                   csv_skiprows=0,\n",
    "                   csv_separator=',',\n",
    "                   signal_abbrs=['Acc','Gyr'],\n",
    "                   signal_orientations=['x','y','z'],\n",
    "                   labels_abbr2num_dict={'RF':0,'RO':1,'RS':2,'LR':3,'BC':4,'TC':5,'MP':6,'SA':7,'P1':8,'P2':9,'NE':10},\n",
    "                   abbreviation_key='abbreviation',\n",
    "                   start_time_key='start_time',\n",
    "                   stop_time_key='stop_time',\n",
    "                   csv_file_key='csv_file',\n",
    "                   print_progress=True,\n",
    "                   progress_info='Generate sequences...'):\n",
    "    '''\n",
    "    Function to generate sequences from separate repetitions, changing the sampling rate\n",
    "    and saving them to a tensor.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_points_df : DataFrame\n",
    "        DataFrame with information about data points (see load_data_from_database()).\n",
    "        \n",
    "    max_sequence_length : int or float\n",
    "        Maximum sequence length to consider in seconds.\n",
    "        \n",
    "    orig_sampling_rate : int or float\n",
    "        Original sampling rate of the signals in Hz.\n",
    "        \n",
    "    new_sampling_rate : int or float\n",
    "        New sampling rate of the signals in Hz.\n",
    "        \n",
    "    cutoff : int or float\n",
    "        Cutoff frequency for filtering.\n",
    "    \n",
    "    order : int\n",
    "        Order of butterworth filter.\n",
    "        \n",
    "    csv_data_dir : string\n",
    "        Directory of signal data csv-files.\n",
    "        \n",
    "    csv_skiprows : int\n",
    "        Number of rows to skip for signal data csv-files.\n",
    "        \n",
    "    csv_separator : string\n",
    "        Separator for signal data csv-files.\n",
    "        \n",
    "    signal_abbrs : list of strings\n",
    "        Abbreviations of the signals (e.g. ['Acc','Gyr']).\n",
    "    \n",
    "    signal_orientations : list of strings\n",
    "        Orientations of the signals (e.g. ['x','y','z']).\n",
    "        \n",
    "    labels_abbr2num_dict : dict\n",
    "        Dictionary to convert exercise abbreviations to number (e.g. ={'RF':0,'RO':1,'RS':2, ... }).\n",
    "    \n",
    "    abbreviation_key : strings\n",
    "        Exercise abbreviation key for DataFrame which contains data base entries.\n",
    "        \n",
    "    start_time_key : strings\n",
    "        Start time key for DataFrame which contains data base entries.\n",
    "        \n",
    "    stop_time_key : strings\n",
    "        Stop time key for DataFrame which contains data base entries.\n",
    "        \n",
    "    csv_file_key : strings\n",
    "        csv-file key for DataFrame which contains data base entries.\n",
    "        \n",
    "    print_progress : boolean\n",
    "        If True --> print progress at signal sequences generation.\n",
    "        \n",
    "    progress_info : strings\n",
    "        Additional information to print with progress.\n",
    "        \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X_all, y_all, seqlens_all\n",
    "        \n",
    "        X_all ... tensor with signal sequences (dimensions: [number of data points, \n",
    "                                                             max sequence length, \n",
    "                                                             number of signals])\n",
    "        y_all ... array with labels\n",
    "        seqlens_all ... array with sequence lengths\n",
    "    '''\n",
    "    \n",
    "    # max index of new sequences\n",
    "    max_sequ_index = max_sequence_length * new_sampling_rate\n",
    "    \n",
    "    # number of signals (Acc: x, y, z; Gyr: x, y, z --> 6 signals)\n",
    "    num_signals = len(signal_abbrs) * len(signal_orientations)\n",
    "    \n",
    "    # number to exercise-abbreviations dict\n",
    "    labels_num2abbr_dict = {num: abbr for abbr, num in labels_abbr2num_dict.items()}\n",
    "                                                   \n",
    "    # create array for labels\n",
    "    y_all = np.zeros(len(data_points_df), dtype=np.int8)\n",
    "    \n",
    "    # create tensor for sequences\n",
    "    X_all = np.zeros((len(data_points_df), max_sequ_index, num_signals))\n",
    "    \n",
    "    # create matrix for sequence lengths\n",
    "    seqlens_all = np.zeros(len(data_points_df), dtype=np.int)\n",
    "    \n",
    "    # sampling rate ratio of original and new sampling rate (e.g. if ratio = 32 --> take every 32nd index)\n",
    "    sampling_rate_ratio = orig_sampling_rate / new_sampling_rate\n",
    "\n",
    "    # location counter for the sequence tensor\n",
    "    loc_count = 0\n",
    "\n",
    "    # variables for progress printing\n",
    "    if print_progress:\n",
    "        prog_count = 0\n",
    "        max_count = len(data_points_df.csv_file.unique()) # number of unique csv-files\n",
    "        prev_progress = 0 # previous progress\n",
    "\n",
    "    # going through all csv-files (unique --> only once for each file)\n",
    "    for current_csv_file in data_points_df.csv_file.unique():\n",
    "\n",
    "        # join file path\n",
    "        file_path = os.path.join(csv_data_dir, current_csv_file)\n",
    "\n",
    "        # load the signal data of the current file\n",
    "        selected_data_df = pd.read_csv(file_path, skiprows=csv_skiprows, sep=csv_separator)\n",
    "        \n",
    "        # write data with selected signals to dict\n",
    "        selected_data = {}\n",
    "        for sig in signal_abbrs:\n",
    "            selected_data[sig] = selected_data_df.filter(regex=sig+'*').values\n",
    "            \n",
    "        # filter data with butterworth filter and save to new dictionary\n",
    "        selected_data_filt = {}\n",
    "        for sig in signal_abbrs:\n",
    "            selected_data_filt[sig] = fmpm.butter_lowpass_filter(selected_data[sig], \n",
    "                                                                 cutoff=cutoff, \n",
    "                                                                 fs=orig_sampling_rate, \n",
    "                                                                 order=order)\n",
    "    \n",
    "        # data frame with all repetitions of the current file\n",
    "        current_data_points = data_points_df.loc[data_points_df[csv_file_key] == current_csv_file]\n",
    "\n",
    "        # going through all repetitions of the current file\n",
    "        for ii in range(len(current_data_points)):\n",
    "            \n",
    "            # get start and stop indices of current data point (current repetition)\n",
    "            start_time = float(current_data_points.reset_index().loc[ii, start_time_key])\n",
    "            stop_time = float(current_data_points.reset_index().loc[ii, stop_time_key])\n",
    "            start_idx = round(start_time * orig_sampling_rate)\n",
    "            stop_idx = round(stop_time * orig_sampling_rate)\n",
    "\n",
    "            # consider the new sampling rate for signal data selection\n",
    "            new_indices = np.arange(start_idx, stop_idx, sampling_rate_ratio).round().astype(int)\n",
    "            \n",
    "            # check if array of new indices is longer than max_sequ_index\n",
    "            if len(new_indices) > max_sequ_index:\n",
    "                new_indices = new_indices[:max_sequ_index] # take only that much indices\n",
    "            \n",
    "            # add current sequences with new sampling rate\n",
    "            for kk, sig in enumerate(signal_abbrs):\n",
    "                for ll in range(len(signal_orientations)):\n",
    "                    # explanation: X_all[index_of_current_data_point, \n",
    "                    #                    select_all_until_length_of_new_signal_data, \n",
    "                    #                    index_of_current_signal (0...5)]\n",
    "                    X_all[loc_count,:len(new_indices),kk*len(signal_orientations)+ll] = \\\n",
    "                        selected_data_filt[sig][new_indices,ll]\n",
    "\n",
    "            # add current label\n",
    "            current_ex_abbr = current_data_points.reset_index().loc[ii,abbreviation_key]\n",
    "            y_all[loc_count] = labels_abbr2num_dict[current_ex_abbr]\n",
    "            \n",
    "            # add current sequence length\n",
    "            seqlens_all[loc_count] = len(new_indices)\n",
    "\n",
    "            loc_count += 1\n",
    "\n",
    "        # print progress of feauture generation\n",
    "        if print_progress:\n",
    "            prog_count += 1\n",
    "            prev_progress = print_progress_func(prog_count, max_count, prev_progress, add_info=progress_info)\n",
    "    \n",
    "    if print_progress:\n",
    "        clear_output()\n",
    "    \n",
    "    return X_all, y_all, seqlens_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:38:28.088430Z",
     "start_time": "2019-02-18T20:38:27.692407Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_sequences_from_repetition_blocks(data_points_df,\n",
    "                   max_sequence_length=80,\n",
    "                   orig_sampling_rate=256,\n",
    "                   new_sampling_rate=8,\n",
    "                   cutoff=10,\n",
    "                   order=6,\n",
    "                   csv_data_dir='E:\\Physio_Data_Split_Ex_and_NonEx',\n",
    "                   csv_skiprows=0,\n",
    "                   csv_separator=',',\n",
    "                   signal_abbrs=['Acc','Gyr'],\n",
    "                   signal_orientations=['x','y','z'],\n",
    "                   labels_abbr2num_dict={'RF':0,'RO':1,'RS':2,'LR':3,'BC':4,'TC':5,'MP':6,'SA':7,'P1':8,'P2':9,'NE':10},\n",
    "                   abbreviation_key='abbreviation',\n",
    "                   csv_file_key='csv_file',\n",
    "                   print_progress=True,\n",
    "                   progress_info='Generate sequences...'):\n",
    "    '''\n",
    "    Function to generate sequences from whole repetition blocks, changing the sampling rate\n",
    "    and saving them to a tensor.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_points_df : DataFrame\n",
    "        DataFrame with information about data points (see load_data_from_database()).\n",
    "        \n",
    "    max_sequence_length : int or float\n",
    "        Maximum sequence length to consider in seconds.\n",
    "        \n",
    "    orig_sampling_rate : int or float\n",
    "        Original sampling rate of the signals in Hz.\n",
    "        \n",
    "    new_sampling_rate : int or float\n",
    "        New sampling rate of the signals in Hz.\n",
    "        \n",
    "    cutoff : int or float\n",
    "        Cutoff frequency for filtering.\n",
    "    \n",
    "    order : int\n",
    "        Order of butterworth filter.\n",
    "        \n",
    "    csv_data_dir : string\n",
    "        Directory of signal data csv-files.\n",
    "        \n",
    "    csv_skiprows : int\n",
    "        Number of rows to skip for signal data csv-files.\n",
    "        \n",
    "    csv_separator : string\n",
    "        Separator for signal data csv-files.\n",
    "        \n",
    "    signal_abbrs : list of strings\n",
    "        Abbreviations of the signals (e.g. ['Acc','Gyr']).\n",
    "    \n",
    "    signal_orientations : list of strings\n",
    "        Orientations of the signals (e.g. ['x','y','z']).\n",
    "        \n",
    "    labels_abbr2num_dict : dict\n",
    "        Dictionary to convert exercise abbreviations to number (e.g. ={'RF':0,'RO':1,'RS':2, ... }).\n",
    "    \n",
    "    abbreviation_key : strings\n",
    "        Exercise abbreviation key for DataFrame which contains data base entries.\n",
    "        \n",
    "    csv_file_key : strings\n",
    "        csv-file key for DataFrame which contains data base entries.\n",
    "        \n",
    "    print_progress : boolean\n",
    "        If True --> print progress at signal sequences generation.\n",
    "        \n",
    "    progress_info : strings\n",
    "        Additional information to print with progress.\n",
    "        \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X_all, y_all, seqlens_all\n",
    "        \n",
    "        X_all ... tensor with signal sequences (dimensions: [number of data points, \n",
    "                                                             max sequence length, \n",
    "                                                             number of signals])\n",
    "        y_all ... array with labels\n",
    "        seqlens_all ... array with sequence lengths\n",
    "    '''\n",
    "    \n",
    "    # max index of new sequences\n",
    "    max_sequ_index = max_sequence_length * new_sampling_rate\n",
    "    \n",
    "    # number of signals (Acc: x, y, z; Gyr: x, y, z --> 6 signals)\n",
    "    num_signals = len(signal_abbrs) * len(signal_orientations)\n",
    "    \n",
    "    # number to exercise-abbreviations dict\n",
    "    labels_num2abbr_dict = {num: abbr for abbr, num in labels_abbr2num_dict.items()}\n",
    "    \n",
    "    # every csv-file is one repetition block --> one data point\n",
    "    csv_files_unique = data_points_df.csv_file.unique()\n",
    "    \n",
    "    # create array for labels\n",
    "    y_all = np.zeros(len(csv_files_unique), dtype=np.int8)\n",
    "    \n",
    "    # create tensor for sequences\n",
    "    X_all = np.zeros((len(csv_files_unique), max_sequ_index, num_signals))\n",
    "    \n",
    "    # create matrix for sequence lengths\n",
    "    seqlens_all = np.zeros(len(csv_files_unique), dtype=np.int)\n",
    "    \n",
    "    # sampling rate ratio of original and new sampling rate (e.g. if ratio = 32 --> take every 32nd index)\n",
    "    sampling_rate_ratio = orig_sampling_rate / new_sampling_rate\n",
    "\n",
    "    # location counter for the sequence tensor\n",
    "    loc_count = 0\n",
    "\n",
    "    # variables for progress printing\n",
    "    if print_progress:\n",
    "        prog_count = 0\n",
    "        max_count = len(csv_files_unique) # number of unique csv-files\n",
    "        prev_progress = 0 # previous progress\n",
    "\n",
    "    # going through all csv-files (unique --> only once for each file)\n",
    "    for current_csv_file in csv_files_unique:\n",
    "\n",
    "        # join file path\n",
    "        file_path = os.path.join(csv_data_dir, current_csv_file)\n",
    "\n",
    "        # load the signal data of the current file\n",
    "        selected_data_df = pd.read_csv(file_path, skiprows=csv_skiprows, sep=csv_separator)\n",
    "        \n",
    "        # write data with selected signals to dict\n",
    "        selected_data = {}\n",
    "        for sig in signal_abbrs:\n",
    "            selected_data[sig] = selected_data_df.filter(regex=sig+'*').values\n",
    "            \n",
    "        # filter data with butterworth filter and save to new dictionary\n",
    "        selected_data_filt = {}\n",
    "        for sig in signal_abbrs:\n",
    "            selected_data_filt[sig] = fmpm.butter_lowpass_filter(selected_data[sig], \n",
    "                                                                 cutoff=cutoff, \n",
    "                                                                 fs=orig_sampling_rate, \n",
    "                                                                 order=order)\n",
    "            \n",
    "        # start and stop indices of current data point (current repetition block)\n",
    "        start_idx = 0\n",
    "        # all signal columns must have the same length\n",
    "        stop_idx = len(selected_data_filt[signal_abbrs[0]][:,0])\n",
    "\n",
    "        # consider the new sampling rate for signal data selection\n",
    "        new_indices = np.arange(start_idx, stop_idx, sampling_rate_ratio).round().astype(int)\n",
    "            \n",
    "        # check if array of new indices is longer than max_sequ_index\n",
    "        if len(new_indices) > max_sequ_index:\n",
    "            new_indices = new_indices[:max_sequ_index] # take only that much indices\n",
    "            \n",
    "        # add current sequences with new sampling rate\n",
    "        for kk, sig in enumerate(signal_abbrs):\n",
    "            for ll in range(len(signal_orientations)):\n",
    "                # explanation: X_all[index_of_current_data_point, \n",
    "                #                    select_all_until_length_of_new_signal_data, \n",
    "                #                    index_of_current_signal (0...5)]\n",
    "                X_all[loc_count,:len(new_indices),kk*len(signal_orientations)+ll] = \\\n",
    "                    selected_data_filt[sig][new_indices,ll]\n",
    "\n",
    "        # add current label\n",
    "        # data frame with all repetitions of the current file\n",
    "        current_data_points = data_points_df.loc[data_points_df[csv_file_key] == current_csv_file]\n",
    "        current_ex_abbr = current_data_points.reset_index().loc[0,abbreviation_key]\n",
    "        y_all[loc_count] = labels_abbr2num_dict[current_ex_abbr]\n",
    "            \n",
    "        # add current sequence length\n",
    "        seqlens_all[loc_count] = len(new_indices)\n",
    "\n",
    "        loc_count += 1\n",
    "\n",
    "        # print progress of feauture generation\n",
    "        if print_progress:\n",
    "            prog_count += 1\n",
    "            prev_progress = print_progress_func(prog_count, max_count, prev_progress, add_info=progress_info)\n",
    "    \n",
    "    if print_progress:\n",
    "        clear_output()\n",
    "    \n",
    "    return X_all, y_all, seqlens_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:38:28.641462Z",
     "start_time": "2019-02-18T20:38:28.092430Z"
    }
   },
   "outputs": [],
   "source": [
    "class PhysioData_RNN():\n",
    "    '''\n",
    "    Class to handle signal data for RNN.\n",
    "    \n",
    "    Detailed description follows ...\n",
    "    \n",
    "    For now: look at docstrings of the following functions:\n",
    "        - load_data_from_database()\n",
    "        - select_data_points_from_df()\n",
    "        - generate_sequences_from_separate_repetitions()\n",
    "        - generate_sequences_from_repetition_blocks()\n",
    "    \n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 test_subject_ids=-1,\n",
    "                 train_subject_ids=-1,\n",
    "                 test_rep_nums=-1,\n",
    "                 train_rep_nums=-1,\n",
    "                 test_ex_abbrs=-1,\n",
    "                 train_ex_abbrs=-1,\n",
    "                 with_non_Ex=True,\n",
    "                 max_sequence_length_testing=6,\n",
    "                 max_sequence_length_training=6,\n",
    "                 orig_sampling_rate=256,\n",
    "                 new_sampling_rate=8,\n",
    "                 whole_rep_blocks_as_data_points_for_testing=False,\n",
    "                 whole_rep_blocks_as_data_points_for_training=False,\n",
    "                 cutoff=10,\n",
    "                 order=6,\n",
    "                 csv_data_dir='E:\\Physio_Data_Split_Ex_and_NonEx',\n",
    "                 csv_skiprows=0,\n",
    "                 csv_separator=',',\n",
    "                 data_base_path='E:\\Physio_Data\\DataBase_Physio_with_nonEx.db',\n",
    "                 print_progress=True,\n",
    "                 signal_abbrs=['Acc','Gyr'],\n",
    "                 signal_orientations=['x','y','z'],\n",
    "                 labels_abbr2num_dict={'RF':0,'RO':1,'RS':2,'LR':3,'BC':4,'TC':5,'MP':6,'SA':7,'P1':8,'P2':9,'NE':10},\n",
    "                 sub_id_key='subject_id',\n",
    "                 num_rep_key='num_rep',\n",
    "                 abbreviation_key='abbreviation',\n",
    "                 start_time_key='start_time',\n",
    "                 stop_time_key='stop_time',\n",
    "                 csv_file_key='csv_file'):\n",
    "        \n",
    "        # load all data from data points\n",
    "        self.all_data_points_df = load_data_from_database(data_base_path)\n",
    "        \n",
    "        # load data points for testing\n",
    "        self.test_data_points_df =  select_data_points_from_df(self.all_data_points_df,\n",
    "                                                               subject_ids=test_subject_ids,\n",
    "                                                               subject_ids_complementary=[],\n",
    "                                                               reps=test_rep_nums,\n",
    "                                                               abbrs=test_ex_abbrs,\n",
    "                                                               with_non_Ex=with_non_Ex,\n",
    "                                                               sub_id_key=sub_id_key,\n",
    "                                                               num_rep_key=num_rep_key,\n",
    "                                                               abbreviation_key=abbreviation_key)\n",
    "        \n",
    "        # load data points for training\n",
    "        self.train_data_points_df = select_data_points_from_df(self.all_data_points_df,\n",
    "                                                               subject_ids=train_subject_ids,\n",
    "                                                               subject_ids_complementary=test_subject_ids,\n",
    "                                                               reps=train_rep_nums,\n",
    "                                                               abbrs=train_ex_abbrs,\n",
    "                                                               with_non_Ex=with_non_Ex,\n",
    "                                                               sub_id_key=sub_id_key,\n",
    "                                                               num_rep_key=num_rep_key,\n",
    "                                                               abbreviation_key=abbreviation_key)\n",
    "        \n",
    "        # take whole repetition blocks as data points for testing\n",
    "        if whole_rep_blocks_as_data_points_for_testing is True:\n",
    "            \n",
    "            # generate sequences for testing\n",
    "            self.X_test, self.y_test, self.seqlens_test = generate_sequences_from_repetition_blocks(\n",
    "                                                                   self.test_data_points_df,\n",
    "                                                                   max_sequence_length=max_sequence_length_testing,\n",
    "                                                                   orig_sampling_rate=orig_sampling_rate,\n",
    "                                                                   new_sampling_rate=new_sampling_rate,\n",
    "                                                                   cutoff=cutoff,\n",
    "                                                                   order=order,\n",
    "                                                                   csv_data_dir=csv_data_dir,\n",
    "                                                                   csv_skiprows=csv_skiprows,\n",
    "                                                                   csv_separator=csv_separator,\n",
    "                                                                   signal_abbrs=signal_abbrs,\n",
    "                                                                   signal_orientations=signal_orientations,\n",
    "                                                                   labels_abbr2num_dict=labels_abbr2num_dict,\n",
    "                                                                   abbreviation_key=abbreviation_key,\n",
    "                                                                   csv_file_key=csv_file_key,\n",
    "                                                                   print_progress=print_progress,\n",
    "                                                                   progress_info='Generate sequences for testing...')\n",
    "        \n",
    "        # take single repetitions as data points for testing\n",
    "        else:\n",
    "            \n",
    "            # generate sequences for testing\n",
    "            self.X_test, self.y_test, self.seqlens_test = generate_sequences_from_separate_repetitions(\n",
    "                                                                   self.test_data_points_df,\n",
    "                                                                   max_sequence_length=max_sequence_length_testing,\n",
    "                                                                   orig_sampling_rate=orig_sampling_rate,\n",
    "                                                                   new_sampling_rate=new_sampling_rate,\n",
    "                                                                   cutoff=cutoff,\n",
    "                                                                   order=order,\n",
    "                                                                   csv_data_dir=csv_data_dir,\n",
    "                                                                   csv_skiprows=csv_skiprows,\n",
    "                                                                   csv_separator=csv_separator,\n",
    "                                                                   signal_abbrs=signal_abbrs,\n",
    "                                                                   signal_orientations=signal_orientations,\n",
    "                                                                   labels_abbr2num_dict=labels_abbr2num_dict,\n",
    "                                                                   abbreviation_key=abbreviation_key,\n",
    "                                                                   start_time_key=start_time_key,\n",
    "                                                                   stop_time_key=stop_time_key,\n",
    "                                                                   csv_file_key=csv_file_key,\n",
    "                                                                   print_progress=print_progress,\n",
    "                                                                   progress_info='Generate sequences for testing...')\n",
    "            \n",
    "        # take whole repetition blocks as data points for training\n",
    "        if whole_rep_blocks_as_data_points_for_training is True:\n",
    "\n",
    "            # generate sequences for training\n",
    "            self.X_train, self.y_train, self.seqlens_train = generate_sequences_from_repetition_blocks(\n",
    "                                                                   self.train_data_points_df,\n",
    "                                                                   max_sequence_length=max_sequence_length_training,\n",
    "                                                                   orig_sampling_rate=orig_sampling_rate,\n",
    "                                                                   new_sampling_rate=new_sampling_rate,\n",
    "                                                                   cutoff=cutoff,\n",
    "                                                                   order=order,\n",
    "                                                                   csv_data_dir=csv_data_dir,\n",
    "                                                                   csv_skiprows=csv_skiprows,\n",
    "                                                                   csv_separator=csv_separator,\n",
    "                                                                   signal_abbrs=signal_abbrs,\n",
    "                                                                   signal_orientations=signal_orientations,\n",
    "                                                                   labels_abbr2num_dict=labels_abbr2num_dict,\n",
    "                                                                   abbreviation_key=abbreviation_key,\n",
    "                                                                   csv_file_key=csv_file_key,\n",
    "                                                                   print_progress=print_progress,\n",
    "                                                                   progress_info='Generate sequences for training...')\n",
    "            \n",
    "        # take single repetitions as data points for training\n",
    "        else:\n",
    "\n",
    "            # generate sequences for training\n",
    "            self.X_train, self.y_train, self.seqlens_train = generate_sequences_from_separate_repetitions(\n",
    "                                                                   self.train_data_points_df,\n",
    "                                                                   max_sequence_length=max_sequence_length_training,\n",
    "                                                                   orig_sampling_rate=orig_sampling_rate,\n",
    "                                                                   new_sampling_rate=new_sampling_rate,\n",
    "                                                                   cutoff=cutoff,\n",
    "                                                                   order=order,\n",
    "                                                                   csv_data_dir=csv_data_dir,\n",
    "                                                                   csv_skiprows=csv_skiprows,\n",
    "                                                                   csv_separator=csv_separator,\n",
    "                                                                   signal_abbrs=signal_abbrs,\n",
    "                                                                   signal_orientations=signal_orientations,\n",
    "                                                                   labels_abbr2num_dict=labels_abbr2num_dict,\n",
    "                                                                   abbreviation_key=abbreviation_key,\n",
    "                                                                   start_time_key=start_time_key,\n",
    "                                                                   stop_time_key=stop_time_key,\n",
    "                                                                   csv_file_key=csv_file_key,\n",
    "                                                                   print_progress=print_progress,\n",
    "                                                                   progress_info='Generate sequences for training...')\n",
    "    \n",
    "    \n",
    "    def get_train_batch(self, batch_size):\n",
    "        '''\n",
    "        Method to get batch with randomly selected training data.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        batch_size : int\n",
    "            Number of data points in batch.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        X_train_batch, y_train_batch, seqlens_train_batch\n",
    "        '''\n",
    "        \n",
    "        instance_indices = list(range(len(self.y_train))) # list with all train indices\n",
    "        np.random.shuffle(instance_indices) # shuffle the train indices\n",
    "        batch_indices = instance_indices[:batch_size] # randomly select train indices\n",
    "    \n",
    "        # select batch data with corresponding indices\n",
    "        X_train_batch = np.array(self.X_train)[batch_indices]\n",
    "        y_train_batch = self.y_train[batch_indices]\n",
    "        seqlens_train_batch = np.array(self.seqlens_train)[batch_indices]\n",
    "\n",
    "        return X_train_batch, y_train_batch, seqlens_train_batch\n",
    "\n",
    "    \n",
    "    # methods to get data\n",
    "    def get_X_test(self):\n",
    "        return self.X_test\n",
    "    \n",
    "    def get_y_test(self):\n",
    "        return self.y_test\n",
    "    \n",
    "    def get_seqlens_test(self):\n",
    "        return self.seqlens_test\n",
    "    \n",
    "    def get_X_train(self):\n",
    "        return self.X_train\n",
    "    \n",
    "    def get_y_train(self):\n",
    "        return self.y_train\n",
    "    \n",
    "    def get_sequlens_train(self):\n",
    "        return self.sequlens_train\n",
    "    \n",
    "    \n",
    "    # methods to get data points (DataFrames)\n",
    "    def get_test_data_points(self):\n",
    "        return self.test_data_points_df\n",
    "    \n",
    "    def get_train_data_points(self):\n",
    "        return self.train_data_points_df\n",
    "    \n",
    "    def get_all_data_points(self):\n",
    "        return self.all_data_points_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create instance of the class *PhysioData_RNN*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:39:05.467568Z",
     "start_time": "2019-02-18T20:38:28.645462Z"
    }
   },
   "outputs": [],
   "source": [
    "PD_RNN1 = PhysioData_RNN(test_subject_ids=1,\n",
    "                         max_sequence_length_testing=6,\n",
    "                         max_sequence_length_training=6,\n",
    "                         new_sampling_rate=4,\n",
    "                         whole_rep_blocks_as_data_points_for_testing=False,\n",
    "                         whole_rep_blocks_as_data_points_for_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:39:05.493570Z",
     "start_time": "2019-02-18T20:39:05.472568Z"
    }
   },
   "outputs": [],
   "source": [
    "np.shape(PD_RNN1.get_X_test())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:39:05.649578Z",
     "start_time": "2019-02-18T20:39:05.498570Z"
    }
   },
   "outputs": [],
   "source": [
    "np.shape(PD_RNN1.get_X_train())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:39:05.897593Z",
     "start_time": "2019-02-18T20:39:05.656579Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PD_RNN1.get_X_test()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:39:06.059602Z",
     "start_time": "2019-02-18T20:39:05.903593Z"
    }
   },
   "outputs": [],
   "source": [
    "PD_RNN1.get_y_test()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:39:06.225611Z",
     "start_time": "2019-02-18T20:39:06.065602Z"
    }
   },
   "outputs": [],
   "source": [
    "PD_RNN1.get_seqlens_test()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:39:06.366619Z",
     "start_time": "2019-02-18T20:39:06.231612Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_batch, y_train_batch, seqlens_train_batch = PD_RNN1.get_train_batch(batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:39:06.522628Z",
     "start_time": "2019-02-18T20:39:06.370620Z"
    }
   },
   "outputs": [],
   "source": [
    "np.shape(X_train_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:39:06.668637Z",
     "start_time": "2019-02-18T20:39:06.529629Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:39:06.824646Z",
     "start_time": "2019-02-18T20:39:06.675637Z"
    }
   },
   "outputs": [],
   "source": [
    "seqlens_train_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:39:07.121663Z",
     "start_time": "2019-02-18T20:39:06.829646Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(X_train_batch[0,:,:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:39:07.380677Z",
     "start_time": "2019-02-18T20:39:07.128663Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(PD_RNN1.get_X_test()[0,:,:]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Recurrent Neural Network with *TensorFlow*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:39:09.222783Z",
     "start_time": "2019-02-18T20:39:07.383678Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:39:09.245784Z",
     "start_time": "2019-02-18T20:39:09.226783Z"
    }
   },
   "outputs": [],
   "source": [
    "# directory to save TensorBoard model summaries\n",
    "LOG_DIR_ALL = 'E:\\Jupyter_Notebooks\\Master_Project_Meinhart_git\\logs\\RNN_with_summaries'\n",
    "\n",
    "# run the command:\n",
    "print('tensorboard --logdir=' + LOG_DIR_ALL)\n",
    "\n",
    "#  --> open http://FlorianMeinhart:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:39:09.386792Z",
     "start_time": "2019-02-18T20:39:09.253785Z"
    }
   },
   "outputs": [],
   "source": [
    "# define parameters for RNN\n",
    "num_signals = 6 # number of signals (Acc: x, y, z; Gyr: x, y, z)\n",
    "num_classes = 11 # number of classes\n",
    "batch_size = 150 # number of data points for each batch\n",
    "time_steps = None # --> dynamic_rnn\n",
    "hidden_layer_size_rnn = 128 # number of neurons in the hidden layer of the RNN\n",
    "num_steps = 1501 # number of steps for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:39:09.518800Z",
     "start_time": "2019-02-18T20:39:09.390792Z"
    }
   },
   "outputs": [],
   "source": [
    "# get time in order to append corresponding string to log directory\n",
    "now = datetime.now()\n",
    "LOG_DIR_TRAIN = LOG_DIR_ALL + now.strftime('\\%Y%m%d-%H%M%S' + '_train')\n",
    "LOG_DIR_TEST = LOG_DIR_ALL + now.strftime('\\%Y%m%d-%H%M%S' + '_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:39:10.104833Z",
     "start_time": "2019-02-18T20:39:09.521800Z"
    }
   },
   "outputs": [],
   "source": [
    "# create new tensorflow graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# name scope for data\n",
    "with tf.name_scope('data'):\n",
    "    # placeholder for tensor with features (signals of repetitions)\n",
    "    inputs = tf.placeholder(tf.float32, shape=[None, time_steps, num_signals], name='inputs')\n",
    "    # placeholder for labels (exercises)\n",
    "    labels = tf.placeholder(tf.int32, shape=[None, num_classes], name='labels')\n",
    "    # placeholder for information of sequence lengths of single repetitions\n",
    "    seqlens = tf.placeholder(tf.int32, shape=[None], name='seqlens')\n",
    "\n",
    "# name scope for hidden RNN layer\n",
    "with tf.name_scope('RNN_layer'):\n",
    "    # used cell for the RNN\n",
    "    rnn_cell = tf.nn.rnn_cell.BasicRNNCell(hidden_layer_size_rnn)\n",
    "    #rnn_cell = tf.nn.rnn_cell.BasicLSTMCell(hidden_layer_size_rnn)\n",
    "    \n",
    "    # creating a RNN with the cell from above\n",
    "    # --> 'outputs' contains hidden states of whole input sequence\n",
    "    # --> 'states' contains only last hidden states\n",
    "    outputs, states = tf.nn.dynamic_rnn(rnn_cell, inputs, sequence_length=seqlens, dtype=tf.float32)\n",
    "\n",
    "# name scope for linear output layer\n",
    "with tf.name_scope('linear_layer'):\n",
    "    # weights for the linear output layer\n",
    "    W1 = tf.Variable(tf.truncated_normal([hidden_layer_size_rnn, num_classes], mean=0, stddev=0.1),\n",
    "                     name='weights_linear')\n",
    "    # bias terms for the linear output layer\n",
    "    b1 = tf.Variable(tf.truncated_normal([num_classes], mean=0, stddev=0.1),\n",
    "                     name='biases_linear')\n",
    "    # computation of final output, considering only the last RNN state of a whole input sequence\n",
    "    final_output = tf.matmul(states, W1) + b1\n",
    "    #final_output = tf.matmul(states[0], W1) + b1\n",
    "    \n",
    "    # computation of final output, considering all RNN states of a whole input sequence\n",
    "    final_output_all_states = tf.matmul(tf.reshape(outputs, [-1, hidden_layer_size_rnn]), W1) + b1\n",
    "    \n",
    "    # using softmax and cross entropy as cost function\n",
    "    softmax = tf.nn.softmax_cross_entropy_with_logits_v2(logits=final_output, labels=labels)\n",
    "    cross_entropy = tf.reduce_mean(softmax)\n",
    "    \n",
    "    # adding cross entropy to summary\n",
    "    tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "\n",
    "# training of the RNN using cross entropy\n",
    "train_step = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cross_entropy)\n",
    "#train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)\n",
    "\n",
    "# name scope for the evaluation\n",
    "with tf.name_scope('evaluation'):\n",
    "    # determining the correct predictions\n",
    "    correct_prediction = tf.equal(tf.argmax(labels,1), tf.argmax(final_output,1), name='correct_prediction')\n",
    "    \n",
    "    # calculating the corresponding accuracy\n",
    "    accuracy = (tf.reduce_mean(tf.cast(correct_prediction, tf.float32)))*100\n",
    "    \n",
    "    # adding accuracy to summary\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "    \n",
    "    # getting predicted probabilities, considering only the last RNN state of a whole input sequence\n",
    "    pred_prob = tf.nn.softmax(logits=final_output, name='predicted_probabilities')\n",
    "    \n",
    "    # getting predicted probabilities, considering all RNN states of a whole input sequence\n",
    "    pred_prob_all_states = tf.nn.softmax(logits=final_output_all_states, name='predicted_probabilities_all_states')\n",
    "    \n",
    "\n",
    "# merging summaries and creating summary writers for training and testing\n",
    "merged = tf.summary.merge_all()\n",
    "train_writer = tf.summary.FileWriter(LOG_DIR_TRAIN)\n",
    "test_writer = tf.summary.FileWriter(LOG_DIR_TEST) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:39:10.119834Z",
     "start_time": "2019-02-18T20:39:10.108834Z"
    }
   },
   "outputs": [],
   "source": [
    "def one_hot(labels, num_classes):\n",
    "    '''\n",
    "    Convert lables to one-hot format.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    labels : array or list of integers\n",
    "        --> e.g. [0, 1, 4, 2, 0]\n",
    "        \n",
    "    num_classes : int\n",
    "        Number of classes.\n",
    "        (Has to be >= max(labels))\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matrix\n",
    "        Lables in one-hot format.\n",
    "    \n",
    "        --> e.g.\n",
    "              [[1., 0., 0., 0., 0.],\n",
    "               [0., 1., 0., 0., 0.],\n",
    "               [0., 0., 0., 0., 1.],\n",
    "               [0., 0., 1., 0., 0.],\n",
    "               [1., 0., 0., 0., 0.]]\n",
    "    '''\n",
    "    n = len(labels)\n",
    "    labels_one_hot = np.zeros((n, num_classes))\n",
    "    labels_one_hot[range(n), labels] = 1\n",
    "    return labels_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:40:17.443685Z",
     "start_time": "2019-02-18T20:39:10.124834Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# open a session for the created graph\n",
    "with tf.Session() as sess:\n",
    "    # initializing variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # add graph to event files (in order to visualize it later)\n",
    "    train_writer.add_graph(sess.graph)\n",
    "    test_writer.add_graph(sess.graph)\n",
    "    \n",
    "    # get test labels in one-hot format\n",
    "    y_test_all_one_hot = one_hot(PD_RNN1.get_y_test(), num_classes)\n",
    "    \n",
    "    # get sequence tensor for testing and corresponding sequence lengths\n",
    "    X_test_all = PD_RNN1.get_X_test()\n",
    "    seqlens_test_all = PD_RNN1.get_seqlens_test()\n",
    "    \n",
    "    # train the RNN with a defined number of steps\n",
    "    for step in range(num_steps):\n",
    "        # get batch data\n",
    "        x_batch, y_batch, seqlens_batch = PD_RNN1.get_train_batch(batch_size)\n",
    "        \n",
    "        # get batch labels in one-hot format\n",
    "        y_batch_one_hot = one_hot(y_batch, num_classes)\n",
    "        \n",
    "        # run the session\n",
    "        sess.run(train_step, feed_dict={inputs:x_batch, labels:y_batch_one_hot, seqlens:seqlens_batch})\n",
    "        \n",
    "        # evaluate the RNN every 50 steps\n",
    "        if step % 50 == 0:\n",
    "            # get summary and accuracy of train batch\n",
    "            summary_train, accuracy_train = sess.run([merged, accuracy], \n",
    "                                                      feed_dict={inputs:x_batch, \n",
    "                                                                 labels:y_batch_one_hot, \n",
    "                                                                 seqlens:seqlens_batch})\n",
    "            print('Accuracy at step {}'.format(step))\n",
    "            print('\\tTrain Set: {:.3f}'.format(accuracy_train))\n",
    "            \n",
    "            # write to train summary\n",
    "            train_writer.add_summary(summary_train, step)\n",
    "            \n",
    "            # get summary, predicted probabilities, predicted classes and accuracy of test data\n",
    "            summary_test, pred_prob_test, pred_prob_test_all, pred_test, accuracy_test = sess.run([merged, pred_prob,\n",
    "                                                        pred_prob_all_states, tf.argmax(final_output,1), accuracy],\n",
    "                                                        feed_dict={inputs:X_test_all, \n",
    "                                                                   labels:y_test_all_one_hot, \n",
    "                                                                   seqlens:seqlens_test_all})\n",
    "            # write to test summary\n",
    "            test_writer.add_summary(summary_test, step)\n",
    "    \n",
    "            print('\\tTest Set:  {:.3f}'.format(accuracy_test))\n",
    "    \n",
    "    \n",
    "    outputs_RNN = sess.run(outputs, feed_dict={inputs:X_test_all, labels:y_test_all_one_hot, seqlens:seqlens_test_all})\n",
    "    \n",
    "    # Create a saver\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, 'E:/TensorFlow_saved_models/final-RNN-model/RNN-model-1')\n",
    "    \n",
    "    # Generate MetaGraphDef\n",
    "    saver.export_meta_graph('E:/TensorFlow_saved_models/final-RNN-model/RNN-model-1.meta')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:40:17.471686Z",
     "start_time": "2019-02-18T20:40:17.455686Z"
    }
   },
   "outputs": [],
   "source": [
    "np.shape(outputs_RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:44:06.318776Z",
     "start_time": "2019-02-18T20:44:06.162767Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise\tPrecision [%]\tRecall [%]\tAccuracy [%]\n",
      "  RF\t\t   82.86\t   96.67\t   99.01\n",
      "  RO\t\t   92.59\t   83.33\t   99.01\n",
      "  RS\t\t  100.00\t   93.33\t   99.72\n",
      "  LR\t\t  100.00\t  100.00\t  100.00\n",
      "  BC\t\t  100.00\t  100.00\t  100.00\n",
      "  TC\t\t   96.77\t  100.00\t   99.86\n",
      "  MP\t\t   93.75\t  100.00\t   99.72\n",
      "  SA\t\t  100.00\t  100.00\t  100.00\n",
      "  P1\t\t   90.62\t   96.67\t   99.44\n",
      "  P2\t\t   93.75\t  100.00\t   99.72\n",
      "  NE\t\t   99.50\t   97.79\t   98.45\n"
     ]
    }
   ],
   "source": [
    "print_precision_recall_accuracy(pred_test, PD_RNN1.get_y_test())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T22:24:02.435734Z",
     "start_time": "2019-02-18T22:24:02.211721Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BC</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MP</th>\n",
       "      <td>0.937500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NE</th>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.977887</td>\n",
       "      <td>0.986369</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P1</th>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.935484</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P2</th>\n",
       "      <td>0.937500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RO</th>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SA</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TC</th>\n",
       "      <td>0.967742</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.954408</td>\n",
       "      <td>0.970717</td>\n",
       "      <td>0.961451</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.974612</td>\n",
       "      <td>0.974612</td>\n",
       "      <td>0.974612</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.976121</td>\n",
       "      <td>0.974612</td>\n",
       "      <td>0.974810</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score  support\n",
       "BC             1.000000  1.000000  1.000000       31\n",
       "LR             1.000000  1.000000  1.000000       30\n",
       "MP             0.937500  1.000000  0.967742       30\n",
       "NE             0.995000  0.977887  0.986369      407\n",
       "P1             0.906250  0.966667  0.935484       30\n",
       "P2             0.937500  1.000000  0.967742       30\n",
       "RF             0.828571  0.966667  0.892308       30\n",
       "RO             0.925926  0.833333  0.877193       30\n",
       "RS             1.000000  0.933333  0.965517       30\n",
       "SA             1.000000  1.000000  1.000000       31\n",
       "TC             0.967742  1.000000  0.983607       30\n",
       "macro avg      0.954408  0.970717  0.961451      709\n",
       "micro avg      0.974612  0.974612  0.974612      709\n",
       "weighted avg   0.976121  0.974612  0.974810      709"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show precision, recall and f1-score\n",
    "classif_report = classification_report(PD_RNN1.get_y_test(), pred_test, \n",
    "    labels = np.arange(0, 11),\n",
    "    target_names = ['RF', 'RO', 'RS', 'LR', 'BC', 'TC', 'MP', 'SA', 'P1', 'P2', 'NE'],\n",
    "    sample_weight = None,\n",
    "    output_dict = True)\n",
    "pd.DataFrame.from_dict(classif_report, orient = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:44:06.620793Z",
     "start_time": "2019-02-18T20:44:06.376779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 misclassified (709 test data points):\n",
      "RF classified as RO\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RS classified as P2\n",
      "RS classified as NE\n",
      "P1 classified as NE\n",
      "NE classified as TC\n",
      "NE classified as P2\n",
      "NE classified as P1\n",
      "NE classified as RF\n",
      "NE classified as RO\n",
      "NE classified as P1\n",
      "NE classified as P1\n",
      "NE classified as MP\n",
      "NE classified as MP\n"
     ]
    }
   ],
   "source": [
    "print_misclassified_data_points(pred_test, PD_RNN1.get_y_test())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:44:06.782802Z",
     "start_time": "2019-02-18T20:44:06.676796Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(709, 11)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(pred_prob_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:44:06.969813Z",
     "start_time": "2019-02-18T20:44:06.841806Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17016, 11)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(pred_prob_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:44:07.140823Z",
     "start_time": "2019-02-18T20:44:07.028816Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "34032 / 709"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:44:07.281831Z",
     "start_time": "2019-02-18T20:44:07.197826Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.6037710e-02, 6.0660648e-05, 1.6245005e-05, 1.7639557e-05,\n",
       "       1.2099737e-07, 5.2310406e-06, 7.0970337e-04, 7.3563591e-02,\n",
       "       6.5415281e-01, 8.3113104e-01, 9.7561783e-01, 8.0313839e-02,\n",
       "       8.0313839e-02, 8.0313839e-02, 8.0313839e-02, 8.0313839e-02,\n",
       "       8.0313839e-02, 8.0313839e-02, 8.0313839e-02, 8.0313839e-02,\n",
       "       8.0313839e-02, 8.0313839e-02, 8.0313839e-02, 8.0313839e-02,\n",
       "       4.0511120e-02, 1.7232499e-03, 2.5641617e-05, 2.1873737e-05,\n",
       "       2.9725885e-05, 8.6014397e-06, 4.5884572e-04, 4.7438382e-03,\n",
       "       2.9501665e-01, 9.3175793e-01, 9.8652077e-01, 9.9435067e-01,\n",
       "       8.0313839e-02, 8.0313839e-02, 8.0313839e-02, 8.0313839e-02,\n",
       "       8.0313839e-02, 8.0313839e-02, 8.0313839e-02, 8.0313839e-02,\n",
       "       8.0313839e-02, 8.0313839e-02, 8.0313839e-02, 8.0313839e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob_test_all[0:48,0] # first 48 rows belong to the first data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:44:07.454841Z",
     "start_time": "2019-02-18T20:44:07.341834Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PD_RNN1.get_seqlens_test()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:44:07.604849Z",
     "start_time": "2019-02-18T20:44:07.511844Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9756178"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob_test_all[PD_RNN1.get_seqlens_test()[0]-1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:44:07.761858Z",
     "start_time": "2019-02-18T20:44:07.660853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9756178"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob_test[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:44:07.936868Z",
     "start_time": "2019-02-18T20:44:07.825862Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:44:10.750029Z",
     "start_time": "2019-02-18T20:44:08.005872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted probabilities [%] for the different exercises:\n",
      "\n",
      "Ex. 0\tEx. 1\tEx. 2\tEx. 3\tEx. 4\tEx. 5\tEx. 6\tEx. 7\tEx. 8\tEx. 9\tEx. 10\tpred. class\n",
      "97.56\t2.43\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t--> 0\n",
      "99.44\t0.54\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t--> 0\n",
      "97.89\t2.05\t0.02\t0.00\t0.01\t0.00\t0.00\t0.01\t0.00\t0.01\t0.01\t--> 0\n",
      "98.98\t0.98\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.02\t--> 0\n",
      "72.64\t27.05\t0.02\t0.01\t0.05\t0.00\t0.00\t0.07\t0.00\t0.04\t0.11\t--> 0\n",
      "96.14\t3.83\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.00\t0.01\t0.00\t--> 0\n",
      "64.95\t33.28\t0.10\t0.02\t0.05\t0.00\t0.00\t0.09\t0.00\t1.13\t0.37\t--> 0\n",
      "99.73\t0.27\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t--> 0\n",
      "98.92\t1.06\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t--> 0\n",
      "99.17\t0.82\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t--> 0\n",
      "91.47\t8.19\t0.01\t0.01\t0.01\t0.00\t0.00\t0.03\t0.00\t0.07\t0.19\t--> 0\n",
      "99.80\t0.20\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t--> 0\n",
      "99.08\t0.85\t0.00\t0.00\t0.01\t0.00\t0.00\t0.02\t0.00\t0.00\t0.04\t--> 0\n",
      "99.31\t0.66\t0.00\t0.00\t0.01\t0.00\t0.00\t0.01\t0.00\t0.00\t0.02\t--> 0\n",
      "97.84\t2.04\t0.00\t0.00\t0.02\t0.00\t0.00\t0.01\t0.00\t0.01\t0.08\t--> 0\n",
      "96.12\t3.84\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t0.00\t0.03\t0.00\t--> 0\n",
      "98.20\t1.79\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t--> 0\n",
      "99.89\t0.11\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t--> 0\n",
      "99.18\t0.82\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t--> 0\n",
      "95.68\t4.27\t0.00\t0.01\t0.00\t0.00\t0.00\t0.01\t0.00\t0.00\t0.03\t--> 0\n",
      "98.18\t1.77\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.04\t--> 0\n",
      "98.53\t1.44\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t--> 0\n",
      "93.61\t6.18\t0.01\t0.01\t0.01\t0.00\t0.00\t0.02\t0.00\t0.02\t0.14\t--> 0\n",
      "98.62\t1.31\t0.00\t0.00\t0.01\t0.00\t0.00\t0.01\t0.00\t0.00\t0.05\t--> 0\n",
      "97.48\t2.11\t0.01\t0.01\t0.02\t0.00\t0.00\t0.03\t0.00\t0.03\t0.31\t--> 0\n",
      "99.30\t0.68\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t--> 0\n",
      "90.59\t9.20\t0.02\t0.01\t0.02\t0.00\t0.00\t0.02\t0.00\t0.02\t0.14\t--> 0\n",
      "47.50\t52.24\t0.01\t0.00\t0.03\t0.00\t0.00\t0.03\t0.00\t0.07\t0.12\t--> 1\n",
      "97.73\t2.25\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.00\t--> 0\n",
      "97.48\t2.50\t0.00\t0.01\t0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t--> 0\n",
      "95.91\t4.00\t0.00\t0.00\t0.01\t0.00\t0.00\t0.03\t0.00\t0.02\t0.03\t--> 0\n",
      "35.48\t64.44\t0.00\t0.01\t0.02\t0.00\t0.00\t0.01\t0.00\t0.03\t0.01\t--> 1\n",
      "21.46\t77.80\t0.02\t0.00\t0.04\t0.00\t0.00\t0.08\t0.00\t0.48\t0.12\t--> 1\n",
      "0.55\t99.38\t0.00\t0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t0.03\t0.02\t--> 1\n",
      "48.76\t51.06\t0.01\t0.00\t0.01\t0.00\t0.00\t0.02\t0.00\t0.07\t0.06\t--> 1\n",
      "96.55\t3.41\t0.00\t0.00\t0.02\t0.00\t0.00\t0.00\t0.00\t0.01\t0.00\t--> 0\n",
      "43.07\t56.18\t0.02\t0.01\t0.08\t0.00\t0.00\t0.19\t0.00\t0.37\t0.09\t--> 1\n",
      "85.87\t14.00\t0.02\t0.00\t0.02\t0.00\t0.00\t0.03\t0.00\t0.01\t0.06\t--> 0\n",
      "4.98\t94.94\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.00\t0.03\t0.03\t--> 1\n",
      "1.67\t98.28\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.02\t--> 1\n",
      "33.88\t66.02\t0.01\t0.00\t0.02\t0.00\t0.00\t0.02\t0.00\t0.04\t0.02\t--> 1\n",
      "17.40\t81.73\t0.02\t0.00\t0.06\t0.00\t0.00\t0.18\t0.00\t0.41\t0.19\t--> 1\n",
      "2.54\t97.27\t0.07\t0.00\t0.00\t0.00\t0.00\t0.01\t0.00\t0.01\t0.08\t--> 1\n",
      "10.81\t88.87\t0.01\t0.01\t0.01\t0.00\t0.01\t0.02\t0.00\t0.02\t0.24\t--> 1\n",
      "4.30\t95.59\t0.00\t0.00\t0.01\t0.00\t0.00\t0.01\t0.00\t0.01\t0.08\t--> 1\n",
      "58.04\t40.81\t0.05\t0.01\t0.02\t0.00\t0.00\t0.06\t0.00\t0.85\t0.17\t--> 0\n",
      "43.83\t55.11\t0.02\t0.06\t0.06\t0.00\t0.02\t0.02\t0.00\t0.67\t0.19\t--> 1\n",
      "6.33\t90.91\t0.02\t0.03\t0.04\t0.00\t0.07\t0.09\t0.00\t2.17\t0.34\t--> 1\n",
      "0.68\t99.22\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.03\t0.06\t--> 1\n",
      "1.89\t97.96\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.00\t0.03\t0.10\t--> 1\n",
      "2.22\t96.58\t0.00\t0.01\t0.01\t0.00\t0.04\t0.05\t0.00\t1.06\t0.04\t--> 1\n",
      "4.49\t92.41\t0.00\t0.03\t0.00\t0.00\t0.03\t0.01\t0.00\t0.02\t2.99\t--> 1\n",
      "20.02\t79.89\t0.00\t0.00\t0.01\t0.00\t0.00\t0.02\t0.00\t0.02\t0.04\t--> 1\n",
      "8.46\t91.33\t0.00\t0.00\t0.01\t0.00\t0.00\t0.02\t0.00\t0.04\t0.13\t--> 1\n",
      "1.04\t82.57\t0.06\t0.02\t0.05\t0.00\t0.11\t0.15\t0.00\t15.13\t0.88\t--> 1\n",
      "54.03\t45.92\t0.00\t0.00\t0.01\t0.00\t0.00\t0.02\t0.00\t0.01\t0.01\t--> 0\n",
      "0.50\t99.33\t0.01\t0.00\t0.01\t0.00\t0.00\t0.00\t0.00\t0.14\t0.01\t--> 1\n",
      "6.53\t92.99\t0.00\t0.00\t0.02\t0.00\t0.00\t0.02\t0.00\t0.41\t0.03\t--> 1\n",
      "3.19\t96.59\t0.00\t0.00\t0.01\t0.00\t0.00\t0.03\t0.00\t0.07\t0.09\t--> 1\n",
      "0.39\t99.55\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.03\t--> 1\n",
      "0.00\t0.00\t99.98\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.00\t--> 2\n",
      "0.00\t0.00\t99.92\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.07\t0.00\t--> 2\n",
      "0.00\t0.00\t99.80\t0.02\t0.00\t0.00\t0.00\t0.00\t0.00\t0.18\t0.00\t--> 2\n",
      "0.00\t0.00\t99.87\t0.01\t0.00\t0.01\t0.00\t0.00\t0.00\t0.09\t0.02\t--> 2\n",
      "0.00\t0.00\t99.94\t0.03\t0.00\t0.00\t0.00\t0.00\t0.00\t0.03\t0.00\t--> 2\n",
      "0.00\t0.00\t99.93\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.05\t0.01\t--> 2\n",
      "0.00\t0.03\t73.68\t0.09\t0.00\t0.29\t0.00\t0.00\t0.00\t25.37\t0.54\t--> 2\n",
      "0.00\t0.00\t99.82\t0.12\t0.00\t0.01\t0.00\t0.00\t0.00\t0.05\t0.00\t--> 2\n",
      "0.03\t0.26\t72.35\t11.23\t0.00\t0.00\t0.01\t0.00\t0.04\t15.96\t0.11\t--> 2\n",
      "0.02\t0.08\t94.23\t4.68\t0.00\t0.03\t0.01\t0.00\t0.01\t0.87\t0.08\t--> 2\n",
      "0.04\t0.15\t87.74\t2.96\t0.00\t0.01\t0.01\t0.00\t0.01\t9.04\t0.05\t--> 2\n",
      "0.00\t0.00\t99.97\t0.01\t0.00\t0.01\t0.00\t0.00\t0.00\t0.02\t0.00\t--> 2\n",
      "0.00\t0.00\t99.49\t0.22\t0.00\t0.00\t0.00\t0.00\t0.00\t0.27\t0.00\t--> 2\n",
      "0.00\t0.00\t99.75\t0.18\t0.00\t0.01\t0.00\t0.00\t0.00\t0.06\t0.00\t--> 2\n",
      "0.00\t0.00\t99.93\t0.01\t0.00\t0.01\t0.00\t0.00\t0.00\t0.05\t0.00\t--> 2\n",
      "0.01\t0.01\t3.99\t0.02\t0.00\t0.00\t0.00\t0.00\t0.00\t95.96\t0.00\t--> 9\n",
      "0.00\t0.00\t99.80\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.18\t0.01\t--> 2\n",
      "0.00\t0.00\t88.21\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t11.77\t0.01\t--> 2\n",
      "0.00\t0.00\t99.94\t0.02\t0.00\t0.00\t0.00\t0.00\t0.00\t0.04\t0.00\t--> 2\n",
      "0.00\t0.01\t99.75\t0.02\t0.00\t0.00\t0.00\t0.00\t0.00\t0.12\t0.10\t--> 2\n",
      "0.00\t0.02\t98.68\t0.30\t0.00\t0.02\t0.00\t0.00\t0.00\t0.96\t0.01\t--> 2\n",
      "0.00\t0.02\t99.30\t0.04\t0.00\t0.02\t0.02\t0.00\t0.00\t0.31\t0.30\t--> 2\n",
      "0.00\t0.00\t97.57\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t2.42\t0.00\t--> 2\n",
      "0.00\t0.00\t99.95\t0.02\t0.00\t0.00\t0.00\t0.00\t0.00\t0.03\t0.00\t--> 2\n",
      "0.01\t0.06\t3.34\t47.33\t0.00\t0.03\t0.00\t0.00\t0.13\t1.20\t47.89\t--> 10\n",
      "0.00\t0.01\t97.07\t0.02\t0.00\t0.01\t0.00\t0.00\t0.00\t2.89\t0.01\t--> 2\n",
      "0.00\t0.00\t99.94\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.06\t0.00\t--> 2\n",
      "0.00\t0.00\t99.84\t0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t0.14\t0.01\t--> 2\n",
      "0.00\t0.00\t99.99\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.00\t--> 2\n",
      "0.00\t0.00\t99.99\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.00\t--> 2\n",
      "0.00\t0.00\t0.00\t100.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t--> 3\n",
      "0.00\t0.00\t0.00\t100.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t--> 3\n",
      "0.00\t0.00\t0.00\t99.99\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t--> 3\n",
      "0.00\t0.01\t0.20\t99.47\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.31\t--> 3\n",
      "0.00\t0.00\t0.01\t99.97\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.01\t--> 3\n",
      "0.00\t0.00\t0.02\t99.97\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t--> 3\n",
      "0.00\t0.00\t0.00\t99.98\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t--> 3\n",
      "0.00\t0.00\t0.01\t99.93\t0.00\t0.00\t0.00\t0.00\t0.00\t0.02\t0.03\t--> 3\n",
      "0.00\t0.00\t0.01\t99.97\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.01\t--> 3\n",
      "0.00\t0.01\t0.20\t99.61\t0.00\t0.00\t0.00\t0.00\t0.01\t0.13\t0.04\t--> 3\n",
      "0.00\t0.00\t0.01\t99.97\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.02\t--> 3\n",
      "0.00\t0.00\t0.01\t99.94\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.04\t--> 3\n",
      "0.00\t0.00\t0.00\t99.99\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t--> 3\n",
      "0.00\t0.01\t0.05\t99.56\t0.00\t0.00\t0.00\t0.00\t0.01\t0.15\t0.21\t--> 3\n",
      "0.00\t0.00\t0.23\t99.64\t0.00\t0.00\t0.00\t0.00\t0.00\t0.03\t0.10\t--> 3\n",
      "0.00\t0.00\t0.00\t99.99\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t--> 3\n",
      "0.00\t0.00\t0.00\t100.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t--> 3\n",
      "0.00\t0.00\t0.05\t99.92\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.02\t--> 3\n",
      "0.00\t0.00\t0.00\t100.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t--> 3\n",
      "0.00\t0.00\t0.00\t99.99\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t--> 3\n",
      "0.00\t0.00\t0.03\t99.96\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t--> 3\n",
      "0.00\t0.00\t0.01\t99.99\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t--> 3\n",
      "0.00\t0.00\t0.00\t100.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t--> 3\n",
      "0.00\t0.00\t0.00\t100.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t--> 3\n",
      "0.00\t0.00\t0.00\t99.99\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t--> 3\n",
      "0.00\t0.00\t0.00\t99.99\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t--> 3\n",
      "0.00\t0.00\t0.00\t99.99\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t--> 3\n",
      "0.00\t0.00\t0.05\t99.89\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.04\t--> 3\n",
      "0.00\t0.00\t0.02\t99.95\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.02\t--> 3\n",
      "0.00\t0.00\t0.00\t100.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t--> 3\n",
      "0.01\t0.00\t0.00\t0.00\t99.99\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t--> 4\n",
      "0.01\t0.00\t0.00\t0.00\t99.99\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t--> 4\n",
      "0.01\t0.00\t0.00\t0.00\t99.97\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t--> 4\n",
      "0.01\t0.00\t0.00\t0.00\t99.97\t0.00\t0.00\t0.02\t0.00\t0.00\t0.00\t--> 4\n",
      "0.00\t0.00\t0.00\t0.00\t99.98\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t--> 4\n",
      "0.01\t0.00\t0.00\t0.00\t99.99\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t--> 4\n",
      "0.01\t0.00\t0.00\t0.00\t99.98\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t--> 4\n",
      "0.01\t0.00\t0.00\t0.00\t99.96\t0.00\t0.00\t0.03\t0.00\t0.00\t0.00\t--> 4\n",
      "0.01\t0.00\t0.00\t0.00\t99.98\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t--> 4\n",
      "0.01\t0.00\t0.00\t0.00\t99.99\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t--> 4\n",
      "0.01\t0.00\t0.00\t0.00\t99.99\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t--> 4\n",
      "0.01\t0.00\t0.00\t0.00\t99.99\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t--> 4\n",
      "0.01\t0.00\t0.00\t0.00\t99.99\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t--> 4\n",
      "0.01\t0.00\t0.00\t0.00\t99.97\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t--> 4\n",
      "0.01\t0.00\t0.00\t0.00\t99.98\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t--> 4\n",
      "0.01\t0.00\t0.00\t0.00\t99.97\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t--> 4\n",
      "0.01\t0.00\t0.00\t0.00\t99.96\t0.00\t0.00\t0.03\t0.00\t0.00\t0.00\t--> 4\n",
      "0.01\t0.00\t0.00\t0.00\t99.98\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t--> 4\n",
      "0.01\t0.00\t0.00\t0.00\t99.97\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t--> 4\n",
      "0.02\t0.00\t0.00\t0.00\t99.97\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t--> 4\n",
      "0.01\t0.00\t0.00\t0.00\t99.97\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t--> 4\n",
      "0.01\t0.00\t0.00\t0.00\t99.98\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t--> 4\n",
      "0.03\t0.01\t0.00\t0.00\t99.89\t0.02\t0.00\t0.04\t0.01\t0.00\t0.00\t--> 4\n",
      "0.01\t0.00\t0.00\t0.00\t99.98\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t--> 4\n",
      "0.01\t0.00\t0.00\t0.00\t99.94\t0.00\t0.00\t0.05\t0.00\t0.00\t0.00\t--> 4\n",
      "0.01\t0.00\t0.00\t0.00\t99.98\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t--> 4\n",
      "0.00\t0.00\t0.00\t0.00\t99.99\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t--> 4\n",
      "0.01\t0.00\t0.00\t0.00\t99.99\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t--> 4\n",
      "0.01\t0.00\t0.00\t0.00\t99.98\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t--> 4\n",
      "0.05\t0.00\t0.00\t0.00\t99.91\t0.01\t0.00\t0.03\t0.00\t0.00\t0.00\t--> 4\n",
      "0.01\t0.00\t0.00\t0.00\t99.98\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t--> 4\n",
      "0.00\t0.00\t0.10\t0.01\t0.01\t98.25\t0.07\t0.01\t0.27\t0.00\t1.28\t--> 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00\t0.00\t0.01\t0.00\t0.00\t99.96\t0.01\t0.00\t0.00\t0.00\t0.02\t--> 5\n",
      "0.00\t0.00\t0.01\t0.00\t0.00\t99.82\t0.01\t0.00\t0.00\t0.00\t0.16\t--> 5\n",
      "0.00\t0.00\t0.01\t0.00\t0.00\t99.87\t0.06\t0.00\t0.00\t0.00\t0.05\t--> 5\n",
      "0.00\t0.00\t0.03\t0.00\t0.00\t99.86\t0.01\t0.00\t0.00\t0.00\t0.10\t--> 5\n",
      "0.00\t0.00\t0.01\t0.00\t0.00\t99.69\t0.01\t0.00\t0.00\t0.00\t0.28\t--> 5\n",
      "0.00\t0.00\t0.25\t0.04\t0.12\t91.33\t0.38\t0.08\t1.42\t0.01\t6.37\t--> 5\n",
      "0.00\t0.00\t0.25\t0.09\t0.15\t86.87\t0.70\t0.12\t4.87\t0.01\t6.93\t--> 5\n",
      "0.00\t0.00\t0.02\t0.00\t0.00\t99.92\t0.01\t0.00\t0.01\t0.00\t0.04\t--> 5\n",
      "0.00\t0.00\t0.28\t0.02\t0.13\t93.08\t0.59\t0.06\t0.76\t0.01\t5.07\t--> 5\n",
      "0.00\t0.00\t0.02\t0.00\t0.00\t99.74\t0.02\t0.00\t0.03\t0.00\t0.17\t--> 5\n",
      "0.00\t0.00\t0.01\t0.00\t0.00\t98.53\t0.62\t0.03\t0.02\t0.00\t0.79\t--> 5\n",
      "0.00\t0.00\t0.02\t0.00\t0.01\t99.74\t0.10\t0.00\t0.02\t0.00\t0.11\t--> 5\n",
      "0.00\t0.00\t0.01\t0.00\t0.00\t99.93\t0.01\t0.00\t0.01\t0.00\t0.05\t--> 5\n",
      "0.00\t0.00\t0.01\t0.00\t0.00\t99.96\t0.01\t0.00\t0.01\t0.00\t0.02\t--> 5\n",
      "0.00\t0.00\t0.01\t0.00\t0.00\t99.78\t0.01\t0.00\t0.00\t0.00\t0.19\t--> 5\n",
      "0.01\t0.00\t0.52\t0.02\t0.06\t74.02\t0.31\t0.06\t1.41\t0.00\t23.59\t--> 5\n",
      "0.00\t0.00\t0.01\t0.00\t0.00\t99.97\t0.01\t0.00\t0.00\t0.00\t0.02\t--> 5\n",
      "0.00\t0.00\t0.01\t0.00\t0.00\t99.83\t0.02\t0.00\t0.02\t0.00\t0.12\t--> 5\n",
      "0.00\t0.00\t0.25\t0.00\t0.13\t95.89\t0.11\t0.02\t0.41\t0.00\t3.19\t--> 5\n",
      "0.00\t0.00\t0.05\t0.00\t0.00\t99.65\t0.02\t0.01\t0.04\t0.00\t0.22\t--> 5\n",
      "0.00\t0.00\t0.03\t0.00\t0.02\t99.33\t0.09\t0.01\t0.06\t0.00\t0.46\t--> 5\n",
      "0.00\t0.00\t0.06\t0.00\t0.03\t99.10\t0.36\t0.02\t0.14\t0.00\t0.28\t--> 5\n",
      "0.00\t0.00\t0.02\t0.00\t0.00\t99.83\t0.05\t0.00\t0.02\t0.00\t0.07\t--> 5\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t99.93\t0.03\t0.00\t0.01\t0.00\t0.02\t--> 5\n",
      "0.00\t0.00\t0.01\t0.00\t0.00\t99.86\t0.05\t0.00\t0.01\t0.00\t0.06\t--> 5\n",
      "0.00\t0.00\t0.01\t0.00\t0.00\t99.96\t0.00\t0.00\t0.00\t0.00\t0.03\t--> 5\n",
      "0.04\t0.00\t0.02\t0.02\t0.01\t93.43\t0.88\t0.24\t0.55\t0.00\t4.81\t--> 5\n",
      "0.00\t0.00\t0.01\t0.00\t0.00\t99.93\t0.01\t0.00\t0.01\t0.00\t0.04\t--> 5\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t99.85\t0.06\t0.00\t0.00\t0.00\t0.08\t--> 5\n",
      "0.00\t0.02\t0.00\t0.01\t0.00\t0.00\t96.52\t0.01\t0.00\t0.02\t3.42\t--> 6\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t99.98\t0.01\t0.00\t0.00\t0.00\t--> 6\n",
      "0.00\t0.01\t0.00\t0.02\t0.00\t0.02\t99.42\t0.15\t0.00\t0.03\t0.35\t--> 6\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.23\t99.45\t0.03\t0.00\t0.02\t0.26\t--> 6\n",
      "0.00\t0.02\t0.00\t0.02\t0.00\t0.00\t89.65\t0.03\t0.00\t0.00\t10.27\t--> 6\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t3.50\t96.47\t0.01\t0.00\t0.00\t0.02\t--> 6\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t99.98\t0.00\t0.00\t0.00\t0.00\t--> 6\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t0.01\t0.00\t0.00\t0.00\t--> 6\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.02\t99.57\t0.08\t0.02\t0.00\t0.31\t--> 6\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.93\t0.01\t0.00\t0.01\t0.05\t--> 6\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t0.00\t0.00\t0.00\t0.00\t--> 6\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.98\t0.00\t0.00\t0.00\t0.02\t--> 6\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.98\t0.00\t0.00\t0.01\t0.00\t--> 6\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.97\t0.00\t0.00\t0.00\t0.03\t--> 6\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.03\t99.83\t0.08\t0.01\t0.02\t0.03\t--> 6\n",
      "0.00\t0.00\t0.00\t0.02\t0.00\t0.00\t95.49\t0.00\t0.00\t0.03\t4.46\t--> 6\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t99.98\t0.00\t0.00\t0.00\t0.00\t--> 6\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.11\t99.85\t0.01\t0.01\t0.00\t0.01\t--> 6\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.21\t99.41\t0.01\t0.00\t0.00\t0.37\t--> 6\n",
      "0.00\t0.00\t0.00\t0.01\t0.00\t0.02\t88.75\t0.19\t0.01\t0.01\t11.02\t--> 6\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.02\t99.87\t0.10\t0.01\t0.00\t0.01\t--> 6\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.98\t0.00\t0.00\t0.01\t0.01\t--> 6\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t0.00\t0.00\t0.00\t0.00\t--> 6\n",
      "0.00\t0.01\t0.00\t0.01\t0.00\t0.00\t99.11\t0.06\t0.00\t0.80\t0.01\t--> 6\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t93.62\t0.10\t0.00\t0.06\t6.21\t--> 6\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.11\t99.80\t0.02\t0.02\t0.01\t0.04\t--> 6\n",
      "0.00\t0.01\t0.00\t0.04\t0.00\t0.05\t99.31\t0.38\t0.00\t0.10\t0.11\t--> 6\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.10\t99.89\t0.00\t0.00\t0.00\t0.00\t--> 6\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t0.00\t0.00\t0.00\t0.00\t--> 6\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.02\t99.97\t0.00\t0.00\t0.00\t0.00\t--> 6\n",
      "0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t0.02\t99.95\t0.00\t0.00\t0.02\t--> 7\n",
      "0.00\t0.00\t0.00\t0.00\t0.01\t0.00\t0.03\t99.95\t0.00\t0.00\t0.01\t--> 7\n",
      "0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t99.98\t0.00\t0.00\t0.00\t--> 7\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t0.00\t0.00\t0.00\t--> 7\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t0.00\t0.00\t0.00\t--> 7\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t0.00\t0.00\t0.00\t--> 7\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t0.00\t0.00\t0.00\t--> 7\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t99.98\t0.01\t0.00\t0.00\t--> 7\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t0.00\t0.00\t0.01\t--> 7\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t0.00\t0.00\t0.00\t--> 7\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t0.00\t0.00\t0.00\t--> 7\n",
      "0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.98\t0.00\t0.00\t0.01\t--> 7\n",
      "0.01\t0.00\t0.00\t0.00\t0.01\t0.00\t0.04\t99.83\t0.00\t0.00\t0.11\t--> 7\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.05\t99.92\t0.00\t0.00\t0.02\t--> 7\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t0.00\t0.00\t0.01\t--> 7\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t0.00\t0.00\t0.00\t--> 7\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t99.99\t0.00\t0.00\t0.00\t--> 7\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t0.00\t0.00\t0.00\t--> 7\n",
      "0.00\t0.00\t0.00\t0.00\t0.01\t0.00\t0.01\t99.98\t0.00\t0.00\t0.00\t--> 7\n",
      "0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.98\t0.00\t0.00\t0.00\t--> 7\n",
      "0.01\t0.00\t0.00\t0.00\t0.01\t0.00\t0.07\t99.85\t0.00\t0.00\t0.06\t--> 7\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t0.00\t0.00\t0.00\t--> 7\n",
      "0.01\t0.00\t0.00\t0.00\t0.02\t0.00\t0.01\t99.92\t0.01\t0.00\t0.03\t--> 7\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t99.98\t0.00\t0.00\t0.01\t--> 7\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t0.00\t0.00\t0.01\t--> 7\n",
      "1.39\t0.15\t0.00\t0.00\t16.88\t0.07\t0.09\t80.03\t0.04\t0.08\t1.28\t--> 7\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t0.00\t0.00\t0.00\t--> 7\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t99.98\t0.01\t0.00\t0.00\t--> 7\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.98\t0.01\t0.00\t0.01\t--> 7\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t0.00\t0.00\t0.00\t--> 7\n",
      "0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t0.00\t0.00\t0.00\t--> 7\n",
      "0.00\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t0.00\t99.98\t0.00\t0.02\t--> 8\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.97\t0.00\t0.02\t--> 8\n",
      "0.00\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t0.00\t99.82\t0.00\t0.16\t--> 8\n",
      "0.00\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t0.00\t99.92\t0.00\t0.07\t--> 8\n",
      "0.00\t0.00\t0.00\t0.24\t0.00\t0.00\t0.00\t0.00\t82.05\t0.00\t17.71\t--> 8\n",
      "0.00\t0.00\t0.00\t0.25\t0.00\t0.04\t0.00\t0.00\t99.58\t0.00\t0.13\t--> 8\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t0.00\t0.01\t--> 8\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t0.00\t0.00\t--> 8\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t0.00\t0.00\t--> 8\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t0.00\t0.01\t--> 8\n",
      "0.00\t0.00\t0.00\t0.27\t0.00\t0.00\t0.00\t0.00\t99.65\t0.00\t0.07\t--> 8\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t0.00\t0.00\t--> 8\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t0.00\t0.01\t--> 8\n",
      "0.00\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t0.00\t99.97\t0.00\t0.02\t--> 8\n",
      "0.00\t0.00\t0.00\t0.08\t0.00\t0.00\t0.00\t0.00\t98.27\t0.00\t1.65\t--> 8\n",
      "0.00\t0.00\t0.00\t0.41\t0.00\t0.00\t0.00\t0.00\t47.32\t0.00\t52.27\t--> 10\n",
      "0.00\t0.00\t0.00\t0.21\t0.00\t0.00\t0.00\t0.00\t98.87\t0.00\t0.92\t--> 8\n",
      "0.00\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t0.00\t99.93\t0.00\t0.06\t--> 8\n",
      "0.00\t0.00\t0.00\t0.22\t0.00\t0.00\t0.00\t0.00\t98.97\t0.00\t0.81\t--> 8\n",
      "0.00\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t0.00\t99.63\t0.00\t0.36\t--> 8\n",
      "0.00\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t0.00\t99.73\t0.00\t0.25\t--> 8\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t0.00\t0.01\t--> 8\n",
      "0.00\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t0.00\t99.97\t0.00\t0.02\t--> 8\n",
      "0.00\t0.00\t0.00\t0.02\t0.00\t0.00\t0.00\t0.00\t99.95\t0.00\t0.02\t--> 8\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.98\t0.00\t0.02\t--> 8\n",
      "0.00\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t0.00\t99.95\t0.00\t0.03\t--> 8\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t0.00\t0.01\t--> 8\n",
      "0.00\t0.00\t0.00\t1.08\t0.00\t0.00\t0.00\t0.00\t98.52\t0.00\t0.39\t--> 8\n",
      "0.00\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t0.00\t99.97\t0.00\t0.01\t--> 8\n",
      "0.00\t0.00\t0.00\t0.03\t0.00\t0.00\t0.00\t0.00\t99.75\t0.00\t0.22\t--> 8\n",
      "0.00\t0.00\t0.03\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.97\t0.00\t--> 9\n",
      "0.00\t0.08\t0.08\t0.25\t0.00\t0.00\t0.07\t0.00\t0.00\t99.43\t0.07\t--> 9\n",
      "0.04\t0.04\t0.01\t0.47\t0.00\t0.00\t0.01\t0.00\t0.00\t95.13\t4.30\t--> 9\n",
      "0.01\t0.02\t0.01\t0.16\t0.00\t0.00\t0.01\t0.00\t0.01\t99.74\t0.04\t--> 9\n",
      "0.00\t0.00\t0.29\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.68\t0.02\t--> 9\n",
      "0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.98\t0.00\t--> 9\n",
      "0.00\t0.00\t0.04\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.94\t0.01\t--> 9\n",
      "0.00\t0.07\t0.31\t0.24\t0.00\t0.00\t0.04\t0.00\t0.00\t99.31\t0.01\t--> 9\n",
      "0.02\t0.11\t8.93\t0.02\t0.00\t0.02\t0.04\t0.00\t0.00\t90.80\t0.05\t--> 9\n",
      "0.08\t0.38\t0.43\t7.73\t0.00\t0.03\t0.34\t0.00\t0.01\t89.39\t1.61\t--> 9\n",
      "0.01\t0.08\t0.70\t0.01\t0.00\t0.02\t0.07\t0.00\t0.00\t98.99\t0.11\t--> 9\n",
      "0.00\t0.02\t8.91\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t91.05\t0.00\t--> 9\n",
      "0.01\t0.01\t0.10\t0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t99.87\t0.00\t--> 9\n",
      "0.04\t0.20\t32.99\t0.09\t0.00\t0.03\t0.07\t0.00\t0.00\t66.37\t0.20\t--> 9\n",
      "0.00\t0.01\t0.09\t0.23\t0.00\t0.00\t0.00\t0.00\t0.00\t99.39\t0.28\t--> 9\n",
      "0.00\t0.02\t0.00\t0.73\t0.00\t0.00\t0.05\t0.00\t0.00\t98.97\t0.22\t--> 9\n",
      "0.00\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t99.98\t0.00\t--> 9\n",
      "0.02\t0.06\t0.22\t0.06\t0.00\t0.00\t0.06\t0.00\t0.00\t99.13\t0.44\t--> 9\n",
      "0.00\t0.02\t0.05\t0.01\t0.00\t0.01\t0.09\t0.00\t0.00\t99.14\t0.68\t--> 9\n",
      "0.01\t0.02\t0.01\t0.01\t0.00\t0.00\t0.04\t0.00\t0.00\t99.54\t0.35\t--> 9\n",
      "0.00\t0.01\t0.02\t0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t99.95\t0.00\t--> 9\n",
      "0.00\t0.00\t0.01\t0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t99.98\t0.00\t--> 9\n",
      "0.00\t0.04\t0.09\t0.02\t0.00\t0.00\t0.02\t0.00\t0.00\t99.78\t0.04\t--> 9\n",
      "0.00\t0.03\t0.64\t0.01\t0.00\t0.00\t0.01\t0.00\t0.00\t99.30\t0.01\t--> 9\n",
      "0.00\t0.03\t0.02\t0.09\t0.00\t0.00\t0.04\t0.00\t0.00\t99.80\t0.02\t--> 9\n",
      "0.01\t0.07\t0.17\t0.08\t0.00\t0.00\t0.10\t0.00\t0.00\t99.44\t0.12\t--> 9\n",
      "0.01\t0.09\t1.63\t0.02\t0.00\t0.04\t0.22\t0.00\t0.00\t97.40\t0.60\t--> 9\n",
      "0.02\t0.06\t0.05\t0.90\t0.00\t0.00\t0.03\t0.00\t0.00\t98.89\t0.05\t--> 9\n",
      "0.01\t0.13\t1.23\t0.12\t0.00\t0.01\t0.11\t0.00\t0.00\t98.11\t0.28\t--> 9\n",
      "0.02\t0.06\t2.16\t0.02\t0.00\t0.00\t0.01\t0.00\t0.00\t97.69\t0.03\t--> 9\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.01\t0.00\t0.00\t0.00\t0.00\t0.22\t0.00\t0.00\t0.00\t99.77\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t0.00\t11.28\t0.00\t88.71\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.61\t1.97\t0.11\t0.00\t97.30\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.98\t--> 10\n",
      "0.01\t0.02\t0.00\t0.03\t0.00\t0.01\t0.00\t0.02\t0.09\t0.00\t99.81\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.03\t0.00\t0.01\t0.59\t0.01\t0.01\t0.29\t0.00\t99.06\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.15\t0.02\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.00\t0.04\t99.77\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.04\t0.01\t99.94\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.04\t0.00\t0.01\t0.67\t0.02\t0.00\t1.84\t0.00\t97.42\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.03\t0.00\t0.00\t99.97\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.98\t--> 10\n",
      "0.01\t0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.02\t99.95\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t--> 10\n",
      "0.00\t0.00\t0.00\t0.03\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.96\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.00\t99.99\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.02\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.00\t0.00\t99.97\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.01\t0.03\t0.25\t0.13\t0.95\t60.14\t0.24\t0.28\t28.68\t0.00\t9.27\t--> 5\n",
      "0.10\t0.07\t0.40\t0.03\t0.01\t0.01\t0.08\t0.03\t0.00\t99.11\t0.15\t--> 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.02\t0.00\t0.00\t0.00\t0.00\t96.58\t0.00\t3.39\t--> 8\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.04\t0.02\t0.00\t0.08\t0.00\t0.01\t0.03\t0.16\t0.12\t0.00\t99.54\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.00\t99.99\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.02\t0.00\t99.98\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t--> 10\n",
      "0.42\t0.40\t0.00\t0.11\t0.00\t0.00\t0.01\t0.01\t0.02\t0.06\t98.97\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t0.00\t0.02\t0.00\t99.97\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.02\t0.02\t0.00\t0.00\t99.95\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.02\t99.96\t--> 10\n",
      "0.04\t0.02\t0.00\t0.01\t0.01\t0.00\t0.08\t0.04\t0.00\t0.03\t99.76\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.02\t0.00\t0.00\t0.00\t0.00\t0.01\t0.01\t0.00\t0.03\t99.92\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.98\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t--> 10\n",
      "0.01\t0.01\t0.00\t0.01\t0.01\t0.01\t0.00\t0.01\t0.21\t0.00\t99.73\t--> 10\n",
      "1.32\t0.08\t0.01\t0.00\t0.49\t40.00\t1.65\t5.43\t0.00\t0.01\t51.00\t--> 10\n",
      "0.40\t0.09\t0.00\t0.00\t0.00\t0.00\t0.01\t0.06\t0.00\t0.00\t99.43\t--> 10\n",
      "0.79\t0.23\t0.00\t0.00\t0.00\t0.00\t0.00\t0.02\t0.00\t0.06\t98.89\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.02\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.98\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "1.29\t0.27\t0.01\t0.37\t0.24\t0.91\t13.56\t13.84\t0.45\t5.33\t63.73\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t99.98\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.18\t99.82\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.02\t0.07\t0.13\t0.17\t0.03\t0.05\t0.04\t0.02\t0.03\t0.15\t99.30\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "6.46\t3.97\t0.09\t0.01\t0.12\t0.01\t0.06\t0.72\t0.02\t2.89\t85.66\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.00\t99.98\t--> 10\n",
      "0.00\t0.00\t0.00\t0.01\t0.00\t0.00\t0.09\t0.00\t0.00\t0.02\t99.88\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.01\t0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.98\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.01\t0.02\t0.00\t0.01\t0.00\t0.00\t0.01\t0.33\t0.33\t0.00\t99.29\t--> 10\n",
      "0.02\t0.04\t0.00\t4.47\t0.01\t0.09\t0.08\t0.01\t0.04\t0.20\t95.05\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.02\t0.00\t0.00\t0.00\t0.00\t0.05\t0.00\t99.92\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t99.98\t--> 10\n",
      "0.00\t0.00\t0.00\t0.18\t0.00\t0.00\t0.00\t0.00\t0.00\t0.02\t99.79\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.01\t0.00\t0.01\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t99.97\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "3.72\t2.08\t0.02\t0.12\t0.16\t0.01\t0.37\t0.27\t0.00\t5.15\t88.11\t--> 10\n",
      "0.12\t0.04\t0.00\t0.07\t0.04\t0.06\t0.20\t0.13\t0.02\t0.12\t99.20\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.00\t0.00\t99.99\t--> 10\n",
      "0.06\t0.02\t0.00\t0.01\t0.02\t0.00\t0.02\t2.04\t1.32\t0.00\t96.52\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t0.00\t99.99\t--> 10\n",
      "0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.01\t0.00\t0.01\t0.10\t0.01\t0.00\t0.02\t0.01\t99.84\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.02\t0.00\t0.01\t99.95\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.00\t0.00\t0.01\t0.00\t99.97\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.02\t0.01\t0.01\t0.51\t99.45\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.02\t0.00\t0.00\t99.96\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.05\t0.00\t99.94\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.98\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.01\t0.00\t0.01\t0.04\t0.00\t0.00\t0.01\t0.00\t99.93\t--> 10\n",
      "0.01\t0.00\t0.00\t0.03\t0.00\t0.00\t0.00\t0.00\t0.01\t0.00\t99.95\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "73.01\t15.52\t0.42\t0.00\t0.06\t0.00\t0.01\t0.74\t0.00\t1.33\t8.90\t--> 0\n",
      "0.01\t0.06\t0.01\t0.03\t0.00\t0.00\t0.01\t0.00\t0.00\t0.16\t99.73\t--> 10\n",
      "0.11\t0.22\t0.42\t1.00\t0.02\t0.48\t0.37\t0.23\t30.55\t0.34\t66.26\t--> 10\n",
      "0.00\t0.02\t0.00\t0.36\t0.00\t0.00\t0.00\t0.00\t0.00\t0.14\t99.47\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.98\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.06\t0.01\t0.00\t0.06\t99.86\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.07\t0.02\t0.00\t0.04\t0.00\t0.00\t0.01\t0.01\t0.00\t0.05\t99.80\t--> 10\n",
      "0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.98\t--> 10\n",
      "0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.98\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.00\t0.00\t0.01\t0.00\t99.98\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "14.06\t79.21\t0.00\t0.13\t0.00\t0.00\t0.04\t0.09\t0.00\t0.03\t6.43\t--> 1\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.02\t0.01\t0.00\t0.01\t0.00\t0.00\t0.00\t0.08\t0.00\t0.01\t99.87\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t--> 10\n",
      "0.01\t0.01\t0.18\t0.03\t0.02\t0.02\t0.00\t0.01\t0.14\t0.04\t99.53\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "1.62\t0.19\t0.00\t0.11\t0.02\t0.00\t0.02\t0.07\t0.01\t0.14\t97.84\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t--> 10\n",
      "9.49\t1.34\t0.14\t0.71\t0.25\t0.02\t0.13\t0.24\t0.06\t3.43\t84.20\t--> 10\n",
      "0.10\t0.18\t0.01\t0.06\t0.03\t0.14\t0.36\t0.47\t0.05\t1.29\t97.30\t--> 10\n",
      "0.10\t0.06\t0.00\t0.00\t0.01\t0.00\t0.00\t0.07\t0.00\t0.05\t99.70\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.01\t0.00\t0.02\t99.97\t--> 10\n",
      "0.00\t0.01\t0.00\t0.01\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t99.97\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t99.99\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.04\t0.31\t0.00\t0.00\t0.00\t0.00\t0.08\t1.14\t0.01\t0.07\t98.33\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t--> 10\n",
      "0.02\t0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.96\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.98\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.45\t0.29\t0.00\t0.00\t0.01\t0.00\t0.01\t0.01\t0.00\t0.05\t99.18\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.06\t0.79\t0.87\t0.05\t0.12\t0.03\t0.13\t0.03\t0.01\t1.05\t96.85\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.01\t0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.97\t--> 10\n",
      "0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.00\t0.02\t99.95\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.03\t0.01\t0.00\t0.01\t0.00\t0.00\t0.00\t0.01\t0.00\t0.02\t99.92\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.98\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t--> 10\n",
      "0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.02\t0.02\t0.00\t99.94\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.06\t0.01\t0.00\t0.00\t0.00\t0.00\t0.07\t0.06\t0.00\t1.41\t98.39\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.00\t99.98\t--> 10\n",
      "0.67\t0.06\t0.00\t0.03\t0.01\t0.00\t0.01\t0.04\t0.01\t0.05\t99.11\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.98\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.02\t0.00\t0.01\t6.76\t0.02\t0.00\t0.12\t93.08\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.06\t0.00\t0.00\t0.00\t99.94\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.01\t0.02\t0.72\t0.00\t0.04\t2.86\t0.03\t0.27\t0.07\t95.98\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.06\t0.03\t0.01\t0.98\t0.04\t0.20\t0.22\t0.41\t65.12\t0.15\t32.80\t--> 8\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.01\t0.16\t0.06\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t99.75\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.54\t0.71\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t98.74\t--> 10\n",
      "4.95\t0.46\t0.12\t1.73\t1.97\t2.93\t1.68\t2.94\t54.67\t4.98\t23.58\t--> 8\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.67\t0.00\t99.32\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t--> 10\n",
      "0.00\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t--> 10\n",
      "0.02\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.00\t0.00\t99.97\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t--> 10\n",
      "0.13\t0.03\t0.00\t0.10\t0.06\t0.00\t0.00\t0.01\t0.02\t0.05\t99.60\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.64\t0.00\t0.00\t0.00\t99.36\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.28\t0.00\t0.00\t0.00\t99.72\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.93\t0.01\t0.00\t0.00\t0.06\t--> 6\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.04\t0.00\t0.00\t99.95\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t99.98\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t99.99\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.00\t0.00\t0.00\t99.99\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.01\t0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.01\t99.96\t--> 10\n",
      "2.22\t0.15\t0.02\t0.04\t0.06\t0.00\t0.03\t0.06\t0.01\t0.06\t97.35\t--> 10\n",
      "0.07\t0.04\t0.00\t0.26\t0.03\t0.05\t0.05\t0.31\t0.57\t0.07\t98.54\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t97.54\t0.03\t0.00\t0.00\t2.42\t--> 6\n",
      "0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t99.99\t--> 10\n",
      "0.16\t0.01\t0.00\t0.00\t0.00\t0.00\t0.00\t0.01\t0.00\t0.00\t99.83\t--> 10\n",
      "0.10\t0.35\t0.40\t0.05\t0.04\t0.17\t0.16\t0.04\t0.00\t5.85\t92.84\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.01\t0.69\t0.10\t0.00\t3.53\t0.18\t0.00\t0.00\t0.09\t95.39\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n",
      "0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t0.00\t100.00\t--> 10\n"
     ]
    }
   ],
   "source": [
    "print('Predicted probabilities [%] for the different exercises:\\n')\n",
    "for jj in range(np.shape(pred_prob_test)[1]):\n",
    "    print('Ex. {:d}\\t'.format(jj), end='')\n",
    "print('pred. class')\n",
    "        \n",
    "for ii in range(np.shape(pred_prob_test)[0]):\n",
    "    for jj in range(np.shape(pred_prob_test)[1]):\n",
    "        print('{:.2f}\\t'.format(pred_prob_test[ii,jj]*100), end='')\n",
    "    print('--> {:d}'.format(np.argmax(pred_prob_test[ii,:])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:44:10.817033Z",
     "start_time": "2019-02-18T20:44:10.810033Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  1,  1,  1,\n",
       "        1,  0,  1,  0,  1,  1,  1,  1,  1,  1,  1,  0,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  0,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  9,  2,  2,  2,  2,  2,  2,  2,  2, 10,\n",
       "        2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "        3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "        3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "        4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
       "        7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
       "        7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "        8,  8, 10,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "        9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "        9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,  5,  9,\n",
       "       10,  8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10,  0, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,  1, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10,  8, 10, 10, 10, 10,  8, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10,  6, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10,  6, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], dtype=int64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(pred_prob_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:44:10.999043Z",
     "start_time": "2019-02-18T20:44:10.871036Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(709, 24, 6)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_testing = PD_RNN1.get_X_test()\n",
    "np.shape(X_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:44:11.146052Z",
     "start_time": "2019-02-18T20:44:11.052047Z"
    }
   },
   "outputs": [],
   "source": [
    "# all sequence lengths shall now have the maximum length (--> np.shape(X_testing)[1])\n",
    "seqlens_testing =  np.full(np.shape(X_testing)[0], np.shape(X_testing)[1], dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:44:11.787089Z",
     "start_time": "2019-02-18T20:44:11.199055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from E:/TensorFlow_saved_models/final-RNN-model/RNN-model-1\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:    \n",
    "    \n",
    "    #First let's load meta graph and restore weights\n",
    "    new_saver = tf.train.import_meta_graph('E:/TensorFlow_saved_models/final-RNN-model/RNN-model-1.meta')\n",
    "    new_saver.restore(sess, 'E:/TensorFlow_saved_models/final-RNN-model/RNN-model-1')\n",
    "\n",
    "    # Now, let's access and create placeholders variables and\n",
    "    # create feed-dict to feed new data\n",
    "    graph = tf.get_default_graph()\n",
    "    inputs = graph.get_tensor_by_name('data/inputs:0')\n",
    "    seqlens = graph.get_tensor_by_name('data/seqlens:0')\n",
    "\n",
    "    # Now, access the op that you want to run. \n",
    "    pred_prob_all_states = graph.get_tensor_by_name(\"evaluation/predicted_probabilities_all_states:0\")\n",
    "\n",
    "    pred_prob_testing = sess.run(pred_prob_all_states, feed_dict={inputs: X_testing,\n",
    "                                                                  seqlens: seqlens_testing})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:44:11.865093Z",
     "start_time": "2019-02-18T20:44:11.857093Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17016, 11)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(pred_prob_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:44:12.049104Z",
     "start_time": "2019-02-18T20:44:11.919096Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.60377098e-02, 6.06606482e-05, 1.62450051e-05, 1.76395570e-05,\n",
       "       1.20997370e-07, 5.23104063e-06, 7.09703367e-04, 7.35635906e-02,\n",
       "       6.54152811e-01, 8.31131041e-01, 9.75617826e-01, 9.92549658e-01,\n",
       "       9.87142980e-01, 9.48836029e-01, 4.83126044e-01, 1.91736855e-02,\n",
       "       4.35857888e-04, 1.27256699e-05, 1.36271626e-06, 3.48048388e-07,\n",
       "       1.11716496e-07, 6.88416364e-08, 6.32633146e-08, 6.38619682e-08,\n",
       "       4.05111201e-02, 1.72324991e-03, 2.56416170e-05, 2.18737368e-05,\n",
       "       2.97258848e-05, 8.60143973e-06, 4.58845723e-04, 4.74383822e-03,\n",
       "       2.95016646e-01, 9.31757927e-01, 9.86520767e-01, 9.94350672e-01,\n",
       "       9.85220194e-01, 9.66581166e-01, 2.42955506e-01, 1.03653576e-02,\n",
       "       1.70370200e-04, 5.87987324e-06, 8.46961768e-07, 3.32452004e-07,\n",
       "       1.26263657e-07, 7.36563877e-08, 6.42996554e-08, 6.35718820e-08],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob_testing[0:48,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:44:12.212113Z",
     "start_time": "2019-02-18T20:44:12.104107Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.6037710e-02, 6.0660648e-05, 1.6245005e-05, 1.7639557e-05,\n",
       "       1.2099737e-07, 5.2310406e-06, 7.0970337e-04, 7.3563591e-02,\n",
       "       6.5415281e-01, 8.3113104e-01, 9.7561783e-01, 8.0313839e-02,\n",
       "       8.0313839e-02, 8.0313839e-02, 8.0313839e-02, 8.0313839e-02,\n",
       "       8.0313839e-02, 8.0313839e-02, 8.0313839e-02, 8.0313839e-02,\n",
       "       8.0313839e-02, 8.0313839e-02, 8.0313839e-02, 8.0313839e-02,\n",
       "       4.0511120e-02, 1.7232499e-03, 2.5641617e-05, 2.1873737e-05,\n",
       "       2.9725885e-05, 8.6014397e-06, 4.5884572e-04, 4.7438382e-03,\n",
       "       2.9501665e-01, 9.3175793e-01, 9.8652077e-01, 9.9435067e-01,\n",
       "       8.0313839e-02, 8.0313839e-02, 8.0313839e-02, 8.0313839e-02,\n",
       "       8.0313839e-02, 8.0313839e-02, 8.0313839e-02, 8.0313839e-02,\n",
       "       8.0313839e-02, 8.0313839e-02, 8.0313839e-02, 8.0313839e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob_test_all[0:48,0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:44:12.360121Z",
     "start_time": "2019-02-18T20:44:12.266116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.11716496e-07"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob_testing[20,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:44:12.509130Z",
     "start_time": "2019-02-18T20:44:12.414124Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08031384"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob_test_all[20,0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:44:12.656138Z",
     "start_time": "2019-02-18T20:44:12.565133Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_testing)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:44:12.802147Z",
     "start_time": "2019-02-18T20:44:12.710141Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_prob_testing_reshape = np.reshape(pred_prob_testing, (-1, np.shape(X_testing)[1], 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:44:12.946155Z",
     "start_time": "2019-02-18T20:44:12.856150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.60377098e-02, 6.06606482e-05, 1.62450051e-05, 1.76395570e-05,\n",
       "       1.20997370e-07, 5.23104063e-06, 7.09703367e-04, 7.35635906e-02,\n",
       "       6.54152811e-01, 8.31131041e-01, 9.75617826e-01, 9.92549658e-01,\n",
       "       9.87142980e-01, 9.48836029e-01, 4.83126044e-01, 1.91736855e-02,\n",
       "       4.35857888e-04, 1.27256699e-05, 1.36271626e-06, 3.48048388e-07,\n",
       "       1.11716496e-07, 6.88416364e-08, 6.32633146e-08, 6.38619682e-08],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probabilities of first data point, all time steps and first class (0: 'RF')\n",
    "pred_prob_testing_reshape[0,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of a whole record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:44:14.497244Z",
     "start_time": "2019-02-18T20:44:13.002158Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the test subject\n",
    "test_data_subject = 1\n",
    "\n",
    "test_subject_dir  = r'E:\\Physio_Data\\Subject_{:02}'.format(test_data_subject)\n",
    "test_subject_file = 'subject{:02}.csv'.format(test_data_subject)\n",
    "test_subject_path = os.path.join(test_subject_dir, test_subject_file)\n",
    "\n",
    "\n",
    "# signal names\n",
    "signal_abbrs = ['Acc','Gyr']\n",
    "\n",
    "# filter properties according to Crema\n",
    "cutoff = 10 # [Hz]\n",
    "order = 6 # butterworth order\n",
    "\n",
    "sampling_rate = 256 # [Hz]\n",
    "\n",
    "# get data from selected file\n",
    "sensor_data = fmpm.get_sensor_data(in_file=test_subject_path,\n",
    "                                   signals=signal_abbrs,\n",
    "                                   sampling_rate=sampling_rate)\n",
    "\n",
    "# filter data with butterworth filter and save to new dictionary\n",
    "sensor_data_filt = {}\n",
    "for signal in signal_abbrs:\n",
    "    sensor_data_filt[signal] = fmpm.butter_lowpass_filter(sensor_data[signal], \n",
    "                                                          cutoff=cutoff, \n",
    "                                                          fs=sampling_rate, \n",
    "                                                          order=order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Down sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:44:14.564247Z",
     "start_time": "2019-02-18T20:44:14.550247Z"
    }
   },
   "outputs": [],
   "source": [
    "new_sampling_rate = 4 # [Hz]\n",
    "\n",
    "# sampling rate ratio of original and new sampling rate (e.g. if ratio = 32 --> take every 32nd index)\n",
    "sampling_rate_ratio = sampling_rate / new_sampling_rate\n",
    "\n",
    "\n",
    "# start and stop indices of current data point (current repetition block)\n",
    "start_idx = 0\n",
    "# all signal columns must have the same length\n",
    "stop_idx = len(sensor_data_filt[signal_abbrs[0]][:,0])\n",
    "\n",
    "# consider the new sampling rate for signal data selection\n",
    "new_indices = np.arange(start_idx, stop_idx, sampling_rate_ratio).round().astype(int)\n",
    "\n",
    "sensor_data_newHz = {}\n",
    "for signal in signal_abbrs:\n",
    "    sensor_data_newHz[signal] = sensor_data_filt[signal][new_indices,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:44:14.747258Z",
     "start_time": "2019-02-18T20:44:14.618250Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8040, 3)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(sensor_data_newHz['Acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor with windowed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:44:14.927268Z",
     "start_time": "2019-02-18T20:44:14.802261Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8017, 24, 6)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_len = 24 # --> 6s * 4Hz\n",
    "num_signals = 6 # Acc, Gyr --> y, x, z\n",
    "\n",
    "data_len = np.shape(sensor_data_newHz['Acc'])[0]\n",
    "num_data_points = data_len - max_seq_len + 1 # number of data points after windowing\n",
    "\n",
    "Tensor_win = np.zeros((num_data_points, max_seq_len, num_signals))\n",
    "\n",
    "for ii in range(num_data_points):\n",
    "    Tensor_win[ii,:,0:3] = sensor_data_newHz['Acc'][ii:ii+max_seq_len, :] # corresponding acc. values \n",
    "    Tensor_win[ii,:,3:6] = sensor_data_newHz['Gyr'][ii:ii+max_seq_len, :] # corresponding ang. vel. values\n",
    "    \n",
    "np.shape(Tensor_win)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict probabilities with RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:44:16.721371Z",
     "start_time": "2019-02-18T20:44:14.983271Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from E:/TensorFlow_saved_models/final-RNN-model/RNN-model-1\n"
     ]
    }
   ],
   "source": [
    "# all sequence lengths shall now have the maximum length (--> np.shape(Tensor_win)[1])\n",
    "seqlens_win =  np.full(np.shape(Tensor_win)[0], np.shape(Tensor_win)[1], dtype=np.int)\n",
    "\n",
    "with tf.Session() as sess:    \n",
    "    \n",
    "    #First let's load meta graph and restore weights\n",
    "    new_saver = tf.train.import_meta_graph('E:/TensorFlow_saved_models/final-RNN-model/RNN-model-1.meta')\n",
    "    new_saver.restore(sess, 'E:/TensorFlow_saved_models/final-RNN-model/RNN-model-1')\n",
    "\n",
    "    # Now, let's access and create placeholders variables and\n",
    "    # create feed-dict to feed new data\n",
    "    graph = tf.get_default_graph()\n",
    "    inputs = graph.get_tensor_by_name('data/inputs:0')\n",
    "    seqlens = graph.get_tensor_by_name('data/seqlens:0')\n",
    "\n",
    "    # Now, access the op that you want to run. \n",
    "    pred_prob_all_states = graph.get_tensor_by_name(\"evaluation/predicted_probabilities_all_states:0\")\n",
    "\n",
    "    pred_prob_win = sess.run(pred_prob_all_states, feed_dict={inputs: Tensor_win,\n",
    "                                                              seqlens: seqlens_win})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:44:16.781374Z",
     "start_time": "2019-02-18T20:44:16.775374Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192408, 11)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(pred_prob_win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:44:16.919382Z",
     "start_time": "2019-02-18T20:44:16.835377Z"
    }
   },
   "outputs": [],
   "source": [
    "ex_dict = {0:'RF',1:'RO',2:'RS',3:'LR',4:'BC',5:'TC',6:'MP',7:'SA',8:'P1',9:'P2',10:'NE'}\n",
    "\n",
    "pred_prob_win_dict = {}\n",
    "for ii in range(len(ex_dict)):\n",
    "    pred_prob_win_dict[ex_dict[ii]] = pred_prob_win[:,ii].reshape(-1,max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:44:17.060390Z",
     "start_time": "2019-02-18T20:44:16.974385Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8017, 24)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(pred_prob_win_dict['RF'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:44:17.258401Z",
     "start_time": "2019-02-18T20:44:17.114393Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raises Oblique</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>01:18.6</td>\n",
       "      <td>01:58.3</td>\n",
       "      <td>02:22.1</td>\n",
       "      <td>02:37.1</td>\n",
       "      <td>02:54.8</td>\n",
       "      <td>03:23.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PNF Diagonal 2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>04:27.1</td>\n",
       "      <td>04:54.3</td>\n",
       "      <td>05:24.5</td>\n",
       "      <td>05:38.9</td>\n",
       "      <td>06:25.8</td>\n",
       "      <td>07:05.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Triceps Curls</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>07:32.3</td>\n",
       "      <td>08:14.8</td>\n",
       "      <td>08:49.5</td>\n",
       "      <td>09:04.9</td>\n",
       "      <td>09:46.1</td>\n",
       "      <td>10:12.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rotation Wrist</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>10:43.1</td>\n",
       "      <td>10:57.3</td>\n",
       "      <td>11:25.6</td>\n",
       "      <td>11:51.8</td>\n",
       "      <td>12:12.1</td>\n",
       "      <td>12:52.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Raises Front</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>13:44.8</td>\n",
       "      <td>14:14</td>\n",
       "      <td>14:40.6</td>\n",
       "      <td>15:20</td>\n",
       "      <td>16:09.5</td>\n",
       "      <td>16:23.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Biceps Curls</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>16:50.8</td>\n",
       "      <td>17:30.2</td>\n",
       "      <td>18:01.3</td>\n",
       "      <td>18:32.2</td>\n",
       "      <td>18:58.6</td>\n",
       "      <td>19:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Raises Side</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>20:13</td>\n",
       "      <td>21:00.2</td>\n",
       "      <td>21:24.9</td>\n",
       "      <td>21:40.2</td>\n",
       "      <td>22:09.6</td>\n",
       "      <td>22:38.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PNF Diagonal 1</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>23:43.9</td>\n",
       "      <td>24:15.9</td>\n",
       "      <td>24:42</td>\n",
       "      <td>25:25.1</td>\n",
       "      <td>25:48.7</td>\n",
       "      <td>26:04.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shoulder Adduct.</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>26:48.5</td>\n",
       "      <td>27:05.3</td>\n",
       "      <td>27:25.4</td>\n",
       "      <td>28:16.5</td>\n",
       "      <td>28:41.2</td>\n",
       "      <td>29:10.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Military Press</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>29:45.6</td>\n",
       "      <td>30:37.4</td>\n",
       "      <td>31:14.6</td>\n",
       "      <td>31:47.3</td>\n",
       "      <td>32:13.6</td>\n",
       "      <td>32:28.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0   1   2   3        4        5        6        7        8  \\\n",
       "0    Raises Oblique  15   5  10  01:18.6  01:58.3  02:22.1  02:37.1  02:54.8   \n",
       "1    PNF Diagonal 2  10   5  15  04:27.1  04:54.3  05:24.5  05:38.9  06:25.8   \n",
       "2     Triceps Curls  15   5  10  07:32.3  08:14.8  08:49.5  09:04.9  09:46.1   \n",
       "3    Rotation Wrist   5  10  15  10:43.1  10:57.3  11:25.6  11:51.8  12:12.1   \n",
       "4      Raises Front  10  15   5  13:44.8    14:14  14:40.6    15:20  16:09.5   \n",
       "5      Biceps Curls  15  10   5  16:50.8  17:30.2  18:01.3  18:32.2  18:58.6   \n",
       "6       Raises Side  15   5  10    20:13  21:00.2  21:24.9  21:40.2  22:09.6   \n",
       "7    PNF Diagonal 1  10  15   5  23:43.9  24:15.9    24:42  25:25.1  25:48.7   \n",
       "8  Shoulder Adduct.   5  15  10  26:48.5  27:05.3  27:25.4  28:16.5  28:41.2   \n",
       "9    Military Press  15  10   5  29:45.6  30:37.4  31:14.6  31:47.3  32:13.6   \n",
       "\n",
       "         9  \n",
       "0  03:23.3  \n",
       "1  07:05.1  \n",
       "2  10:12.6  \n",
       "3  12:52.4  \n",
       "4  16:23.1  \n",
       "5    19:12  \n",
       "6  22:38.4  \n",
       "7  26:04.6  \n",
       "8  29:10.9  \n",
       "9  32:28.1  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the actual time ranges of the exercises of the test data for the subsequent plot \n",
    "# to compare with predicted values\n",
    "\n",
    "# select file with timetable (csv) of the test subject\n",
    "timetable_file_dir = r'E:\\Physio_Data\\Exercise_time_tables'\n",
    "timetable_file_name = 'Timetable_subject{:02}.txt'.format(test_data_subject)\n",
    "timetable_data_path = os.path.join(timetable_file_dir, timetable_file_name)\n",
    "\n",
    "# read in time table\n",
    "timetable_data = pd.read_csv(timetable_data_path, skiprows=0, sep='\\t', header=None)\n",
    "num_exercises = timetable_data.shape[0] # number of exercises\n",
    "timetable_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:44:17.428411Z",
     "start_time": "2019-02-18T20:44:17.313405Z"
    }
   },
   "outputs": [],
   "source": [
    "# function to convert indices to time strings\n",
    "def indices_to_time(start_index, stop_index):\n",
    "    '''\n",
    "    Function convert indices to time string.\n",
    "    !! Global variables are used !!\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    start_index : int\n",
    "        \n",
    "    stop_index : int\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        String with start and stop time (e.g. '14:39.6 - 15:19.4').\n",
    "    '''\n",
    "    start_time_text = '{0:02}:{1:04.1f}'.format(int(start_index/new_sampling_rate/60), \n",
    "                                               (start_index/new_sampling_rate)%60)\n",
    "    stop_time_text = '{0:02}:{1:04.1f}'.format(int(stop_index/new_sampling_rate/60), \n",
    "                                               (stop_index/new_sampling_rate)%60)\n",
    "    return start_time_text + ' - ' + stop_time_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T20:44:18.497472Z",
     "start_time": "2019-02-18T20:44:17.481414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib auto\n",
    "\n",
    "# text for current subject\n",
    "sub_text = 'Subject {}\\n'.format(test_data_subject)\n",
    "\n",
    "yticks = np.arange(0, max_seq_len)[::10]\n",
    "\n",
    "ylabels = np.arange(1, max_seq_len+1)/new_sampling_rate\n",
    "ylabels = ylabels[::10]\n",
    "\n",
    "fig, axis = plt.subplots(12,1,figsize=(18,9), sharex=True)\n",
    "\n",
    "# image color settings for RFC probabilities\n",
    "cmap = plt.cm.seismic\n",
    "vmin=0\n",
    "vmax=1\n",
    "\n",
    "exercise_abbrs = [ex_dict[ii] for ii in range(len(ex_dict))]\n",
    "\n",
    "for ax, ex in zip(axis, exercise_abbrs):\n",
    "    s = ax.imshow(pred_prob_win_dict[ex].transpose(), interpolation='nearest', \n",
    "                  aspect='auto', cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_yticks(yticks)\n",
    "    ax.set_yticklabels(ylabels, fontsize=7)\n",
    "    ax.set_ylabel(ex, rotation=0, fontsize=13)\n",
    "    ax.yaxis.labelpad = 34\n",
    "    ax.xaxis.set_ticklabels([])\n",
    "\n",
    "    \n",
    "plt.gcf().text(0.09, 0.6, r'sequence length $[s]$', fontsize=10, rotation=90)\n",
    "# plt.gcf().text(0.078, 0.6, r'window length $[s]$', fontsize=10, rotation=90) # for half the window size\n",
    "\n",
    "#axis[-1].plot(range(num_start_points), np.zeros(num_start_points), 'k', alpha=0.0)\n",
    "formatter = FuncFormatter(lambda i, x: time.strftime('%M:%S', time.gmtime(i/new_sampling_rate)))\n",
    "axis[-1].xaxis.set_major_formatter(formatter)\n",
    "axis[-1].set_xlabel(r'time $[min:sec]$', fontsize=13)\n",
    "axis[-1].set_yticks([])\n",
    "axis[-1].set_ylim([0,1])\n",
    "\n",
    "fig.subplots_adjust(bottom=0.2, right=0.9) # make space for buttons and color bar\n",
    "cbar_ax = fig.add_axes([0.93, 0.255, 0.01, 0.625])\n",
    "fig.colorbar(s, cax=cbar_ax)\n",
    "\n",
    "# add slider for selections on the x axis\n",
    "Slider_shiftX_ax = plt.axes([0.125, 0.07, 0.775, 0.025])\n",
    "Slider_zoomX_ax = plt.axes([0.125, 0.035, 0.775, 0.025])\n",
    "\n",
    "axcolor = 'cornflowerblue'\n",
    "Slider_shiftX = Slider(Slider_shiftX_ax, 'time shift [%]', 0.0, 100.0, valinit=0, facecolor=axcolor)\n",
    "Slider_zoomX = Slider(Slider_zoomX_ax, 'time scale [%]', 0.1, 100.0, valinit=100, facecolor=axcolor)\n",
    "Slider_zoomX_ax.xaxis.set_visible(True)\n",
    "Slider_zoomX_ax.set_xticks(np.arange(0,105,5)) \n",
    "\n",
    "def updateX(val):\n",
    "    start_index = int(Slider_shiftX.val / 100 * num_data_points)\n",
    "    stop_index = start_index + Slider_zoomX.val / 100 * num_data_points\n",
    "    axis[-1].set_xlim((start_index, stop_index))\n",
    "    fig.suptitle('Predicted Probabilities ' + sub_text + indices_to_time(start_index, stop_index), fontsize=20)\n",
    "    plt.draw()\n",
    "\n",
    "Slider_shiftX.on_changed(updateX)\n",
    "Slider_zoomX.on_changed(updateX)\n",
    "\n",
    "# add button to reset view\n",
    "def resetX(val):\n",
    "    start_index = 0\n",
    "    stop_index = num_data_points\n",
    "    axis[-1].set_xlim((start_index, stop_index))\n",
    "    Slider_shiftX.reset()\n",
    "    Slider_zoomX.reset()\n",
    "    fig.suptitle('Predicted Probabilities ' + sub_text + indices_to_time(start_index, stop_index), fontsize=20)\n",
    "    plt.draw()\n",
    "\n",
    "Button_resetX_ax = plt.axes([0.85, 0.12, 0.05, 0.03])\n",
    "Button_resetX = Button(Button_resetX_ax, 'Reset view')\n",
    "Button_resetX.on_clicked(resetX)\n",
    "\n",
    "start_index = 0\n",
    "stop_index = num_data_points\n",
    "\n",
    "fig.suptitle('Predicted Probabilities ' + sub_text + indices_to_time(start_index, stop_index), fontsize=20)\n",
    "\n",
    "axis[-1].set_xlim(0, num_data_points)\n",
    "\n",
    "\n",
    "# Plotting the actual classes (exercises) on the last axis:\n",
    "\n",
    "# dictionary to get exercise abbreviations from exercise names in timetable\n",
    "exercise_names = {'Raises Front':'RF',\n",
    "                  'Raises Oblique':'RO',\n",
    "                  'Raises Side':'RS',\n",
    "                  'Rotation Wrist':'LR',\n",
    "                  'Biceps Curls':'BC',\n",
    "                  'Triceps Curls':'TC',\n",
    "                  'Military Press':'MP',\n",
    "                  'Shoulder Adduct.':'SA',\n",
    "                  'PNF Diagonal 1':'P1',\n",
    "                  'PNF Diagonal 2':'P2'}\n",
    "\n",
    "# going through all exercises in the timetable\n",
    "for ii, ex_name in enumerate(timetable_data.values[:,0]):\n",
    "    \n",
    "    # going through all repetition blocks in the timetable (5, 10 and 15 rep. blocks)\n",
    "    for rep_col, start_col, stop_col in zip([1,2,3],[4,6,8],[5,7,9]): # corresponding columns\n",
    "        rep_num = timetable_data.values[ii,rep_col]\n",
    "        left_border = fmpm.convert_time_format_to_index(timetable_data.values[ii,start_col], \n",
    "                                                        sampling_rate=new_sampling_rate)\n",
    "        right_border = fmpm.convert_time_format_to_index(timetable_data.values[ii,stop_col], \n",
    "                                                         sampling_rate=new_sampling_rate)\n",
    "        # mark the corresponding area\n",
    "        axis[-1].axvspan(left_border, right_border, color='y', alpha=0.3, lw=0)\n",
    "        # write text to the corresponding area\n",
    "        x_center = left_border + (right_border-left_border)/2 # x center of marked area\n",
    "        axis[-1].text(x_center, 0.5, str(rep_num) + '\\n' + exercise_names[ex_name], \n",
    "                      horizontalalignment='center', verticalalignment='center', fontsize=10, clip_on=True)\n",
    "        \n",
    "axis[-1].set_ylabel('Actual classes', rotation=0, fontsize=11)\n",
    "axis[-1].yaxis.labelpad = 50\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "282px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
