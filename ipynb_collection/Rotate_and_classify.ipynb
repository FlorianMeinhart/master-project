{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of rotated signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T10:24:46.739992Z",
     "start_time": "2019-01-07T10:24:44.682874Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "import skinematics as skin\n",
    "import matplotlib.pyplot as plt\n",
    "import functionsMasterProjectMeinhart as fmpm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T10:24:46.958004Z",
     "start_time": "2019-01-07T10:24:46.742992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the individual data frames:\n",
      "RF:\t239\n",
      "RO:\t240\n",
      "RS:\t240\n",
      "LR:\t241\n",
      "BC:\t242\n",
      "TC:\t243\n",
      "MP:\t242\n",
      "SA:\t242\n",
      "P1:\t240\n",
      "P2:\t239\n",
      "NE:\t3712\n",
      "total:\t6120\n"
     ]
    }
   ],
   "source": [
    "# load all data, except data from one subject (test data)\n",
    "test_data_subject = 1\n",
    "\n",
    "db_name='DataBase_Physio_with_nonEx.db' # database name\n",
    "exercise_abbrs = ['RF','RO','RS','LR','BC','TC','MP','SA','P1','P2','NE'] # exercise abbreviations\n",
    "# Connect to an existing database\n",
    "conn = sqlite3.connect(db_name)\n",
    "cur = conn.cursor()\n",
    "train_data_points = {} # dictionary with the exercise abbreviation as key\n",
    "for key in exercise_abbrs:\n",
    "    # sql command to extract data\n",
    "    query_sql = \"\"\"\n",
    "        SELECT r.start_time, r.stop_time, e.csv_file\n",
    "        FROM subjects s\n",
    "        INNER JOIN exercises e\n",
    "        ON s.id = e.subject_id\n",
    "        INNER JOIN paradigms p\n",
    "        ON p.id = e.paradigm_id\n",
    "        INNER JOIN repetitions r\n",
    "        ON e.id = r.exercise_id\n",
    "        WHERE p.abbreviation = '{}'\n",
    "        AND NOT s.id = {}\n",
    "        \"\"\".format(key, test_data_subject)\n",
    "    # get data from data base and close connection\n",
    "    train_data_points[key] = pd.read_sql_query(query_sql, conn)\n",
    "conn.close()\n",
    "\n",
    "print('Length of the individual data frames:')\n",
    "num_data_points_train = 0\n",
    "for key in exercise_abbrs:\n",
    "    print(key + ':\\t' + str(train_data_points[key].shape[0]))\n",
    "    num_data_points_train += train_data_points[key].shape[0]\n",
    "print('total:\\t' + str(num_data_points_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T10:24:46.989006Z",
     "start_time": "2019-01-07T10:24:46.971005Z"
    }
   },
   "outputs": [],
   "source": [
    "# number of sections to split the signals\n",
    "number_sections = 10\n",
    "\n",
    "sampling_rate = 256 # [Hz]\n",
    "sig_names = ['Acc','Gyr'] # signals which shall be considered for the mean calculation\n",
    "csv_dir='E:\\Physio_Data_Split_Ex_and_NonEx' # directory of csv file\n",
    "exercise_abbrs = ['RF','RO','RS','LR','BC','TC','MP','SA','P1','P2','NE']\n",
    "exercise_dict = {ex: ii for ii, ex in enumerate(exercise_abbrs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T10:29:42.349900Z",
     "start_time": "2019-01-07T10:24:46.993006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 100%\n"
     ]
    }
   ],
   "source": [
    "X_train = np.zeros((num_data_points_train, number_sections*6))\n",
    "y_train = np.zeros(num_data_points_train, dtype=np.int8)\n",
    "\n",
    "count = 0\n",
    "y_pos = 0\n",
    "prev_prog = 0\n",
    "max_num = num_data_points_train\n",
    "\n",
    "# go through all exercises\n",
    "for ex in exercise_abbrs:\n",
    "    \n",
    "    # go through all repetitions (data points) of the current exercise\n",
    "    for ii in range(len(train_data_points[ex])):\n",
    "\n",
    "        # join file path\n",
    "        file_path = os.path.join(csv_dir, train_data_points[ex]['csv_file'][ii])\n",
    "\n",
    "        # load the signal data of the corresponding time range of the current repetition\n",
    "        selected_data = fmpm.get_sensor_data(in_file = file_path, \n",
    "                                             signals = sig_names, \n",
    "                                             sampling_rate = sampling_rate, \n",
    "                                             start_time = float(train_data_points[ex]['start_time'][ii]), \n",
    "                                             stop_time = float(train_data_points[ex]['stop_time'][ii]))\n",
    "        \n",
    "\n",
    "        # calculate the corresponding section means of the current repetition\n",
    "        section_means = fmpm.split_range_into_sections(signal_data = selected_data,\n",
    "                                                       num_sec = number_sections,\n",
    "                                                       signals = sig_names)\n",
    "        \n",
    "        # generate features\n",
    "        col = 0\n",
    "        for sig in sig_names:\n",
    "            for jj in [0,1,2]: # x, y, z comp. of the corresponding signal\n",
    "                X_train[count, col:col+number_sections] = section_means[sig][:,jj]\n",
    "                col += number_sections\n",
    "        \n",
    "        count += 1\n",
    "        prev_prog = fmpm.print_progress(count, max_num, prev_prog)\n",
    "    \n",
    "    label = exercise_dict[ex]\n",
    "    y_train[y_pos:y_pos+len(train_data_points[ex])] = label\n",
    "    y_pos += len(train_data_points[ex])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T10:29:42.361900Z",
     "start_time": "2019-01-07T10:29:42.355900Z"
    }
   },
   "outputs": [],
   "source": [
    "#plt.plot(X_train[0,:].reshape(6,10).transpose());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T10:29:42.581913Z",
     "start_time": "2019-01-07T10:29:42.367901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the individual data frames:\n",
      "RF:\t30\n",
      "RO:\t30\n",
      "RS:\t30\n",
      "LR:\t30\n",
      "BC:\t31\n",
      "TC:\t30\n",
      "MP:\t30\n",
      "SA:\t31\n",
      "P1:\t30\n",
      "P2:\t30\n",
      "NE:\t407\n",
      "total:\t709\n"
     ]
    }
   ],
   "source": [
    "# Connect to an existing database\n",
    "conn = sqlite3.connect(db_name)\n",
    "cur = conn.cursor()\n",
    "test_data_points = {} # dictionary with the exercise abbreviation as key\n",
    "for key in exercise_abbrs:\n",
    "    # sql command to extract data\n",
    "    query_sql = \"\"\"\n",
    "        SELECT r.start_time, r.stop_time, e.csv_file\n",
    "        FROM subjects s\n",
    "        INNER JOIN exercises e\n",
    "        ON s.id = e.subject_id\n",
    "        INNER JOIN paradigms p\n",
    "        ON p.id = e.paradigm_id\n",
    "        INNER JOIN repetitions r\n",
    "        ON e.id = r.exercise_id\n",
    "        WHERE p.abbreviation = '{}'\n",
    "        AND s.id = {}\n",
    "        \"\"\".format(key, test_data_subject)\n",
    "    # get data from data base and close connection\n",
    "    test_data_points[key] = pd.read_sql_query(query_sql, conn)\n",
    "conn.close()\n",
    "\n",
    "print('Length of the individual data frames:')\n",
    "num_data_points_test = 0\n",
    "for key in exercise_abbrs:\n",
    "    print(key + ':\\t' + str(test_data_points[key].shape[0]))\n",
    "    num_data_points_test += test_data_points[key].shape[0]\n",
    "print('total:\\t' + str(num_data_points_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T10:29:42.669918Z",
     "start_time": "2019-01-07T10:29:42.586913Z"
    }
   },
   "outputs": [],
   "source": [
    "def rotate_signal(signal_data, axis=0, rot_angle=90, signals=['Acc','Gyr']):\n",
    "    \n",
    "    # if no signals are given as keys, select all keys of the input dictionary\n",
    "    if signals is None:\n",
    "        signals = [*signal_data]\n",
    "    \n",
    "    # create rotation matrix\n",
    "    R = skin.rotmat.R(axis=axis, angle=rot_angle)\n",
    "    \n",
    "    # dictionary for rotated data\n",
    "    rot_signal_data = {}\n",
    "    \n",
    "    # rotate the signals\n",
    "    for sig in signals: \n",
    "        rot_signal_data[sig] = (R @ signal_data[sig].T).T\n",
    "        \n",
    "    return rot_signal_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T10:45:39.862666Z",
     "start_time": "2019-01-07T10:45:10.224971Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 100%\n"
     ]
    }
   ],
   "source": [
    "X_test = np.zeros((num_data_points_test, number_sections*6))\n",
    "y_test = np.zeros(num_data_points_test, dtype=np.int8)\n",
    "\n",
    "rot_axis = 0 # 0,1,2 --> x,y,z\n",
    "rot_angle = 20 # deg\n",
    "\n",
    "count = 0\n",
    "y_pos = 0\n",
    "prev_prog = 0\n",
    "max_num = num_data_points_test\n",
    "\n",
    "# go through all exercises\n",
    "for ex in exercise_abbrs:\n",
    "    \n",
    "    # go through all repetitions (data points) of the current exercise\n",
    "    for ii in range(len(test_data_points[ex])):\n",
    "\n",
    "        # join file path\n",
    "        file_path = os.path.join(csv_dir, test_data_points[ex]['csv_file'][ii])\n",
    "\n",
    "        # load the signal data of the corresponding time range of the current repetition\n",
    "        selected_data = fmpm.get_sensor_data(in_file = file_path, \n",
    "                                             signals = sig_names, \n",
    "                                             sampling_rate = sampling_rate, \n",
    "                                             start_time = float(test_data_points[ex]['start_time'][ii]), \n",
    "                                             stop_time = float(test_data_points[ex]['stop_time'][ii]))\n",
    "        \n",
    "        # rotate the signals\n",
    "        rot_data = rotate_signal(selected_data, axis=rot_axis, rot_angle=rot_angle, signals=['Acc','Gyr'])\n",
    "        \n",
    "        # calculate the corresponding section means of the current repetition\n",
    "        section_means = fmpm.split_range_into_sections(signal_data = rot_data,\n",
    "                                                       num_sec = number_sections,\n",
    "                                                       signals = sig_names)\n",
    "        \n",
    "        # generate features\n",
    "        col = 0\n",
    "        for sig in sig_names:\n",
    "            for jj in [0,1,2]: # x, y, z comp. of the corresponding signal\n",
    "                X_test[count, col:col+number_sections] = section_means[sig][:,jj]\n",
    "                col += number_sections\n",
    "        \n",
    "        count += 1\n",
    "        prev_prog = fmpm.print_progress(count, max_num, prev_prog)\n",
    "    \n",
    "    label = exercise_dict[ex]\n",
    "    y_test[y_pos:y_pos+len(test_data_points[ex])] = label\n",
    "    y_pos += len(test_data_points[ex])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T10:45:39.881667Z",
     "start_time": "2019-01-07T10:45:39.872667Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T10:45:46.295034Z",
     "start_time": "2019-01-07T10:45:39.884668Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=40,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=-1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create random forest classifier\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=40, n_jobs=-1, random_state=42)\n",
    "\n",
    "# train the model\n",
    "rnd_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T20:55:38.570120Z",
     "start_time": "2018-12-17T20:55:38.249101Z"
    }
   },
   "source": [
    "### Functions for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T10:45:46.419041Z",
     "start_time": "2019-01-07T10:45:46.306035Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_precision_recall_accuracy(y_pred, y_test):\n",
    "    '''\n",
    "    This function prints precision, recall and accuracy for each exercise.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_pred : array\n",
    "        Prediceted classes (0...10).\n",
    "    \n",
    "    y_test : array\n",
    "        Actual classes (0...10).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    '''\n",
    "    \n",
    "    # exercise abbreviations\n",
    "    exercise_abbrs = ['RF','RO','RS','LR','BC','TC','MP','SA','P1','P2','NE']\n",
    "    \n",
    "    # dictionary for labels\n",
    "    label_ex = {'RF':0,'RO':1,'RS':2,'LR':3,'BC':4,'TC':5,'MP':6,'SA':7,'P1':8,'P2':9,'NE':10}\n",
    "\n",
    "    \n",
    "    print('Exercise\\tPrecision [%]\\tRecall [%]\\tAccuracy[%]')\n",
    "    \n",
    "    for ex in exercise_abbrs:\n",
    "        TP = sum((y_pred == label_ex[ex]) & (np.array(y_test) == label_ex[ex])) # True Positives\n",
    "        TN = sum((y_pred != label_ex[ex]) & (np.array(y_test) != label_ex[ex])) # True Negatives\n",
    "        FP = sum((y_pred == label_ex[ex]) & (np.array(y_test) != label_ex[ex])) # False Positives\n",
    "        FN = sum((y_pred != label_ex[ex]) & (np.array(y_test) == label_ex[ex])) # False Negatives\n",
    "\n",
    "        precision = TP / (TP+FP)\n",
    "        recall = TP / (TP+FN)\n",
    "        accuracy = (TP+TN) / (TP+TN+FP+FN)\n",
    "        \n",
    "        print('  '+ ex +'\\t\\t  {:6.2f}'.format(precision*100)+ \\\n",
    "              '\\t  {:6.2f}'.format(recall*100)+'\\t  {:6.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T10:45:46.596051Z",
     "start_time": "2019-01-07T10:45:46.458044Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_misclassified_data_points(y_pred, y_test):\n",
    "    '''\n",
    "    This function prints all misclassified data points.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_pred : array\n",
    "        Predicted classes (0...10).\n",
    "    \n",
    "    y_test : array\n",
    "        Actual classes (0...10).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    '''\n",
    "    \n",
    "    # exercise abbreviations\n",
    "    exercise_abbrs = ['RF','RO','RS','LR','BC','TC','MP','SA','P1','P2','NE'] \n",
    "    \n",
    "    # indices of misclassified data points\n",
    "    ind_misclassified = np.flatnonzero(y_test != y_pred) \n",
    "\n",
    "    # print misclassified data points\n",
    "    print('{0} misclassified ({1} test data points):'.format(sum(y_test != y_pred), len(y_test)))\n",
    "    for ii in ind_misclassified:\n",
    "        print(exercise_abbrs[y_test[ii]] + ' classified as ' + exercise_abbrs[y_pred[ii]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T10:45:47.292091Z",
     "start_time": "2019-01-07T10:45:46.606052Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest Classifier\n",
      "\n",
      "Features: Means of 10 sections per signal (3 x Acc + 3 x Gyr) --> 60 features\n",
      "\n",
      "Total Accuracy: 0.97884\n",
      "\n",
      "\n",
      "Exercise\tPrecision [%]\tRecall [%]\tAccuracy[%]\n",
      "  RF\t\t   83.33\t  100.00\t   99.15\n",
      "  RO\t\t  100.00\t   80.00\t   99.15\n",
      "  RS\t\t  100.00\t  100.00\t  100.00\n",
      "  LR\t\t  100.00\t   93.33\t   99.72\n",
      "  BC\t\t  100.00\t  100.00\t  100.00\n",
      "  TC\t\t  100.00\t  100.00\t  100.00\n",
      "  MP\t\t   81.08\t  100.00\t   99.01\n",
      "  SA\t\t  100.00\t  100.00\t  100.00\n",
      "  P1\t\t  100.00\t  100.00\t  100.00\n",
      "  P2\t\t  100.00\t  100.00\t  100.00\n",
      "  NE\t\t   99.50\t   98.28\t   98.73\n",
      "\n",
      "\n",
      "15 misclassified (709 test data points):\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "LR classified as NE\n",
      "LR classified as NE\n",
      "NE classified as MP\n",
      "NE classified as MP\n",
      "NE classified as MP\n",
      "NE classified as MP\n",
      "NE classified as MP\n",
      "NE classified as MP\n",
      "NE classified as MP\n"
     ]
    }
   ],
   "source": [
    "# predict labels\n",
    "y_pred = rnd_clf.predict(X_test)\n",
    "\n",
    "# show results\n",
    "print('Model: Random Forest Classifier\\n')\n",
    "print('Features: Means of {} sections per signal (3 x Acc + 3 x Gyr) --> {} features\\n'.format(number_sections,\n",
    "                                                                                              number_sections*6))\n",
    "print('Total Accuracy: {:.5f}'.format((accuracy_score(y_test, y_pred))))\n",
    "print('\\n')\n",
    "print_precision_recall_accuracy(y_pred, y_test)\n",
    "print('\\n')\n",
    "print_misclassified_data_points(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
