{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same Subject for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-03T12:16:50.271139Z",
     "start_time": "2019-01-03T12:16:47.764996Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "import skinematics as skin\n",
    "import matplotlib.pyplot as plt\n",
    "import functionsMasterProjectMeinhart as fmpm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-03T12:16:50.478151Z",
     "start_time": "2019-01-03T12:16:50.274140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the individual data frames:\n",
      "RF:\t15\n",
      "RO:\t15\n",
      "RS:\t15\n",
      "LR:\t15\n",
      "BC:\t16\n",
      "TC:\t15\n",
      "MP:\t15\n",
      "SA:\t16\n",
      "P1:\t15\n",
      "P2:\t15\n",
      "NE:\t252\n",
      "total:\t404\n"
     ]
    }
   ],
   "source": [
    "# load all data from one subject for training \n",
    "# --> except the first 5 repetitions from each block as well as non-exercise data with sequence num > 5\n",
    "eval_subject = 1\n",
    "\n",
    "num_test_repetitions = 5\n",
    "\n",
    "db_name='DataBase_Physio_with_nonEx.db' # database name\n",
    "exercise_abbrs = ['RF','RO','RS','LR','BC','TC','MP','SA','P1','P2','NE'] # exercise abbreviations\n",
    "# Connect to an existing database\n",
    "conn = sqlite3.connect(db_name)\n",
    "cur = conn.cursor()\n",
    "train_data_points = {} # dictionary with the exercise abbreviation as key\n",
    "for key in exercise_abbrs:\n",
    "    # sql command to extract data\n",
    "    query_sql = \"\"\"\n",
    "        SELECT r.start_time, r.stop_time, e.csv_file\n",
    "        FROM subjects s\n",
    "        INNER JOIN exercises e\n",
    "        ON s.id = e.subject_id\n",
    "        INNER JOIN paradigms p\n",
    "        ON p.id = e.paradigm_id\n",
    "        INNER JOIN repetitions r\n",
    "        ON e.id = r.exercise_id\n",
    "        WHERE p.abbreviation = '{}'\n",
    "        AND s.id = {}\n",
    "        AND sequence_num > {}\n",
    "        \"\"\".format(key, eval_subject, num_test_repetitions)\n",
    "    # get data from data base and close connection\n",
    "    train_data_points[key] = pd.read_sql_query(query_sql, conn)\n",
    "conn.close()\n",
    "\n",
    "print('Length of the individual data frames:')\n",
    "num_data_points_train = 0\n",
    "for key in exercise_abbrs:\n",
    "    print(key + ':\\t' + str(train_data_points[key].shape[0]))\n",
    "    num_data_points_train += train_data_points[key].shape[0]\n",
    "print('total:\\t' + str(num_data_points_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-03T12:16:50.529154Z",
     "start_time": "2019-01-03T12:16:50.486152Z"
    }
   },
   "outputs": [],
   "source": [
    "# number of sections to split the signals\n",
    "number_sections = 10\n",
    "\n",
    "sampling_rate = 256 # [Hz]\n",
    "sig_names = ['Acc','Gyr'] # signals which shall be considered for the mean calculation\n",
    "csv_dir='E:\\Physio_Data_Split_Ex_and_NonEx' # directory of csv file\n",
    "exercise_abbrs = ['RF','RO','RS','LR','BC','TC','MP','SA','P1','P2','NE']\n",
    "exercise_dict = {ex: ii for ii, ex in enumerate(exercise_abbrs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-03T12:17:12.071386Z",
     "start_time": "2019-01-03T12:16:50.534155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 100%\n"
     ]
    }
   ],
   "source": [
    "X_train = np.zeros((num_data_points_train, number_sections*6))\n",
    "y_train = np.zeros(num_data_points_train, dtype=np.int8)\n",
    "\n",
    "count = 0\n",
    "y_pos = 0\n",
    "prev_prog = 0\n",
    "max_num = num_data_points_train\n",
    "\n",
    "# go through all exercises\n",
    "for ex in exercise_abbrs:\n",
    "    \n",
    "    # go through all repetitions (data points) of the current exercise\n",
    "    for ii in range(len(train_data_points[ex])):\n",
    "\n",
    "        # join file path\n",
    "        file_path = os.path.join(csv_dir, train_data_points[ex]['csv_file'][ii])\n",
    "\n",
    "        # load the signal data of the corresponding time range of the current repetition\n",
    "        selected_data = fmpm.get_sensor_data(in_file = file_path, \n",
    "                                             signals = sig_names, \n",
    "                                             sampling_rate = sampling_rate, \n",
    "                                             start_time = float(train_data_points[ex]['start_time'][ii]), \n",
    "                                             stop_time = float(train_data_points[ex]['stop_time'][ii]))\n",
    "        \n",
    "\n",
    "        # calculate the corresponding section means of the current repetition\n",
    "        section_means = fmpm.split_range_into_sections(signal_data = selected_data,\n",
    "                                                       num_sec = number_sections,\n",
    "                                                       signals = sig_names)\n",
    "        \n",
    "        # generate features\n",
    "        col = 0\n",
    "        for sig in sig_names:\n",
    "            for jj in [0,1,2]: # x, y, z comp. of the corresponding signal\n",
    "                X_train[count, col:col+number_sections] = section_means[sig][:,jj]\n",
    "                col += number_sections\n",
    "        \n",
    "        count += 1\n",
    "        prev_prog = fmpm.print_progress(count, max_num, prev_prog)\n",
    "    \n",
    "    label = exercise_dict[ex]\n",
    "    y_train[y_pos:y_pos+len(train_data_points[ex])] = label\n",
    "    y_pos += len(train_data_points[ex])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-03T12:17:12.144391Z",
     "start_time": "2019-01-03T12:17:12.076387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the individual data frames:\n",
      "RF:\t15\n",
      "RO:\t15\n",
      "RS:\t15\n",
      "LR:\t15\n",
      "BC:\t15\n",
      "TC:\t15\n",
      "MP:\t15\n",
      "SA:\t15\n",
      "P1:\t15\n",
      "P2:\t15\n",
      "NE:\t155\n",
      "total:\t305\n"
     ]
    }
   ],
   "source": [
    "# load all 5 repetition blocks from one subject for testing\n",
    "\n",
    "# connect to an existing database\n",
    "conn = sqlite3.connect(db_name)\n",
    "cur = conn.cursor()\n",
    "test_data_points = {} # dictionary with the exercise abbreviation as key\n",
    "for key in exercise_abbrs:\n",
    "    # sql command to extract data\n",
    "    query_sql = \"\"\"\n",
    "        SELECT r.start_time, r.stop_time, e.csv_file\n",
    "        FROM subjects s\n",
    "        INNER JOIN exercises e\n",
    "        ON s.id = e.subject_id\n",
    "        INNER JOIN paradigms p\n",
    "        ON p.id = e.paradigm_id\n",
    "        INNER JOIN repetitions r\n",
    "        ON e.id = r.exercise_id\n",
    "        WHERE p.abbreviation = '{}'\n",
    "        AND s.id = {}\n",
    "        AND sequence_num <= {}\n",
    "        \"\"\".format(key, eval_subject, num_test_repetitions)\n",
    "    # get data from data base and close connection\n",
    "    test_data_points[key] = pd.read_sql_query(query_sql, conn)\n",
    "conn.close()\n",
    "\n",
    "print('Length of the individual data frames:')\n",
    "num_data_points_test = 0\n",
    "for key in exercise_abbrs:\n",
    "    print(key + ':\\t' + str(test_data_points[key].shape[0]))\n",
    "    num_data_points_test += test_data_points[key].shape[0]\n",
    "print('total:\\t' + str(num_data_points_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-03T12:17:12.289399Z",
     "start_time": "2019-01-03T12:17:12.150391Z"
    }
   },
   "outputs": [],
   "source": [
    "def rotate_signal(signal_data, axis=0, rot_angle=90, signals=['Acc','Gyr']):\n",
    "    \n",
    "    if rot_angle != 0:\n",
    "        \n",
    "        # if no signals are given as keys, select all keys of the input dictionary\n",
    "        if signals is None:\n",
    "            signals = [*signal_data]\n",
    "        \n",
    "        # create rotation matrix\n",
    "        R = skin.rotmat.R(axis=axis, angle=rot_angle)\n",
    "        \n",
    "        # dictionary for rotated data\n",
    "        rot_signal_data = {}\n",
    "        \n",
    "        # rotate the signals\n",
    "        for sig in signals: \n",
    "            rot_signal_data[sig] = (R @ signal_data[sig].T).T\n",
    "    else:\n",
    "        rot_signal_data = signal_data\n",
    "        \n",
    "    return rot_signal_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-03T12:17:24.780113Z",
     "start_time": "2019-01-03T12:17:12.294399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 100%\n"
     ]
    }
   ],
   "source": [
    "X_test = np.zeros((num_data_points_test, number_sections*6))\n",
    "y_test = np.zeros(num_data_points_test, dtype=np.int8)\n",
    "\n",
    "rot_axis = 0 # 0,1,2 --> x,y,z\n",
    "rot_angle = 0 # deg\n",
    "\n",
    "count = 0\n",
    "y_pos = 0\n",
    "prev_prog = 0\n",
    "max_num = num_data_points_test\n",
    "\n",
    "# go through all exercises\n",
    "for ex in exercise_abbrs:\n",
    "    \n",
    "    # go through all repetitions (data points) of the current exercise\n",
    "    for ii in range(len(test_data_points[ex])):\n",
    "\n",
    "        # join file path\n",
    "        file_path = os.path.join(csv_dir, test_data_points[ex]['csv_file'][ii])\n",
    "\n",
    "        # load the signal data of the corresponding time range of the current repetition\n",
    "        selected_data = fmpm.get_sensor_data(in_file = file_path, \n",
    "                                             signals = sig_names, \n",
    "                                             sampling_rate = sampling_rate, \n",
    "                                             start_time = float(test_data_points[ex]['start_time'][ii]), \n",
    "                                             stop_time = float(test_data_points[ex]['stop_time'][ii]))\n",
    "        \n",
    "        # rotate the signals\n",
    "        rot_data = rotate_signal(selected_data, axis=rot_axis, rot_angle=rot_angle, signals=['Acc','Gyr'])\n",
    "        \n",
    "        # calculate the corresponding section means of the current repetition\n",
    "        section_means = fmpm.split_range_into_sections(signal_data = rot_data,\n",
    "                                                       num_sec = number_sections,\n",
    "                                                       signals = sig_names)\n",
    "        \n",
    "        # generate features\n",
    "        col = 0\n",
    "        for sig in sig_names:\n",
    "            for jj in [0,1,2]: # x, y, z comp. of the corresponding signal\n",
    "                X_test[count, col:col+number_sections] = section_means[sig][:,jj]\n",
    "                col += number_sections\n",
    "        \n",
    "        count += 1\n",
    "        prev_prog = fmpm.print_progress(count, max_num, prev_prog)\n",
    "    \n",
    "    label = exercise_dict[ex]\n",
    "    y_test[y_pos:y_pos+len(test_data_points[ex])] = label\n",
    "    y_pos += len(test_data_points[ex])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-03T12:17:24.999126Z",
     "start_time": "2019-01-03T12:17:24.788114Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-03T12:17:25.808172Z",
     "start_time": "2019-01-03T12:17:25.002126Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=40,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=-1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create random forest classifier\n",
    "ML_model = RandomForestClassifier(n_estimators=500, max_leaf_nodes=40, n_jobs=-1, random_state=42)\n",
    "\n",
    "# train the model\n",
    "ML_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-03T12:17:26.127190Z",
     "start_time": "2019-01-03T12:17:25.826173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestClassifier\n",
      "\n",
      "Features: Means of 10 sections per signal (3 x Acc + 3 x Gyr) --> 60 features\n",
      "\n",
      "Total Accuracy: 0.98033\n",
      "\n",
      "\n",
      "Exercise\tPrecision [%]\tRecall [%]\tAccuracy[%]\n",
      "  RF\t\t   83.33\t  100.00\t   99.02\n",
      "  RO\t\t  100.00\t   66.67\t   98.36\n",
      "  RS\t\t  100.00\t  100.00\t  100.00\n",
      "  LR\t\t  100.00\t   93.33\t   99.67\n",
      "  BC\t\t  100.00\t  100.00\t  100.00\n",
      "  TC\t\t  100.00\t  100.00\t  100.00\n",
      "  MP\t\t  100.00\t  100.00\t  100.00\n",
      "  SA\t\t  100.00\t  100.00\t  100.00\n",
      "  P1\t\t  100.00\t  100.00\t  100.00\n",
      "  P2\t\t  100.00\t  100.00\t  100.00\n",
      "  NE\t\t   98.10\t  100.00\t   99.02\n",
      "\n",
      "\n",
      "6 misclassified (305 test data points):\n",
      "RO classified as NE\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RO classified as NE\n",
      "RO classified as RF\n",
      "LR classified as NE\n"
     ]
    }
   ],
   "source": [
    "# predict labels\n",
    "y_pred = ML_model.predict(X_test)\n",
    "\n",
    "# show results\n",
    "print('Model: ' + ML_model.__class__.__name__ + '\\n')\n",
    "print('Features: Means of {} sections per signal (3 x Acc + 3 x Gyr) --> {} features\\n'.format(number_sections,\n",
    "                                                                                              number_sections*6))\n",
    "print('Total Accuracy: {:.5f}'.format((accuracy_score(y_test, y_pred))))\n",
    "print('\\n')\n",
    "fmpm.print_precision_recall_accuracy(y_pred, y_test)\n",
    "print('\\n')\n",
    "fmpm.print_misclassified_data_points(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
