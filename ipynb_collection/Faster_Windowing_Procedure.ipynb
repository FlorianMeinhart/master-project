{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faster Windowing Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The windowing follows a certain procedure:\n",
    "\n",
    ">•\tTaking a 1 s block of the data\n",
    "\n",
    ">•\tVarying the block length from 1 s to 5 s with an increment of 200 ms (starting point remains the same for all blocks)\n",
    "\n",
    ">•\tSectioning and feature generation for all blocks\n",
    "\n",
    ">•\tFor each block class probabilities are calculated (ML classifier) \n",
    "\n",
    ">•\tSliding the starting point with an increment of 200 ms and starting again with a 1 s block varying to 5 s\n",
    "\n",
    "*see animation below*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T11:09:34.783769Z",
     "start_time": "2018-12-18T11:09:34.759768Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"windowing_procedure.gif\" width=600 >"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<img src=\"windowing_procedure.gif\" width=600 >')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T11:09:37.043899Z",
     "start_time": "2018-12-18T11:09:34.949779Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import functionsMasterProjectMeinhart as fmpm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the test subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T11:09:39.458037Z",
     "start_time": "2018-12-18T11:09:39.442036Z"
    }
   },
   "outputs": [],
   "source": [
    "# define the test subject\n",
    "test_subject = 'subject01'\n",
    "\n",
    "# path to the csv-file with the whole record of the test subject\n",
    "test_subject_dir = 'E:\\Physio_Data\\Subject_' + test_subject[-2:] # last two characters of the test subject (e.g. '01')\n",
    "test_subject_file = test_subject + '.csv'\n",
    "test_subject_path = os.path.join(test_subject_dir, test_subject_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and filtering of test subject data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T09:57:04.526949Z",
     "start_time": "2018-12-18T09:57:02.922857Z"
    }
   },
   "outputs": [],
   "source": [
    "# sampling rate of the signals\n",
    "sampling_rate = 256 # [Hz]\n",
    "\n",
    "# signal names\n",
    "sig_names= ['Acc','Gyr']\n",
    "\n",
    "# get data from selected file\n",
    "sensor_data = fmpm.get_sensor_data(in_file=test_subject_path,\n",
    "                                   signals=sig_names,\n",
    "                                   sampling_rate=sampling_rate)\n",
    "\n",
    "# filter properties according to Crema\n",
    "cutoff = 10 # [Hz]\n",
    "order = 6 # butterworth order\n",
    "\n",
    "# filter data with butterworth filter and save to new dictionary\n",
    "sensor_data_filt = {}\n",
    "for signal in sig_names:\n",
    "    sensor_data_filt[signal] = fmpm.butter_lowpass_filter(sensor_data[signal], \n",
    "                                                          cutoff=cutoff, \n",
    "                                                          fs=sampling_rate, \n",
    "                                                          order=order)\n",
    "    \n",
    "np.shape(sensor_data_filt['Acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Windowing procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T10:03:53.915365Z",
     "start_time": "2018-12-18T10:03:53.854361Z"
    }
   },
   "outputs": [],
   "source": [
    "# number of sections to split the signal\n",
    "number_sections = 10\n",
    "\n",
    "# abbreviations for exercises / non-exercise\n",
    "exercise_abbrs = ['RF','RO','RS','LR','BC','TC','MP','SA','P1','P2','NE']\n",
    "\n",
    "# window start increment\n",
    "win_start_inc = 0.2 # [s]\n",
    "\n",
    "# window stretch increment\n",
    "win_stretch_inc = 0.2 # [s]\n",
    "\n",
    "# minimum window length\n",
    "win_min_len = 1 # [s]\n",
    "\n",
    "# maximim window length\n",
    "win_max_len = 5 # [s]\n",
    "\n",
    "# signal length (all sensor data must have same length --> Acc, Gyr, ...)\n",
    "signal_len = np.shape(sensor_data_filt[sig_names[0]])[0]\n",
    "\n",
    "# window start time\n",
    "win_start = 0 # [s]\n",
    "\n",
    "# last window start time --> time where the minimum window length just fits into the sensor data\n",
    "win_last_start = signal_len/sampling_rate - win_min_len\n",
    "\n",
    "# number of different window sizes\n",
    "num_win_sizes = len(np.arange(win_min_len, win_max_len+win_stretch_inc, win_stretch_inc))\n",
    "\n",
    "# number of different window start points\n",
    "num_start_points = len(np.arange(win_start, win_last_start, win_start_inc))\n",
    "\n",
    "# dictionary with matrices to save predicted values for all classes\n",
    "pred_matrix = {}\n",
    "for ex in exercise_abbrs:\n",
    "    pred_matrix[ex] = np.zeros([num_start_points, num_win_sizes])\n",
    "\n",
    "# matrix with all generated features\n",
    "feature_map = np.zeros([num_start_points * num_win_sizes, number_sections*6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Windowing the filtered signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T10:53:36.155939Z",
     "start_time": "2018-12-18T10:53:25.965356Z"
    }
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "max_count = len(feature_map)\n",
    "prev_progress = 0 # previous progress\n",
    "\n",
    "break_flag = False\n",
    "\n",
    "# going through all window start points\n",
    "for ii, win_pos in enumerate(np.arange(win_start, win_last_start, win_start_inc)):\n",
    "    \n",
    "    if break_flag is True:\n",
    "        break\n",
    "    \n",
    "    # going through all window lengths  (+win_stretch_inc to include end point)\n",
    "    for jj, win_len in enumerate(np.arange(win_min_len, win_max_len+win_stretch_inc, win_stretch_inc)):\n",
    "        \n",
    "        # calculate start and stop index\n",
    "        start_index = win_pos * sampling_rate\n",
    "        stop_index = start_index + (win_len * sampling_rate)\n",
    "        \n",
    "        # check if stop index is out of range\n",
    "        if stop_index >= signal_len:\n",
    "            stop_index = signal_len-1 # set equal to last index\n",
    "        \n",
    "        # get indices of the sections\n",
    "        section_indices, step = np.linspace(start_index, stop_index, number_sections, endpoint=False, retstep=True)\n",
    "        \n",
    "        #  + step/2 in order to get the indices in the middle of the sections\n",
    "        section_indices = (section_indices + step/2).round().astype(int)\n",
    "        \n",
    "        try:\n",
    "            # putting the feature map together\n",
    "            feature_map[count,:] = np.concatenate((sensor_data_filt[sig_names[0]][section_indices,:].transpose(), \n",
    "                                                   sensor_data_filt[sig_names[1]][section_indices,:].transpose())).flatten().reshape(1, -1)\n",
    "        except:\n",
    "            print(count)\n",
    "            break_flag = True\n",
    "            break\n",
    "        count += 1\n",
    "    \n",
    "    prev_progress = fmpm.print_progress(count, max_count, prev_progress)\n",
    "    \n",
    "print('\\nShape of feature map:')\n",
    "np.shape(feature_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to automatize procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T13:22:50.602104Z",
     "start_time": "2018-12-18T13:22:50.296087Z"
    }
   },
   "outputs": [],
   "source": [
    "def signal_windowing_via_indices(test_subject_path,\n",
    "                                 number_sections=10,\n",
    "                                 sig_names=['Acc','Gyr'],\n",
    "                                 sampling_rate=256,\n",
    "                                 cutoff=10,\n",
    "                                 order=6,\n",
    "                                 win_start_inc=0.2,\n",
    "                                 win_stretch_inc=0.2,\n",
    "                                 win_min_len=1,\n",
    "                                 win_max_len=5,\n",
    "                                 win_start=0,\n",
    "                                 win_last_start=None):\n",
    "    '''\n",
    "    This function applies a defined windowing procedure in order to split a signal \n",
    "    into different sections, which can be then taken as features for machine learning.\n",
    "    The different section values are determined by taking the index in the middle of\n",
    "    the corresponding section.\n",
    "    In order to avoid extreme outliers a butterworth filter is used before sectioning.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    test_subject_path : str\n",
    "        Path to the csv-file of the test subject data.\n",
    "        \n",
    "    number_sections: int\n",
    "        Number of sections to split each window.\n",
    "        \n",
    "    sig_names : list of strings\n",
    "        Signal names, used as keys for signal dictionaries.\n",
    "        \n",
    "    sampling_rate : int or float\n",
    "        Sampling rate of the signals.\n",
    "        \n",
    "    cutoff : int or float\n",
    "        Cutoff frequency of the butterworh filter.\n",
    "        \n",
    "    order : int\n",
    "        Order of the butterworth filter.\n",
    "        \n",
    "    win_start_inc : int or float\n",
    "        Start increment for the window [s].\n",
    "        \n",
    "    win_stretch_inc : int or float\n",
    "        Stretch increment for the window [s].\n",
    "    \n",
    "    win_min_len : int or float\n",
    "        Minimum window length [s].\n",
    "    \n",
    "    win_max_len : int or float\n",
    "        Maximum window length [s].\n",
    "    \n",
    "    win_start : int or float\n",
    "        Start time of the window [s].\n",
    "    \n",
    "    win_last_start : int or float or None\n",
    "        Last start time of the window [s].\n",
    "        If None, set to time where the minimum window length just fits into the sensor data.\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        list[0] : numpy.ndarray\n",
    "            Matrix with sectioned signal data.\n",
    "                (Number of columns = number of features)\n",
    "                (Number of rows = number of data points)\n",
    "        list[1] : int\n",
    "            Length of the original signals (number of indices).\n",
    "    '''\n",
    "\n",
    "\n",
    "    # get data from selected file\n",
    "    sensor_data = fmpm.get_sensor_data(in_file=test_subject_path,\n",
    "                                       signals=sig_names,\n",
    "                                       sampling_rate=sampling_rate)\n",
    "\n",
    "    # filter data with butterworth filter and save to new dictionary\n",
    "    sensor_data_filt = {}\n",
    "    for signal in sig_names:\n",
    "        sensor_data_filt[signal] = fmpm.butter_lowpass_filter(sensor_data[signal], \n",
    "                                                              cutoff=cutoff, \n",
    "                                                              fs=sampling_rate, \n",
    "                                                              order=order)\n",
    "\n",
    "    # signal length: all sensor data must have same length --> Acc, Gyr, ...\n",
    "    # --> but to ensure that indices are not out of range in case of wrong input data\n",
    "    # let's take the smallest stop index of the different signals\n",
    "    signal_len = float('inf')\n",
    "    for sig in sig_names:\n",
    "        if np.shape(sensor_data_filt[sig])[0] < signal_len:\n",
    "            signal_len = np.shape(sensor_data_filt[sig])[0]\n",
    "\n",
    "    # last window start time --> time where the minimum window length just fits into the sensor data\n",
    "    if win_last_start is None:\n",
    "        win_last_start = signal_len/sampling_rate - win_min_len\n",
    "\n",
    "    # number of different window sizes\n",
    "    num_win_sizes = len(np.arange(win_min_len, win_max_len+win_stretch_inc, win_stretch_inc))\n",
    "\n",
    "    # number of different window start points\n",
    "    num_start_points = len(np.arange(win_start, win_last_start+win_start_inc, win_start_inc))\n",
    "\n",
    "    # matrix with all generated features\n",
    "    feature_map = np.zeros([num_start_points * num_win_sizes, number_sections*6])\n",
    "    \n",
    "    # count for current position in the feature map\n",
    "    count = 0\n",
    "    \n",
    "    # variables for progress printing\n",
    "    max_count = len(feature_map)\n",
    "    prev_progress = 0 # previous progress\n",
    "\n",
    "    # going through all window start points\n",
    "    for ii, win_pos in enumerate(np.arange(win_start, win_last_start+win_start_inc, win_start_inc)):\n",
    "\n",
    "        # going through all window lengths  (+win_stretch_inc to include end point)\n",
    "        for jj, win_len in enumerate(np.arange(win_min_len, win_max_len+win_stretch_inc, win_stretch_inc)):\n",
    "\n",
    "            # calculate start and stop index\n",
    "            start_index = win_pos * sampling_rate\n",
    "            stop_index = start_index + (win_len * sampling_rate)\n",
    "\n",
    "            # check if stop index is out of range\n",
    "            if stop_index >= signal_len:\n",
    "                stop_index = signal_len-1 # set equal to last index\n",
    "\n",
    "            # get indices of the sections\n",
    "            section_indices, step = np.linspace(start_index, stop_index, number_sections, endpoint=False, retstep=True)\n",
    "\n",
    "            #  + step/2 in order to get the indices in the middle of the sections\n",
    "            section_indices = (section_indices + step/2).round().astype(int)\n",
    "\n",
    "            # putting the feature map together\n",
    "            feature_map[count,:] = np.concatenate((sensor_data_filt[sig_names[0]][section_indices,:].transpose(), \n",
    "                                                       sensor_data_filt[sig_names[1]][section_indices,:].transpose())).flatten().reshape(1, -1)\n",
    "\n",
    "            count += 1\n",
    "        \n",
    "        # print progress of feauture map generation\n",
    "        prev_progress = fmpm.print_progress(count, max_count, prev_progress)\n",
    "    \n",
    "    return feature_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Test the function:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T11:38:33.303207Z",
     "start_time": "2018-12-18T11:38:21.356524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 100%\n"
     ]
    }
   ],
   "source": [
    "feature_map = signal_windowing_via_indices(test_subject_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T11:38:34.726288Z",
     "start_time": "2018-12-18T11:38:34.709287Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12656700"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_map.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T11:45:49.662165Z",
     "start_time": "2018-12-18T11:45:49.640164Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210945, 60)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
