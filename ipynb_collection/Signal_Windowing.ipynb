{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal Windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T15:19:53.150694Z",
     "start_time": "2018-12-09T15:19:38.546859Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider, Button, RadioButtons, TextBox\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import functionsMasterProjectMeinhart as fmpm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T15:19:54.393765Z",
     "start_time": "2018-12-09T15:19:53.169695Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# load all date, except data from one subject (test data)\n",
    "test_data_subject = 9\n",
    "\n",
    "db_name='DataBase_Pysio.db' # database name\n",
    "\n",
    "exercise_abbrs = ['RF','RO','RS','LR','BC','TC','MP','SA','P1','P2'] # exercise abbreviations\n",
    "\n",
    "\n",
    "# Connect to an existing database\n",
    "conn = sqlite3.connect(db_name)\n",
    "cur = conn.cursor()\n",
    "\n",
    "# dictionary with the exercise abbreviation as key\n",
    "data_points = {}\n",
    "\n",
    "for key in exercise_abbrs:\n",
    "    # sql command to extract data\n",
    "    query_sql = \"\"\"\n",
    "        SELECT r.start_time, r.stop_time, e.csv_file\n",
    "        FROM subjects s\n",
    "        INNER JOIN exercises e\n",
    "        ON s.id = e.subject_id\n",
    "        INNER JOIN paradigms p\n",
    "        ON p.id = e.paradigm_id\n",
    "        INNER JOIN repetitions r\n",
    "        ON e.id = r.exercise_id\n",
    "        WHERE p.abbreviation = '{}'\n",
    "        AND NOT s.id = {}\n",
    "        \"\"\".format(key, test_data_subject)\n",
    "\n",
    "    # get data from data base and close connection\n",
    "    data_points[key] = pd.read_sql_query(query_sql, conn)\n",
    "    \n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T15:19:54.559774Z",
     "start_time": "2018-12-09T15:19:54.529773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of one loaded data frame as an example:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>stop_time</th>\n",
       "      <th>csv_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1482924107142871</td>\n",
       "      <td>3.699122023809525</td>\n",
       "      <td>subject01_RF_05.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.699122023809525</td>\n",
       "      <td>6.49581473214286</td>\n",
       "      <td>subject01_RF_05.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.49581473214286</td>\n",
       "      <td>9.384706101190478</td>\n",
       "      <td>subject01_RF_05.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.384706101190478</td>\n",
       "      <td>12.073833705357146</td>\n",
       "      <td>subject01_RF_05.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.073833705357146</td>\n",
       "      <td>14.809060639880954</td>\n",
       "      <td>subject01_RF_05.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           start_time           stop_time             csv_file\n",
       "0  1.1482924107142871   3.699122023809525  subject01_RF_05.csv\n",
       "1   3.699122023809525    6.49581473214286  subject01_RF_05.csv\n",
       "2    6.49581473214286   9.384706101190478  subject01_RF_05.csv\n",
       "3   9.384706101190478  12.073833705357146  subject01_RF_05.csv\n",
       "4  12.073833705357146  14.809060639880954  subject01_RF_05.csv"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Head of one loaded data frame as an example:')\n",
    "data_points['RF'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T15:19:54.763786Z",
     "start_time": "2018-12-09T15:19:54.744785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the individual data frames:\n",
      "RF:\t239\n",
      "RO:\t240\n",
      "RS:\t240\n",
      "LR:\t240\n",
      "BC:\t243\n",
      "TC:\t242\n",
      "MP:\t242\n",
      "SA:\t243\n",
      "P1:\t240\n",
      "P2:\t240\n",
      "total:\t2409\n"
     ]
    }
   ],
   "source": [
    "print('Length of the individual data frames:')\n",
    "count = 0\n",
    "for key in exercise_abbrs:\n",
    "    print(key + ':\\t' + str(data_points[key].shape[0]))\n",
    "    count += data_points[key].shape[0]\n",
    "print('total:\\t' + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T15:19:54.992799Z",
     "start_time": "2018-12-09T15:19:54.916795Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_range_into_sections(signal_data, num_sec=10, signals=['Acc','Gyr'], start_index=0, stop_index=None):\n",
    "    '''\n",
    "    This function splits a selected range of the input signals into a defined number \n",
    "    of equally distributed sections. For each signal and section the mean is calculated,\n",
    "    and afterwards returned by means of a dictionary.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    signal_data : dict\n",
    "        Dictionary with the signals in the 'signals' argument as keys.\n",
    "        The signal arrays must have same length.\n",
    "    \n",
    "    num_sec : int\n",
    "        Number of sections to split the signals.\n",
    "        \n",
    "    signals : list\n",
    "        Keys to select signals in the signal_data dictionary.\n",
    "        If no keys are provided, all keys of the signal_data\n",
    "        dictionary are taken.\n",
    "        \n",
    "    start_index : int\n",
    "        Start index of selected range (default=0).\n",
    "    \n",
    "    stop_index : int\n",
    "        Stop index of selected range.\n",
    "        If not given --> take length of signal data.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Dictionary with section means for each signal --> keys are same as the selected\n",
    "    in the list \"signals\".\n",
    "    '''\n",
    "    \n",
    "    # if no signals are given as keys, select all keys of the input dictionary\n",
    "    if not signals:\n",
    "        signals = [*signal_data]\n",
    "    \n",
    "    # number of input data points of each signal (signals have to be of the same length --> take index 0)\n",
    "    len_signals = np.shape(signal_data[signals[0]])[0]\n",
    "    \n",
    "    # check if stop index is given\n",
    "    if stop_index is None:\n",
    "        stop_index = len_signals\n",
    "    \n",
    "    # get indices of the sections (+1 due to start and end index of each section)\n",
    "    sec_ind = np.linspace(start_index, stop_index, num_sec+1).round().astype(int)\n",
    "    \n",
    "    # dicitonary to save sections means for each signal\n",
    "    section_means = {}\n",
    "\n",
    "    for signal in signals:\n",
    "        # generate row with zeros in order to use np.vstack afterwards\n",
    "        section_means[signal] = np.zeros([1, np.shape(signal_data[signal])[1]])\n",
    "\n",
    "        # add the mean of each section\n",
    "        for ii in range(len(sec_ind)-1):\n",
    "            section_means[signal] = np.vstack([section_means[signal], \n",
    "                                               np.mean(signal_data[signal][sec_ind[ii]:sec_ind[ii+1]], axis=0)])\n",
    "\n",
    "        # delete the first row with the zeros\n",
    "        section_means[signal] = np.delete(section_means[signal], 0, axis=0)\n",
    "        \n",
    "    return section_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T15:19:55.127807Z",
     "start_time": "2018-12-09T15:19:55.113806Z"
    }
   },
   "outputs": [],
   "source": [
    "number_sections = 10 # number of sections to split the signals\n",
    "\n",
    "csv_dir='E:\\Physio_Data_Split_Exercise_done' # directory of csv files\n",
    "#  csv-file to save the features\n",
    "feature_csv_file = '1_ML_Approach_Features/features_without_sub9_sections_'+'{:02}'.format(number_sections)+'.csv' \n",
    "\n",
    "sampling_rate = 256 # [Hz]\n",
    "signals = ['Acc','Gyr'] # signals which shall be considered for the mean calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Execute cell below only if csv-file does not already exist***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-07T20:10:11.585294Z",
     "start_time": "2018-12-07T20:08:08.380247Z"
    }
   },
   "outputs": [],
   "source": [
    "# putting the header of the feature-file together\n",
    "header_string = 'label;' # first column contains the labels\n",
    "\n",
    "for sig in signals:\n",
    "    for ax in ['_x','_y','_z']:\n",
    "        for ii in range(number_sections):\n",
    "            header_string +=  sig + ax + '_{:02}'.format(ii+1) + ';'\n",
    "\n",
    "# remove last separator (;)\n",
    "idx_last_sep = header_string.rfind(\";\")\n",
    "header_string =  header_string[:idx_last_sep]\n",
    "\n",
    "# write header to file\n",
    "with open(feature_csv_file, 'w') as feature_file:\n",
    "    feature_file.writelines(header_string + '\\n')\n",
    "\n",
    "\n",
    "# go through all exercises\n",
    "for ex in exercise_abbrs:\n",
    "    \n",
    "    # go through all repetitions (data points) of the current exercise\n",
    "    for ii in range(len(data_points[ex])):\n",
    "        \n",
    "        # join file path\n",
    "        file_path = os.path.join(csv_dir, data_points[ex]['csv_file'][ii])\n",
    "        \n",
    "        # load the signal data of the corresponding time range of the current repetition\n",
    "        selected_data = fmpm.get_sensor_data(in_file = file_path, \n",
    "                                             signals = signals, \n",
    "                                             sampling_rate = sampling_rate, \n",
    "                                             start_time = float(data_points[ex]['start_time'][ii]), \n",
    "                                             stop_time = float(data_points[ex]['stop_time'][ii]))\n",
    "         \n",
    "        # calculate the corresponding section means of the current repetition\n",
    "        section_means = split_range_into_sections(signal_data = selected_data,\n",
    "                                                  num_sec = number_sections,\n",
    "                                                  signals = signals)\n",
    "        \n",
    "        # string to write data of the current data point to the csv-file\n",
    "        data_point_string = ex + ';' # first column contains the label\n",
    "        \n",
    "        # copy section mean values to string\n",
    "        for sig in signals:\n",
    "            for jj in [0,1,2]: # x, y, z comp. of the corresponding signal\n",
    "                for ll in range(number_sections):\n",
    "                    \n",
    "                    # append to string for writing to csv file (5 decimals)\n",
    "                    data_point_string += \"{:.5f};\".format(section_means[sig][ll,jj])\n",
    "                    \n",
    "        # remove last separator (;)\n",
    "        idx_last_sep = data_point_string.rfind(\";\")\n",
    "        data_point_string =  data_point_string[:idx_last_sep]\n",
    "        \n",
    "        # append values of current data point to file\n",
    "        with open(feature_csv_file, 'a') as feature_file:\n",
    "            feature_file.writelines(data_point_string + '\\n')\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the generated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T15:20:55.844280Z",
     "start_time": "2018-12-09T15:20:55.134239Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2409 entries, 0 to 2408\n",
      "Data columns (total 61 columns):\n",
      "label       2409 non-null object\n",
      "Acc_x_01    2409 non-null float64\n",
      "Acc_x_02    2409 non-null float64\n",
      "Acc_x_03    2409 non-null float64\n",
      "Acc_x_04    2409 non-null float64\n",
      "Acc_x_05    2409 non-null float64\n",
      "Acc_x_06    2409 non-null float64\n",
      "Acc_x_07    2409 non-null float64\n",
      "Acc_x_08    2409 non-null float64\n",
      "Acc_x_09    2409 non-null float64\n",
      "Acc_x_10    2409 non-null float64\n",
      "Acc_y_01    2409 non-null float64\n",
      "Acc_y_02    2409 non-null float64\n",
      "Acc_y_03    2409 non-null float64\n",
      "Acc_y_04    2409 non-null float64\n",
      "Acc_y_05    2409 non-null float64\n",
      "Acc_y_06    2409 non-null float64\n",
      "Acc_y_07    2409 non-null float64\n",
      "Acc_y_08    2409 non-null float64\n",
      "Acc_y_09    2409 non-null float64\n",
      "Acc_y_10    2409 non-null float64\n",
      "Acc_z_01    2409 non-null float64\n",
      "Acc_z_02    2409 non-null float64\n",
      "Acc_z_03    2409 non-null float64\n",
      "Acc_z_04    2409 non-null float64\n",
      "Acc_z_05    2409 non-null float64\n",
      "Acc_z_06    2409 non-null float64\n",
      "Acc_z_07    2409 non-null float64\n",
      "Acc_z_08    2409 non-null float64\n",
      "Acc_z_09    2409 non-null float64\n",
      "Acc_z_10    2409 non-null float64\n",
      "Gyr_x_01    2409 non-null float64\n",
      "Gyr_x_02    2409 non-null float64\n",
      "Gyr_x_03    2409 non-null float64\n",
      "Gyr_x_04    2409 non-null float64\n",
      "Gyr_x_05    2409 non-null float64\n",
      "Gyr_x_06    2409 non-null float64\n",
      "Gyr_x_07    2409 non-null float64\n",
      "Gyr_x_08    2409 non-null float64\n",
      "Gyr_x_09    2409 non-null float64\n",
      "Gyr_x_10    2409 non-null float64\n",
      "Gyr_y_01    2409 non-null float64\n",
      "Gyr_y_02    2409 non-null float64\n",
      "Gyr_y_03    2409 non-null float64\n",
      "Gyr_y_04    2409 non-null float64\n",
      "Gyr_y_05    2409 non-null float64\n",
      "Gyr_y_06    2409 non-null float64\n",
      "Gyr_y_07    2409 non-null float64\n",
      "Gyr_y_08    2409 non-null float64\n",
      "Gyr_y_09    2409 non-null float64\n",
      "Gyr_y_10    2409 non-null float64\n",
      "Gyr_z_01    2409 non-null float64\n",
      "Gyr_z_02    2409 non-null float64\n",
      "Gyr_z_03    2409 non-null float64\n",
      "Gyr_z_04    2409 non-null float64\n",
      "Gyr_z_05    2409 non-null float64\n",
      "Gyr_z_06    2409 non-null float64\n",
      "Gyr_z_07    2409 non-null float64\n",
      "Gyr_z_08    2409 non-null float64\n",
      "Gyr_z_09    2409 non-null float64\n",
      "Gyr_z_10    2409 non-null float64\n",
      "dtypes: float64(60), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "feature_data = pd.read_csv(feature_csv_file, skiprows=0, sep=';')\n",
    "feature_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T15:20:58.281419Z",
     "start_time": "2018-12-09T15:20:58.248417Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Acc_x_01</th>\n",
       "      <th>Acc_x_02</th>\n",
       "      <th>Acc_x_03</th>\n",
       "      <th>Acc_x_04</th>\n",
       "      <th>Acc_x_05</th>\n",
       "      <th>Acc_x_06</th>\n",
       "      <th>Acc_x_07</th>\n",
       "      <th>Acc_x_08</th>\n",
       "      <th>Acc_x_09</th>\n",
       "      <th>...</th>\n",
       "      <th>Gyr_z_01</th>\n",
       "      <th>Gyr_z_02</th>\n",
       "      <th>Gyr_z_03</th>\n",
       "      <th>Gyr_z_04</th>\n",
       "      <th>Gyr_z_05</th>\n",
       "      <th>Gyr_z_06</th>\n",
       "      <th>Gyr_z_07</th>\n",
       "      <th>Gyr_z_08</th>\n",
       "      <th>Gyr_z_09</th>\n",
       "      <th>Gyr_z_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>-0.94158</td>\n",
       "      <td>-0.84232</td>\n",
       "      <td>-0.06218</td>\n",
       "      <td>0.52175</td>\n",
       "      <td>0.58297</td>\n",
       "      <td>0.22722</td>\n",
       "      <td>-0.43416</td>\n",
       "      <td>-0.99045</td>\n",
       "      <td>-0.97328</td>\n",
       "      <td>...</td>\n",
       "      <td>103.51442</td>\n",
       "      <td>174.14299</td>\n",
       "      <td>124.47019</td>\n",
       "      <td>38.04615</td>\n",
       "      <td>-11.82500</td>\n",
       "      <td>-100.36080</td>\n",
       "      <td>-155.38269</td>\n",
       "      <td>-134.52115</td>\n",
       "      <td>-63.53977</td>\n",
       "      <td>-4.68558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>-0.92893</td>\n",
       "      <td>-1.00249</td>\n",
       "      <td>-0.48374</td>\n",
       "      <td>0.21750</td>\n",
       "      <td>0.57440</td>\n",
       "      <td>0.36039</td>\n",
       "      <td>-0.31218</td>\n",
       "      <td>-0.95081</td>\n",
       "      <td>-0.93390</td>\n",
       "      <td>...</td>\n",
       "      <td>38.50087</td>\n",
       "      <td>139.13732</td>\n",
       "      <td>152.86458</td>\n",
       "      <td>90.02641</td>\n",
       "      <td>11.11632</td>\n",
       "      <td>-58.15191</td>\n",
       "      <td>-155.85739</td>\n",
       "      <td>-144.87066</td>\n",
       "      <td>-66.45246</td>\n",
       "      <td>3.56337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>-0.89641</td>\n",
       "      <td>-0.94826</td>\n",
       "      <td>-0.36936</td>\n",
       "      <td>0.29406</td>\n",
       "      <td>0.53504</td>\n",
       "      <td>0.32506</td>\n",
       "      <td>-0.23003</td>\n",
       "      <td>-0.86684</td>\n",
       "      <td>-0.95014</td>\n",
       "      <td>...</td>\n",
       "      <td>46.91807</td>\n",
       "      <td>133.67483</td>\n",
       "      <td>143.52111</td>\n",
       "      <td>59.91554</td>\n",
       "      <td>8.84122</td>\n",
       "      <td>-61.00942</td>\n",
       "      <td>-131.24409</td>\n",
       "      <td>-142.97044</td>\n",
       "      <td>-68.36571</td>\n",
       "      <td>3.00929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>-0.92039</td>\n",
       "      <td>-0.97978</td>\n",
       "      <td>-0.60092</td>\n",
       "      <td>0.12516</td>\n",
       "      <td>0.49953</td>\n",
       "      <td>0.38173</td>\n",
       "      <td>-0.17635</td>\n",
       "      <td>-0.73176</td>\n",
       "      <td>-0.95656</td>\n",
       "      <td>...</td>\n",
       "      <td>33.52264</td>\n",
       "      <td>126.68025</td>\n",
       "      <td>152.88496</td>\n",
       "      <td>100.61685</td>\n",
       "      <td>13.80423</td>\n",
       "      <td>-64.13678</td>\n",
       "      <td>-122.12228</td>\n",
       "      <td>-140.03351</td>\n",
       "      <td>-91.74547</td>\n",
       "      <td>-2.57428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF</td>\n",
       "      <td>-0.93697</td>\n",
       "      <td>-0.86661</td>\n",
       "      <td>-0.26934</td>\n",
       "      <td>0.26927</td>\n",
       "      <td>0.54755</td>\n",
       "      <td>0.39191</td>\n",
       "      <td>-0.08301</td>\n",
       "      <td>-0.61854</td>\n",
       "      <td>-0.90253</td>\n",
       "      <td>...</td>\n",
       "      <td>63.20268</td>\n",
       "      <td>139.25179</td>\n",
       "      <td>130.30089</td>\n",
       "      <td>63.78125</td>\n",
       "      <td>6.25268</td>\n",
       "      <td>-47.06964</td>\n",
       "      <td>-110.11339</td>\n",
       "      <td>-116.17143</td>\n",
       "      <td>-95.74554</td>\n",
       "      <td>-13.73214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  Acc_x_01  Acc_x_02  Acc_x_03  Acc_x_04  Acc_x_05  Acc_x_06  Acc_x_07  \\\n",
       "0    RF  -0.94158  -0.84232  -0.06218   0.52175   0.58297   0.22722  -0.43416   \n",
       "1    RF  -0.92893  -1.00249  -0.48374   0.21750   0.57440   0.36039  -0.31218   \n",
       "2    RF  -0.89641  -0.94826  -0.36936   0.29406   0.53504   0.32506  -0.23003   \n",
       "3    RF  -0.92039  -0.97978  -0.60092   0.12516   0.49953   0.38173  -0.17635   \n",
       "4    RF  -0.93697  -0.86661  -0.26934   0.26927   0.54755   0.39191  -0.08301   \n",
       "\n",
       "   Acc_x_08  Acc_x_09    ...      Gyr_z_01   Gyr_z_02   Gyr_z_03   Gyr_z_04  \\\n",
       "0  -0.99045  -0.97328    ...     103.51442  174.14299  124.47019   38.04615   \n",
       "1  -0.95081  -0.93390    ...      38.50087  139.13732  152.86458   90.02641   \n",
       "2  -0.86684  -0.95014    ...      46.91807  133.67483  143.52111   59.91554   \n",
       "3  -0.73176  -0.95656    ...      33.52264  126.68025  152.88496  100.61685   \n",
       "4  -0.61854  -0.90253    ...      63.20268  139.25179  130.30089   63.78125   \n",
       "\n",
       "   Gyr_z_05   Gyr_z_06   Gyr_z_07   Gyr_z_08  Gyr_z_09  Gyr_z_10  \n",
       "0 -11.82500 -100.36080 -155.38269 -134.52115 -63.53977  -4.68558  \n",
       "1  11.11632  -58.15191 -155.85739 -144.87066 -66.45246   3.56337  \n",
       "2   8.84122  -61.00942 -131.24409 -142.97044 -68.36571   3.00929  \n",
       "3  13.80423  -64.13678 -122.12228 -140.03351 -91.74547  -2.57428  \n",
       "4   6.25268  -47.06964 -110.11339 -116.17143 -95.74554 -13.73214  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T15:20:59.509489Z",
     "start_time": "2018-12-09T15:20:59.492488Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2409, 60)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get feature matrix\n",
    "X_original = feature_data.values[:,1:]\n",
    "np.shape(X_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T15:21:21.563751Z",
     "start_time": "2018-12-09T15:21:01.185585Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2409,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dictionary for labels\n",
    "label_ex = {'RF':0,\n",
    "            'RO':1,\n",
    "            'RS':2,\n",
    "            'LR':3,\n",
    "            'BC':4,\n",
    "            'TC':5,\n",
    "            'MP':6,\n",
    "            'SA':7,\n",
    "            'P1':8,\n",
    "            'P2':9}\n",
    "\n",
    "# get label array with labels (0 ... 9)\n",
    "y = [label_ex[feature_data.values[ii,0]] for ii in range(len(feature_data.values[:,0]))]\n",
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T15:28:22.150949Z",
     "start_time": "2018-12-09T15:28:22.027942Z"
    }
   },
   "outputs": [],
   "source": [
    "# get train data of separate exercises\n",
    "\n",
    "exercise_abbrs = ['RF','RO','RS','LR','BC','TC','MP','SA','P1','P2'] # exercise abbreviations\n",
    "\n",
    "X_ex = {} # dicitionary for separate feature matrices\n",
    "\n",
    "for ex in exercise_abbrs:\n",
    "    \n",
    "    ind = [ii for ii, ex_num in enumerate(y) if ex_num==label_ex[ex]] # indices for the current exercise\n",
    "\n",
    "    X_ex[ex] = feature_data.values[ind,1:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T15:29:00.889165Z",
     "start_time": "2018-12-09T15:29:00.878164Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 60)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_ex['RO'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML models to distinguish between exercise and non-exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T15:31:39.296225Z",
     "start_time": "2018-12-09T15:31:36.685076Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T16:06:42.191504Z",
     "start_time": "2018-12-09T16:06:42.088498Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate one LocalOutlierFactor model for each exercise\n",
    "distExNonex = {}\n",
    "for ex in exercise_abbrs:\n",
    "    distExNonex[ex] = LocalOutlierFactor(n_neighbors=20, novelty=True, contamination='auto')\n",
    "    distExNonex[ex].fit(X_ex[ex])\n",
    "\n",
    "# method: score_samples\n",
    "# returns: opposite_lof_scores : array, shape (n_samples,)\n",
    "# --> The opposite of the Local Outlier Factor of each input samples. The lower, the more abnormal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T15:55:59.388737Z",
     "start_time": "2018-12-09T15:55:59.231728Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(X_ex['RF']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Random Forest Classifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T12:43:28.043433Z",
     "start_time": "2018-12-09T12:43:27.889424Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T12:43:30.521575Z",
     "start_time": "2018-12-09T12:43:28.153439Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=40,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=-1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create random forest classifier\n",
    "rnd_clf_orig = RandomForestClassifier(n_estimators=500, max_leaf_nodes=40, n_jobs=-1, random_state=42)\n",
    "\n",
    "# train the model\n",
    "rnd_clf_orig.fit(X_original, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T15:57:08.855711Z",
     "start_time": "2018-12-09T15:57:07.319623Z"
    }
   },
   "outputs": [],
   "source": [
    "# select file (csv) of test subject\n",
    "file_dir  = r'E:\\Physio_Data\\Subject_09'\n",
    "file_name = 'subject09.csv'\n",
    "\n",
    "# selecet time range [min:sec]\n",
    "#start_min_sec = '01:36.0' # Raises Oblique\n",
    "#stop_min_sec  = '02:00.3'\n",
    "\n",
    "# selecet time range [min:sec]\n",
    "start_min_sec = '00:00.0'\n",
    "stop_min_sec  = '35:00.0'\n",
    "\n",
    "sampling_rate = 256 # [Hz]\n",
    "\n",
    "# split time string and convert to float\n",
    "start_min = float(start_min_sec.split(':')[0])\n",
    "start_sec = float(start_min_sec.split(':')[1])\n",
    "stop_min = float(stop_min_sec.split(':')[0])\n",
    "stop_sec = float(stop_min_sec.split(':')[1])\n",
    "\n",
    "# start and stop time in seconds\n",
    "start_time = start_min*60 + start_sec # [s]\n",
    "stop_time = stop_min*60 + stop_sec # [s]\n",
    "\n",
    "# join data path\n",
    "data_path = os.path.join(file_dir, file_name)\n",
    "\n",
    "# get data from selected file\n",
    "sensor_data = fmpm.get_sensor_data(in_file=data_path,\n",
    "                                   sampling_rate=sampling_rate,\n",
    "                                   start_time=start_time,\n",
    "                                   stop_time=stop_time)\n",
    "\n",
    "# filter properties\n",
    "cutoff = 10 # [Hz]\n",
    "order = 6 # butterworth order\n",
    "\n",
    "# filter data with butterworth filter and save to new dictionary\n",
    "signal_keys = ['Acc', 'Gyr']\n",
    "sensor_data_filt = {}\n",
    "for signal in signal_keys:\n",
    "    sensor_data_filt[signal] = fmpm.butter_lowpass_filter(sensor_data[signal], \n",
    "                                                          cutoff=cutoff, \n",
    "                                                          fs=sampling_rate, \n",
    "                                                          order=order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T15:57:09.132727Z",
     "start_time": "2018-12-09T15:57:09.106725Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_window_indices(signal_len, window_length=5, start_time=None, start_index=0, sampling_rate=256, auto_end=True):\n",
    "    '''\n",
    "    This function returns the indices of a certain time range,\n",
    "    selected via start time (or start index) and window length.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    signal_len : int\n",
    "        signal length (indices)\n",
    "        \n",
    "    window_length : float or int\n",
    "        window length in seconds to select data\n",
    "        \n",
    "    start_time : float or int\n",
    "        start time in seconds where data selection starts\n",
    "        \n",
    "    start_index : int\n",
    "        only used, if start_time is None;\n",
    "        start index where data selection starts\n",
    "        \n",
    "    sampling_rate : float or int\n",
    "        sampling rate of signal data\n",
    "        \n",
    "    auto_end : boolean\n",
    "        if True --> set stop index to signal length if out of range\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        start and stop indices,\n",
    "        or empty list if stop index is out of range and auto_end = False\n",
    "    '''\n",
    "    \n",
    "    # if start time is given --> convert to start index\n",
    "    if start_time is not None:\n",
    "        start_index = int(start_time * sampling_rate)\n",
    "    \n",
    "    # calculate stop index\n",
    "    stop_index = start_index + int(window_length * sampling_rate)\n",
    "    \n",
    "    if stop_index > signal_len:\n",
    "        if auto_end is True:\n",
    "            stop_index = signal_len\n",
    "        else:\n",
    "            return []\n",
    "    \n",
    "    return [start_index, stop_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Windowing the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T13:32:23.925913Z",
     "start_time": "2018-12-10T13:32:23.909912Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"windowing_procedure.gif\" width=600 >"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<img src=\"windowing_procedure.gif\" width=600 >')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T15:57:10.892827Z",
     "start_time": "2018-12-09T15:57:10.812823Z"
    }
   },
   "outputs": [],
   "source": [
    "# window start increment\n",
    "win_start_inc = 0.2 # [s]\n",
    "\n",
    "# window stretch increment\n",
    "win_stretch_inc = 0.2 # [s]\n",
    "\n",
    "# minimum window length\n",
    "win_min_len = 1 # [s]\n",
    "\n",
    "# maximim window length\n",
    "win_max_len = 5 # [s]\n",
    "\n",
    "# sampling rate of the signals\n",
    "sampling_rate = 256 # [Hz]\n",
    "\n",
    "# signal names\n",
    "sig_names = ['Acc','Gyr']\n",
    "\n",
    "# number of sections to split the signal\n",
    "number_sections = 10\n",
    "\n",
    "# signal length (all sensor data must have same length --> Acc, Gyr, ...)\n",
    "signal_len = len(sensor_data[sig_names[0]])\n",
    "\n",
    "# \n",
    "## selecet time range [min:sec]\n",
    "#win_start_min_sec = '30:00.0'\n",
    "#win_last_start_min_sec  = '34:45.0'\n",
    "## split time string and convert to float\n",
    "#win_start_min = float(win_start_min_sec.split(':')[0])\n",
    "#win_start_sec = float(win_start_min_sec.split(':')[1])\n",
    "#win_last_start_min = float(win_last_start_min_sec.split(':')[0])\n",
    "#win_last_start_sec = float(win_last_start_min_sec.split(':')[1])\n",
    "## start and stop time in seconds\n",
    "#win_start = win_start_min*60 + win_start_sec # [s]\n",
    "#win_last_start = win_last_start_min*60 + win_last_start_sec # [s]\n",
    "\n",
    "# ---> selsect all data\n",
    "# window start time\n",
    "win_start = 0 # [s]\n",
    "\n",
    "# last window start time --> time where the minimum window length just fits into the sensor data\n",
    "win_last_start = signal_len/sampling_rate - win_min_len\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# number of different window sizes\n",
    "num_win_sizes = len(np.arange(win_min_len, win_max_len+win_stretch_inc, win_stretch_inc))\n",
    "\n",
    "# number of different window start points\n",
    "num_start_points = len(np.arange(win_start, win_last_start, win_start_inc))\n",
    "\n",
    "# matrix to save the distinction values (exercise/non-exercise)\n",
    "dist_matrix = np.zeros([num_start_points, num_win_sizes])\n",
    "\n",
    "# matrices to save predicted values for all classes\n",
    "# exercise_abbrs = ['RF','RO','RS','LR','BC','TC','MP','SA','P1','P2']\n",
    "dist_matrix = {}\n",
    "for ex in exercise_abbrs:\n",
    "    dist_matrix[ex] = np.zeros([num_start_points, num_win_sizes])\n",
    "\n",
    "    \n",
    "feature_map = np.zeros([num_start_points * num_win_sizes, number_sections*6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T16:07:00.201534Z",
     "start_time": "2018-12-09T16:07:00.192533Z"
    }
   },
   "outputs": [],
   "source": [
    "# function to print progress\n",
    "\n",
    "def print_progress(current_num, max_num, prev_prog):\n",
    "    \n",
    "    new_prog = int(current_num/max_num*100)\n",
    "    \n",
    "    if new_prog > prev_prog:\n",
    "        clear_output(wait=True)\n",
    "        print('Progress: {:3d}%'.format(new_prog))\n",
    "        \n",
    "    return new_prog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T16:08:45.905580Z",
     "start_time": "2018-12-09T16:07:00.650559Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 100%\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "max_count = len(feature_map)\n",
    "prev_progress = 0 # previous progress\n",
    "\n",
    "# going through all window start points\n",
    "for ii, win_pos in enumerate(np.arange(win_start, win_last_start, win_start_inc)):\n",
    "\n",
    "    # going through all window lengths  (+win_stretch_inc to include end point)\n",
    "    for jj, win_len in enumerate(np.arange(win_min_len, win_max_len+win_stretch_inc, win_stretch_inc)):\n",
    "\n",
    "        [idx_start, idx_stop] = get_window_indices(signal_len, \n",
    "                                                   window_length = win_len, \n",
    "                                                   start_time = win_pos,\n",
    "                                                   sampling_rate = sampling_rate, \n",
    "                                                   auto_end = True)\n",
    "\n",
    "        section_means = split_range_into_sections(sensor_data, \n",
    "                                                  num_sec = number_sections, \n",
    "                                                  signals = sig_names, \n",
    "                                                  start_index = idx_start, \n",
    "                                                  stop_index = idx_stop)\n",
    "        \n",
    "        \n",
    "        feature_map[count,:] = np.concatenate((section_means[sig_names[0]].transpose(), \n",
    "                                               section_means[sig_names[1]].transpose())).flatten().reshape(1, -1)\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "    prev_progress = print_progress(count, max_count, prev_progress)\n",
    "        \n",
    "        \n",
    "        #pred_probs = rnd_clf_orig.predict_proba(features)[0]\n",
    "        \n",
    "        #for kk, ex in enumerate(exercise_abbrs):\n",
    "        #    dist_matrix[ex][ii,jj] = pred_probs[kk]\n",
    "        \n",
    "        #dist_matrix[ii, jj] = distExNonex.score_samples(features)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T16:10:10.205401Z",
     "start_time": "2018-12-09T16:08:46.160594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 100%\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "max_count = 10 # 10 models\n",
    "prev_progress = 0 # previous progress\n",
    "\n",
    "scores_LOF = {}\n",
    "for ex in exercise_abbrs:\n",
    "    scores_LOF[ex] = distExNonex[ex].score_samples(feature_map)\n",
    "    count += 1\n",
    "    prev_progress = print_progress(count, max_count, prev_progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T12:46:39.655393Z",
     "start_time": "2018-12-09T12:46:26.877662Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220395, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "#pred_probs = rnd_clf_orig.predict_proba(feature_map)\n",
    "#np.shape(pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T16:11:16.810211Z",
     "start_time": "2018-12-09T16:11:14.267065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 100%\n"
     ]
    }
   ],
   "source": [
    "# creating the images\n",
    "\n",
    "count = 0\n",
    "max_count = len(feature_map)\n",
    "prev_progress = 0 # previous progress\n",
    "\n",
    "# going through all window start points\n",
    "for ii, win_pos in enumerate(np.arange(win_start, win_last_start, win_start_inc)):\n",
    "    # going through all window lengths  (+win_stretch_inc to include end point)\n",
    "    for jj, win_len in enumerate(np.arange(win_min_len, win_max_len+win_stretch_inc, win_stretch_inc)):\n",
    "        \n",
    "        for kk, ex in enumerate(exercise_abbrs):\n",
    "            # dist_matrix[ex][ii,jj] = pred_probs[count][kk] # for RFC probabilities\n",
    "            dist_matrix[ex][ii,jj] = scores_LOF[ex][count]\n",
    "            \n",
    "        count += 1\n",
    "        prev_progress = print_progress(count, max_count, prev_progress)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T16:01:46.888613Z",
     "start_time": "2018-12-09T16:01:46.756606Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T16:11:19.038338Z",
     "start_time": "2018-12-09T16:11:18.991336Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_time_format_to_index(min_sec, sampling_rate, time_offset=0, max_index=None):\n",
    "    '''\n",
    "    Function converts a string with the time format 'min:sec' (e.g. 5:17.2)\n",
    "    to a corresponding index, considering the sampling rate.\n",
    "    If index would be negative, 0 is returned.\n",
    "    \n",
    "    Inputs\n",
    "    ------\n",
    "    min_sec : string\n",
    "        Time data, defined format: 'min:sec'\n",
    "    \n",
    "    sampling_rate : float or int\n",
    "        Sampling rate for the index calculation. [Hz]\n",
    "        \n",
    "    time_offset : float of int\n",
    "        Time offset, considered at the index calculation. [s]\n",
    "        \n",
    "    max_index : int\n",
    "        Maximum valid index.\n",
    "        If provided and calculated index is out of range,\n",
    "        max_index is returned instead.\n",
    "     \n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        Corresponding index to parameter 'min_max'.\n",
    "    '''\n",
    "    \n",
    "    # split time string and convert to float\n",
    "    minutes = float(min_sec.split(':')[0])\n",
    "    seconds = float(min_sec.split(':')[1])\n",
    "    \n",
    "    # start and stop time in seconds\n",
    "    time_s = minutes*60 + seconds + time_offset\n",
    "    \n",
    "    # get corresponding index\n",
    "    index = round(time_s * sampling_rate)\n",
    "    \n",
    "    # ensure that index is not below 0\n",
    "    if index < 0:\n",
    "        index = 0\n",
    "    \n",
    "    # ensure that index is in valid range if max index is given\n",
    "    if max_index is not None and index > max_index:\n",
    "        index = max_index\n",
    "            \n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T16:11:20.044396Z",
     "start_time": "2018-12-09T16:11:19.892387Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(scores_LOF['MP']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T16:11:24.827670Z",
     "start_time": "2018-12-09T16:11:24.046625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib auto\n",
    "\n",
    "\n",
    "yticks = np.arange(0, win_max_len-win_min_len+win_stretch_inc, 1) / win_stretch_inc\n",
    "ylabels = ['{}'.format(yticks[ii] * win_stretch_inc + win_min_len) for ii in range(len(yticks))]\n",
    "\n",
    "\n",
    "fig, axis = plt.subplots(11,1,figsize=(18,8), sharex=True)\n",
    "fig.suptitle('Scores\\nLocal Outlier Factor', fontsize=20)\n",
    "\n",
    "# image color settings for RFC\n",
    "#vmin=0\n",
    "#vmax=1\n",
    "\n",
    "# image color settings for LOF\n",
    "vmin=-3\n",
    "vmax=-1\n",
    "\n",
    "for ax, ex in zip(axis, exercise_abbrs):\n",
    "    s = ax.imshow(dist_matrix[ex].transpose(), interpolation='nearest', \n",
    "                  aspect='auto', cmap=plt.cm.seismic, vmin=vmin, vmax=vmax)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_yticks(yticks)\n",
    "    ax.set_yticklabels(ylabels)\n",
    "    ax.set_ylabel(ex, fontsize=13)\n",
    "    ax.xaxis.set_ticklabels([])\n",
    "\n",
    "axis[-1].plot(range(num_start_points), np.zeros(num_start_points), 'k', alpha=0.0)\n",
    "formatter = matplotlib.ticker.FuncFormatter(lambda i, x: time.strftime('%M:%S', time.gmtime(i*win_start_inc+win_start)))\n",
    "axis[-1].xaxis.set_major_formatter(formatter)\n",
    "axis[-1].set_yticks([])\n",
    "axis[-1].set_ylim([0,1])\n",
    "axis[-1].set_xlabel(r'time $[min:sec]$', fontsize=13)\n",
    "\n",
    "fig.subplots_adjust(bottom=0.2, right=0.9) # make space for buttons and color bar\n",
    "cbar_ax = fig.add_axes([0.92, 0.1, 0.01, 0.8])\n",
    "fig.colorbar(s, cax=cbar_ax)\n",
    "\n",
    "\n",
    "# add slider for selections on the x axis\n",
    "Slider_shiftX_ax = plt.axes([0.1, 0.07, 0.75, 0.025])\n",
    "Slider_zoomX_ax = plt.axes([0.1, 0.035, 0.75, 0.025])\n",
    "\n",
    "axcolor = 'cornflowerblue'\n",
    "Slider_shiftX = Slider(Slider_shiftX_ax, 'x shift [%]', 0.0, 100.0, valinit=0, facecolor=axcolor)\n",
    "Slider_zoomX = Slider(Slider_zoomX_ax, 'x scale [%]', 0.1, 100.0, valinit=100, facecolor=axcolor)\n",
    "Slider_zoomX_ax.xaxis.set_visible(True)\n",
    "Slider_zoomX_ax.set_xticks(np.arange(0,105,5)) \n",
    "\n",
    "\n",
    "def updateX(val):\n",
    "    start_index = int(Slider_shiftX.val / 100 * num_start_points)\n",
    "    stop_index = start_index + Slider_zoomX.val / 100 * num_start_points\n",
    "    axis[-1].set_xlim((start_index, stop_index))\n",
    "    plt.draw()\n",
    "\n",
    "Slider_shiftX.on_changed(updateX)\n",
    "Slider_zoomX.on_changed(updateX)\n",
    "\n",
    "\n",
    "# add textboxes to select time range\n",
    "initial_start_text = \"00:00.0\"\n",
    "initial_stop_text = \"00:00.0\"\n",
    "\n",
    "\n",
    "def updateXval(text):\n",
    "    fig.suptitle(text_box_stop.text)\n",
    "    try:\n",
    "        start_index = convert_time_format_to_index(text_box_start.text, sampling_rate=1/win_start_inc, \n",
    "                                                   time_offset=0, max_index=None)\n",
    "        stop_index = convert_time_format_to_index(text_box_stop.text, sampling_rate=1/win_start_inc, \n",
    "                                                  time_offset=0, max_index=None)\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "        if start_index < stop_index:\n",
    "            axis[-1].set_xlim((start_index, stop_index))\n",
    "            plt.draw()\n",
    "        \n",
    "axbox_start = plt.axes([0.1, 0.12, 0.05, 0.03])\n",
    "text_box_start = TextBox(axbox_start, 'Start time: ', initial=initial_start_text)\n",
    "text_box_start.on_submit(updateXval)\n",
    "\n",
    "axbox_stop = plt.axes([0.2, 0.12, 0.05, 0.03])\n",
    "text_box_stop = TextBox(axbox_stop, 'Stop time: ', initial=initial_stop_text)\n",
    "text_box_stop.on_submit(updateXval)\n",
    "\n",
    "\n",
    "axis[-1].set_xlim(0, num_start_points)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
