{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 0,
        "width": 12
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "# Machine Learning Approach with Exercise and Non-Ex. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:07:26.014638Z",
     "start_time": "2019-01-15T09:07:26.000638Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import time\n",
    "import itertools\n",
    "import os\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider, TextBox, Button\n",
    "from IPython.display import clear_output\n",
    "import sys\n",
    "sys.path.append('..') # in order to import modules from my own package\n",
    "from packageMeinhart import functionsMasterProjectMeinhart as fmpm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 4,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:04:31.645665Z",
     "start_time": "2019-01-15T09:04:31.353648Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# load all data, except data from one subject (test data)\n",
    "test_data_subject = 1\n",
    "\n",
    "db_name='E:\\Physio_Data\\DataBase_Physio_with_nonEx.db' # database name\n",
    "exercise_abbrs = ['RF','RO','RS','LR','BC','TC','MP','SA','P1','P2','NE'] # exercise abbreviations\n",
    "# Connect to an existing database\n",
    "conn = sqlite3.connect(db_name)\n",
    "cur = conn.cursor()\n",
    "train_data_points = {} # dictionary with the exercise abbreviation as key\n",
    "for key in exercise_abbrs:\n",
    "    # sql command to extract data\n",
    "    query_sql = \"\"\"\n",
    "        SELECT r.start_time, r.stop_time, e.csv_file\n",
    "        FROM subjects s\n",
    "        INNER JOIN exercises e\n",
    "        ON s.id = e.subject_id\n",
    "        INNER JOIN paradigms p\n",
    "        ON p.id = e.paradigm_id\n",
    "        INNER JOIN repetitions r\n",
    "        ON e.id = r.exercise_id\n",
    "        WHERE p.abbreviation = '{}'\n",
    "        AND NOT s.id = {}\n",
    "        \"\"\".format(key, test_data_subject)\n",
    "    # get data from data base and close connection\n",
    "    train_data_points[key] = pd.read_sql_query(query_sql, conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:04:31.794674Z",
     "start_time": "2019-01-15T09:04:31.650665Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 7,
        "hidden": false,
        "row": 4,
        "width": 5
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>stop_time</th>\n",
       "      <th>csv_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.6097522701321</td>\n",
       "      <td>subject02_00_nonEx.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.6097522701321</td>\n",
       "      <td>5.98056861437206</td>\n",
       "      <td>subject02_00_nonEx.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.98056861437206</td>\n",
       "      <td>7.84471642992804</td>\n",
       "      <td>subject02_00_nonEx.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.84471642992804</td>\n",
       "      <td>12.3377339822144</td>\n",
       "      <td>subject02_00_nonEx.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.3377339822144</td>\n",
       "      <td>15.5979262935134</td>\n",
       "      <td>subject02_00_nonEx.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         start_time         stop_time                csv_file\n",
       "0                 0   3.6097522701321  subject02_00_nonEx.csv\n",
       "1   3.6097522701321  5.98056861437206  subject02_00_nonEx.csv\n",
       "2  5.98056861437206  7.84471642992804  subject02_00_nonEx.csv\n",
       "3  7.84471642992804  12.3377339822144  subject02_00_nonEx.csv\n",
       "4  12.3377339822144  15.5979262935134  subject02_00_nonEx.csv"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Head of one loaded data frame as an example:\n",
    "train_data_points['NE'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:04:31.916681Z",
     "start_time": "2019-01-15T09:04:31.797674Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 9,
        "hidden": false,
        "row": 8,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the individual data frames:\n",
      "RF:\t239\n",
      "RO:\t240\n",
      "RS:\t240\n",
      "LR:\t241\n",
      "BC:\t242\n",
      "TC:\t243\n",
      "MP:\t242\n",
      "SA:\t242\n",
      "P1:\t240\n",
      "P2:\t239\n",
      "NE:\t3712\n",
      "total:\t6120\n"
     ]
    }
   ],
   "source": [
    "print('Length of the individual data frames:')\n",
    "count = 0\n",
    "for key in exercise_abbrs:\n",
    "    print(key + ':\\t' + str(train_data_points[key].shape[0]))\n",
    "    count += train_data_points[key].shape[0]\n",
    "print('total:\\t' + str(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 11,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "## Generate and save features for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:04:32.098691Z",
     "start_time": "2019-01-15T09:04:31.924681Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 11,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Physio_Features\\features_without_subject01_Ex_nonEx_sections10.csv\n"
     ]
    }
   ],
   "source": [
    "# number of sections to split the signals\n",
    "number_sections = 10\n",
    "\n",
    "# directory of csv file\n",
    "csv_dir='E:\\Physio_Data_Split_Ex_and_NonEx'\n",
    "\n",
    "#  csv-file to save the features\n",
    "save_dir  = 'E:\\Physio_Features'\n",
    "save_file_name = 'features_without_subject{0:02}_Ex_nonEx_sections{1:02}.csv'.format(\n",
    "    test_data_subject, number_sections)\n",
    "feature_csv_file = os.path.join(save_dir, save_file_name)\n",
    "print(feature_csv_file)\n",
    "\n",
    "sampling_rate = 256 # [Hz]\n",
    "sig_names = ['Acc','Gyr'] # signals which shall be considered for the mean calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T12:05:12.986721Z",
     "start_time": "2018-12-10T12:05:12.965719Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 15,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "***Cell below is only executed if feature csv-file does not already exist***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:04:32.264700Z",
     "start_time": "2019-01-15T09:04:32.103691Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# this cell shall only be executed if the feature file does not already exist\n",
    "if not os.path.isfile(feature_csv_file):\n",
    "\n",
    "    # putting the header of the feature-file together\n",
    "    header_string = 'label;' # first column contains the labels\n",
    "\n",
    "    for sig in sig_names:\n",
    "        for ax in ['_x','_y','_z']:\n",
    "            for ii in range(number_sections):\n",
    "                header_string +=  sig + ax + '_{:02}'.format(ii+1) + ';'\n",
    "\n",
    "    # remove last separator (;)\n",
    "    idx_last_sep = header_string.rfind(\";\")\n",
    "    header_string =  header_string[:idx_last_sep]\n",
    "\n",
    "    # write header to file\n",
    "    with open(feature_csv_file, 'w') as feature_file:\n",
    "        feature_file.writelines(header_string + '\\n')\n",
    "\n",
    "    # go through all exercises\n",
    "    for ex in exercise_abbrs:\n",
    "\n",
    "        # go through all repetitions (data points) of the current exercise\n",
    "        for ii in range(len(train_data_points[ex])):\n",
    "\n",
    "            # join file path\n",
    "            file_path = os.path.join(csv_dir, train_data_points[ex]['csv_file'][ii])\n",
    "\n",
    "            # load the signal data of the corresponding time range of the current repetition\n",
    "            selected_data = fmpm.get_sensor_data(in_file = file_path, \n",
    "                                                 signals = sig_names, \n",
    "                                                 sampling_rate = sampling_rate, \n",
    "                                                 start_time = float(train_data_points[ex]['start_time'][ii]), \n",
    "                                                 stop_time = float(train_data_points[ex]['stop_time'][ii]))\n",
    "\n",
    "            # calculate the corresponding section means of the current repetition\n",
    "            section_means = fmpm.split_range_into_sections(signal_data = selected_data,\n",
    "                                                           num_sec = number_sections,\n",
    "                                                           signals = sig_names)\n",
    "\n",
    "            # string to write data of the current data point to the csv-file\n",
    "            data_point_string = ex + ';' # first column contains the label\n",
    "\n",
    "            # copy section mean values to string\n",
    "            for sig in sig_names:\n",
    "                for jj in [0,1,2]: # x, y, z comp. of the corresponding signal\n",
    "                    for ll in range(number_sections):\n",
    "\n",
    "                        # append to string for writing to csv file (5 decimals)\n",
    "                        data_point_string += \"{:.5f};\".format(section_means[sig][ll,jj])\n",
    "\n",
    "            # remove last separator (;)\n",
    "            idx_last_sep = data_point_string.rfind(\";\")\n",
    "            data_point_string =  data_point_string[:idx_last_sep]\n",
    "\n",
    "            # append values of current data point to file\n",
    "            with open(feature_csv_file, 'a') as feature_file:\n",
    "                feature_file.writelines(data_point_string + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 15,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "## Load the generated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:04:32.961740Z",
     "start_time": "2019-01-15T09:04:32.267701Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 12,
        "hidden": false,
        "row": 17,
        "width": 4
       },
       "report_default": {}
      }
     }
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6120 entries, 0 to 6119\n",
      "Data columns (total 61 columns):\n",
      "label       6120 non-null object\n",
      "Acc_x_01    6120 non-null float64\n",
      "Acc_x_02    6120 non-null float64\n",
      "Acc_x_03    6120 non-null float64\n",
      "Acc_x_04    6120 non-null float64\n",
      "Acc_x_05    6120 non-null float64\n",
      "Acc_x_06    6120 non-null float64\n",
      "Acc_x_07    6120 non-null float64\n",
      "Acc_x_08    6120 non-null float64\n",
      "Acc_x_09    6120 non-null float64\n",
      "Acc_x_10    6120 non-null float64\n",
      "Acc_y_01    6120 non-null float64\n",
      "Acc_y_02    6120 non-null float64\n",
      "Acc_y_03    6120 non-null float64\n",
      "Acc_y_04    6120 non-null float64\n",
      "Acc_y_05    6120 non-null float64\n",
      "Acc_y_06    6120 non-null float64\n",
      "Acc_y_07    6120 non-null float64\n",
      "Acc_y_08    6120 non-null float64\n",
      "Acc_y_09    6120 non-null float64\n",
      "Acc_y_10    6120 non-null float64\n",
      "Acc_z_01    6120 non-null float64\n",
      "Acc_z_02    6120 non-null float64\n",
      "Acc_z_03    6120 non-null float64\n",
      "Acc_z_04    6120 non-null float64\n",
      "Acc_z_05    6120 non-null float64\n",
      "Acc_z_06    6120 non-null float64\n",
      "Acc_z_07    6120 non-null float64\n",
      "Acc_z_08    6120 non-null float64\n",
      "Acc_z_09    6120 non-null float64\n",
      "Acc_z_10    6120 non-null float64\n",
      "Gyr_x_01    6120 non-null float64\n",
      "Gyr_x_02    6120 non-null float64\n",
      "Gyr_x_03    6120 non-null float64\n",
      "Gyr_x_04    6120 non-null float64\n",
      "Gyr_x_05    6120 non-null float64\n",
      "Gyr_x_06    6120 non-null float64\n",
      "Gyr_x_07    6120 non-null float64\n",
      "Gyr_x_08    6120 non-null float64\n",
      "Gyr_x_09    6120 non-null float64\n",
      "Gyr_x_10    6120 non-null float64\n",
      "Gyr_y_01    6120 non-null float64\n",
      "Gyr_y_02    6120 non-null float64\n",
      "Gyr_y_03    6120 non-null float64\n",
      "Gyr_y_04    6120 non-null float64\n",
      "Gyr_y_05    6120 non-null float64\n",
      "Gyr_y_06    6120 non-null float64\n",
      "Gyr_y_07    6120 non-null float64\n",
      "Gyr_y_08    6120 non-null float64\n",
      "Gyr_y_09    6120 non-null float64\n",
      "Gyr_y_10    6120 non-null float64\n",
      "Gyr_z_01    6120 non-null float64\n",
      "Gyr_z_02    6120 non-null float64\n",
      "Gyr_z_03    6120 non-null float64\n",
      "Gyr_z_04    6120 non-null float64\n",
      "Gyr_z_05    6120 non-null float64\n",
      "Gyr_z_06    6120 non-null float64\n",
      "Gyr_z_07    6120 non-null float64\n",
      "Gyr_z_08    6120 non-null float64\n",
      "Gyr_z_09    6120 non-null float64\n",
      "Gyr_z_10    6120 non-null float64\n",
      "dtypes: float64(60), object(1)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "feature_train_data = pd.read_csv(feature_csv_file, skiprows=0, sep=';')\n",
    "feature_train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:04:33.038745Z",
     "start_time": "2019-01-15T09:04:32.968741Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 8,
        "hidden": false,
        "row": 29,
        "width": 12
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Acc_x_01</th>\n",
       "      <th>Acc_x_02</th>\n",
       "      <th>Acc_x_03</th>\n",
       "      <th>Acc_x_04</th>\n",
       "      <th>Acc_x_05</th>\n",
       "      <th>Acc_x_06</th>\n",
       "      <th>Acc_x_07</th>\n",
       "      <th>Acc_x_08</th>\n",
       "      <th>Acc_x_09</th>\n",
       "      <th>...</th>\n",
       "      <th>Gyr_z_01</th>\n",
       "      <th>Gyr_z_02</th>\n",
       "      <th>Gyr_z_03</th>\n",
       "      <th>Gyr_z_04</th>\n",
       "      <th>Gyr_z_05</th>\n",
       "      <th>Gyr_z_06</th>\n",
       "      <th>Gyr_z_07</th>\n",
       "      <th>Gyr_z_08</th>\n",
       "      <th>Gyr_z_09</th>\n",
       "      <th>Gyr_z_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>-0.94862</td>\n",
       "      <td>-0.96133</td>\n",
       "      <td>-0.39374</td>\n",
       "      <td>0.35776</td>\n",
       "      <td>0.44864</td>\n",
       "      <td>0.05871</td>\n",
       "      <td>-0.50909</td>\n",
       "      <td>-0.86553</td>\n",
       "      <td>-0.91736</td>\n",
       "      <td>...</td>\n",
       "      <td>33.96461</td>\n",
       "      <td>119.09226</td>\n",
       "      <td>134.11672</td>\n",
       "      <td>45.16518</td>\n",
       "      <td>-20.69654</td>\n",
       "      <td>-83.85617</td>\n",
       "      <td>-101.04688</td>\n",
       "      <td>-79.37651</td>\n",
       "      <td>-28.57366</td>\n",
       "      <td>1.50226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>-0.91875</td>\n",
       "      <td>-0.90737</td>\n",
       "      <td>-0.56951</td>\n",
       "      <td>0.10319</td>\n",
       "      <td>0.40801</td>\n",
       "      <td>0.21426</td>\n",
       "      <td>-0.33080</td>\n",
       "      <td>-0.83806</td>\n",
       "      <td>-0.93589</td>\n",
       "      <td>...</td>\n",
       "      <td>21.89922</td>\n",
       "      <td>90.21641</td>\n",
       "      <td>118.35156</td>\n",
       "      <td>74.62266</td>\n",
       "      <td>-0.48750</td>\n",
       "      <td>-49.51187</td>\n",
       "      <td>-109.20234</td>\n",
       "      <td>-101.00547</td>\n",
       "      <td>-50.23281</td>\n",
       "      <td>-6.03594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>-0.93875</td>\n",
       "      <td>-0.93639</td>\n",
       "      <td>-0.60812</td>\n",
       "      <td>0.12386</td>\n",
       "      <td>0.46588</td>\n",
       "      <td>0.39421</td>\n",
       "      <td>-0.02835</td>\n",
       "      <td>-0.61382</td>\n",
       "      <td>-0.91854</td>\n",
       "      <td>...</td>\n",
       "      <td>15.96221</td>\n",
       "      <td>83.73110</td>\n",
       "      <td>123.72845</td>\n",
       "      <td>78.51526</td>\n",
       "      <td>9.25073</td>\n",
       "      <td>-30.06541</td>\n",
       "      <td>-83.66424</td>\n",
       "      <td>-102.55460</td>\n",
       "      <td>-72.67878</td>\n",
       "      <td>-8.51526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>-0.91961</td>\n",
       "      <td>-0.87408</td>\n",
       "      <td>-0.46247</td>\n",
       "      <td>0.17987</td>\n",
       "      <td>0.45833</td>\n",
       "      <td>0.28772</td>\n",
       "      <td>-0.27465</td>\n",
       "      <td>-0.78274</td>\n",
       "      <td>-0.88386</td>\n",
       "      <td>...</td>\n",
       "      <td>30.38491</td>\n",
       "      <td>94.18287</td>\n",
       "      <td>116.64787</td>\n",
       "      <td>70.11052</td>\n",
       "      <td>2.69985</td>\n",
       "      <td>-46.96799</td>\n",
       "      <td>-106.49924</td>\n",
       "      <td>-99.39024</td>\n",
       "      <td>-43.10108</td>\n",
       "      <td>-3.91768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF</td>\n",
       "      <td>-0.89435</td>\n",
       "      <td>-0.92486</td>\n",
       "      <td>-0.64687</td>\n",
       "      <td>0.03317</td>\n",
       "      <td>0.46411</td>\n",
       "      <td>0.44731</td>\n",
       "      <td>0.05423</td>\n",
       "      <td>-0.60571</td>\n",
       "      <td>-0.92647</td>\n",
       "      <td>...</td>\n",
       "      <td>13.04983</td>\n",
       "      <td>87.60167</td>\n",
       "      <td>130.50169</td>\n",
       "      <td>99.33333</td>\n",
       "      <td>20.78632</td>\n",
       "      <td>-28.67314</td>\n",
       "      <td>-86.20250</td>\n",
       "      <td>-126.16892</td>\n",
       "      <td>-94.74250</td>\n",
       "      <td>-11.61824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  Acc_x_01  Acc_x_02  Acc_x_03  Acc_x_04  Acc_x_05  Acc_x_06  Acc_x_07  \\\n",
       "0    RF  -0.94862  -0.96133  -0.39374   0.35776   0.44864   0.05871  -0.50909   \n",
       "1    RF  -0.91875  -0.90737  -0.56951   0.10319   0.40801   0.21426  -0.33080   \n",
       "2    RF  -0.93875  -0.93639  -0.60812   0.12386   0.46588   0.39421  -0.02835   \n",
       "3    RF  -0.91961  -0.87408  -0.46247   0.17987   0.45833   0.28772  -0.27465   \n",
       "4    RF  -0.89435  -0.92486  -0.64687   0.03317   0.46411   0.44731   0.05423   \n",
       "\n",
       "   Acc_x_08  Acc_x_09    ...     Gyr_z_01   Gyr_z_02   Gyr_z_03  Gyr_z_04  \\\n",
       "0  -0.86553  -0.91736    ...     33.96461  119.09226  134.11672  45.16518   \n",
       "1  -0.83806  -0.93589    ...     21.89922   90.21641  118.35156  74.62266   \n",
       "2  -0.61382  -0.91854    ...     15.96221   83.73110  123.72845  78.51526   \n",
       "3  -0.78274  -0.88386    ...     30.38491   94.18287  116.64787  70.11052   \n",
       "4  -0.60571  -0.92647    ...     13.04983   87.60167  130.50169  99.33333   \n",
       "\n",
       "   Gyr_z_05  Gyr_z_06   Gyr_z_07   Gyr_z_08  Gyr_z_09  Gyr_z_10  \n",
       "0 -20.69654 -83.85617 -101.04688  -79.37651 -28.57366   1.50226  \n",
       "1  -0.48750 -49.51187 -109.20234 -101.00547 -50.23281  -6.03594  \n",
       "2   9.25073 -30.06541  -83.66424 -102.55460 -72.67878  -8.51526  \n",
       "3   2.69985 -46.96799 -106.49924  -99.39024 -43.10108  -3.91768  \n",
       "4  20.78632 -28.67314  -86.20250 -126.16892 -94.74250 -11.61824  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 19,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "### Generate feature matrix of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:04:33.182753Z",
     "start_time": "2019-01-15T09:04:33.049745Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 19,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6120, 60)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get feature matrix\n",
    "X_train = feature_train_data.values[:,1:]\n",
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T12:25:41.106965Z",
     "start_time": "2018-12-10T12:25:41.100965Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 23,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "### Generate label array of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:04:33.402766Z",
     "start_time": "2019-01-15T09:04:33.190753Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 23,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6120,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dictionary for labels\n",
    "label_ex = {'RF':0,\n",
    "            'RO':1,\n",
    "            'RS':2,\n",
    "            'LR':3,\n",
    "            'BC':4,\n",
    "            'TC':5,\n",
    "            'MP':6,\n",
    "            'SA':7,\n",
    "            'P1':8,\n",
    "            'P2':9,\n",
    "            'NE':10}\n",
    "\n",
    "# get label array with labels (0 ... 10)\n",
    "labels_str = feature_train_data.values[:,0]\n",
    "y_train = [label_ex[labels_str[ii]] for ii in range(len(feature_train_data.values[:,0]))]\n",
    "np.shape(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 37,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "## Training of ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:04:33.724784Z",
     "start_time": "2019-01-15T09:04:33.409766Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 37,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "***Voting Classifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:04:33.738785Z",
     "start_time": "2019-01-15T09:04:33.727784Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#LogReg_clf = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, n_jobs=-1, random_state=42)\n",
    "#RF_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=40, n_jobs=-1, random_state=42)\n",
    "\n",
    "#voting_clf = VotingClassifier(estimators=[('lr', LogReg_clf), ('rf', RF_clf)], voting='soft')\n",
    "#voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 37,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "***Random Forest Classifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:04:39.188096Z",
     "start_time": "2019-01-15T09:04:33.742785Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 8,
        "hidden": false,
        "row": 41,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=50,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=-1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create random forest classifier model\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=50, n_jobs=-1, random_state=42)\n",
    "\n",
    "# train the model\n",
    "rnd_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 41,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "## Test Data\n",
    "\n",
    "Loading all sensor data from the test subject,\n",
    "without knowing the start and stop times of the exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:04:39.216098Z",
     "start_time": "2019-01-15T09:04:39.200097Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# select file (csv) of test subject\n",
    "test_subject_dir  = r'E:\\Physio_Data\\Subject_{:02}'.format(test_data_subject)\n",
    "test_subject_file = 'subject{:02}.csv'.format(test_data_subject)\n",
    "test_subject_path = os.path.join(test_subject_dir, test_subject_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T13:33:05.585296Z",
     "start_time": "2018-12-10T13:33:05.580296Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 11,
        "hidden": false,
        "row": 49,
        "width": 12
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "### Windowing the test data\n",
    "\n",
    "The windowing follows a certain procedure:\n",
    "\n",
    ">•\tTaking a 1 s block of the data\n",
    "\n",
    ">•\tVarying the block length from 1 s to 5 s with an increment of 200 ms (starting point remains the same for all blocks)\n",
    "\n",
    ">•\tSectioning and feature generation for all blocks\n",
    "\n",
    ">•\tFor each block class probabilities are calculated (ML classifier) \n",
    "\n",
    ">•\tSliding the starting point with an increment of 200 ms and starting again with a 1 s block varying to 5 s\n",
    "\n",
    "*see animation below*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:04:39.379107Z",
     "start_time": "2019-01-15T09:04:39.226099Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 9,
        "hidden": false,
        "row": 60,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"windowing_procedure.gif\" width=600 >"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<img src=\"windowing_procedure.gif\" width=600 >')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:04:39.720127Z",
     "start_time": "2019-01-15T09:04:39.385108Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def signal_windowing_via_indices(test_subject_path,\n",
    "                                 number_sections=10,\n",
    "                                 sig_names=['Acc','Gyr'],\n",
    "                                 sampling_rate=256,\n",
    "                                 cutoff=10,\n",
    "                                 order=6,\n",
    "                                 win_start_inc=0.2,\n",
    "                                 win_stretch_inc=0.2,\n",
    "                                 win_min_len=1,\n",
    "                                 win_max_len=5,\n",
    "                                 win_start=0,\n",
    "                                 win_last_start=None,\n",
    "                                 progress_info='Generate feature map...'):\n",
    "    '''\n",
    "    This function applies a defined windowing procedure in order to split a signal \n",
    "    into different sections, which can be then taken as features for machine learning.\n",
    "    The different section values are determined by taking the index in the middle of\n",
    "    the corresponding section.\n",
    "    In order to avoid extreme outliers a butterworth filter is used before sectioning.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    test_subject_path : str\n",
    "        Path to the csv-file of the test subject data.\n",
    "        \n",
    "    number_sections: int\n",
    "        Number of sections to split each window.\n",
    "        \n",
    "    sig_names : list of strings\n",
    "        Signal names, used as keys for signal dictionaries.\n",
    "        \n",
    "    sampling_rate : int or float\n",
    "        Sampling rate of the signals.\n",
    "        \n",
    "    cutoff : int or float\n",
    "        Cutoff frequency of the butterworh filter.\n",
    "        \n",
    "    order : int\n",
    "        Order of the butterworth filter.\n",
    "        \n",
    "    win_start_inc : int or float\n",
    "        Start increment for the window [s].\n",
    "        \n",
    "    win_stretch_inc : int or float\n",
    "        Stretch increment for the window [s].\n",
    "    \n",
    "    win_min_len : int or float\n",
    "        Minimum window length [s].\n",
    "    \n",
    "    win_max_len : int or float\n",
    "        Maximum window length [s].\n",
    "    \n",
    "    win_start : int or float\n",
    "        Start time of the window [s].\n",
    "    \n",
    "    win_last_start : int or float or None\n",
    "        Last start time of the window [s].\n",
    "        If None, set to time where the minimum window length just fits into the sensor data.\n",
    "        \n",
    "    progress_info : str\n",
    "        Information to print with progress.\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        list[0] : numpy.ndarray\n",
    "            Matrix with sectioned signal data.\n",
    "                (Number of columns = number of features)\n",
    "                (Number of rows = number of data points)\n",
    "        list[1] : int\n",
    "            Length of the original signals (number of indices).\n",
    "    '''\n",
    "\n",
    "\n",
    "    # get data from selected file\n",
    "    sensor_data = fmpm.get_sensor_data(in_file=test_subject_path,\n",
    "                                       signals=sig_names,\n",
    "                                       sampling_rate=sampling_rate)\n",
    "\n",
    "    # filter data with butterworth filter and save to new dictionary\n",
    "    sensor_data_filt = {}\n",
    "    for signal in sig_names:\n",
    "        sensor_data_filt[signal] = fmpm.butter_lowpass_filter(sensor_data[signal], \n",
    "                                                              cutoff=cutoff, \n",
    "                                                              fs=sampling_rate, \n",
    "                                                              order=order)\n",
    "\n",
    "    # signal length: all sensor data must have same length --> Acc, Gyr, ...\n",
    "    # --> but to ensure that indices are not out of range in case of wrong input data\n",
    "    # let's take the smallest stop index of the different signals\n",
    "    signal_len = float('inf')\n",
    "    for sig in sig_names:\n",
    "        if np.shape(sensor_data_filt[sig])[0] < signal_len:\n",
    "            signal_len = np.shape(sensor_data_filt[sig])[0]\n",
    "\n",
    "    # last window start is None--> set to time where the minimum window length just fits into the sensor data\n",
    "    if win_last_start is None:\n",
    "        win_last_start = signal_len/sampling_rate - win_min_len\n",
    "\n",
    "    # number of different window sizes\n",
    "    num_win_sizes = len(np.arange(win_min_len, win_max_len+win_stretch_inc, win_stretch_inc))\n",
    "\n",
    "    # number of different window start points\n",
    "    num_start_points = len(np.arange(win_start, win_last_start+win_start_inc, win_start_inc))\n",
    "\n",
    "    # matrix with all generated features (number_sections*6 = number of features --> Acc, Gyr (x,y,z))\n",
    "    feature_map = np.zeros([num_start_points * num_win_sizes, number_sections*6])\n",
    "    \n",
    "    # counter for current position (row) in the feature map\n",
    "    count = 0\n",
    "    \n",
    "    # variables for progress printing\n",
    "    max_count = len(feature_map)\n",
    "    prev_progress = 0 # previous progress\n",
    "\n",
    "    # going through all window start points\n",
    "    for ii, win_pos in enumerate(np.arange(win_start, win_last_start+win_start_inc, win_start_inc)):\n",
    "\n",
    "        # going through all window lengths  (+win_stretch_inc to include end point)\n",
    "        for jj, win_len in enumerate(np.arange(win_min_len, win_max_len+win_stretch_inc, win_stretch_inc)):\n",
    "\n",
    "            # calculate start and stop index (type: float --> conversion to int happens afterwards)\n",
    "            start_index = win_pos * sampling_rate\n",
    "            stop_index = start_index + (win_len * sampling_rate)\n",
    "\n",
    "            # check if stop index is out of range\n",
    "            if stop_index >= signal_len:\n",
    "                stop_index = signal_len-1 # set equal to last index\n",
    "\n",
    "            # get indices of the sections\n",
    "            section_indices, step = np.linspace(start_index, stop_index, number_sections, endpoint=False, retstep=True)\n",
    "\n",
    "            #  + step/2 in order to get the indices in the middle of the sections\n",
    "            section_indices = (section_indices + step/2).round().astype(int)\n",
    "\n",
    "            # putting the feature map together\n",
    "            #feature_map[count,:] = np.concatenate((sensor_data_filt[sig_names[0]][section_indices,:].transpose(), \n",
    "            #                                       sensor_data_filt[sig_names[1]][section_indices,:].transpose())).flatten().reshape(1, -1)\n",
    "            feature_map[count,:] = np.concatenate([sensor_data_filt[sig][section_indices,:].transpose().flatten() for sig in sig_names])\n",
    "\n",
    "            count += 1\n",
    "        \n",
    "        # print progress of feauture map generation\n",
    "        prev_progress = fmpm.print_progress(count, max_count, prev_progress, add_info=progress_info)\n",
    "    \n",
    "    return [feature_map, signal_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 41,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "### Generating the feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:04:39.922138Z",
     "start_time": "2019-01-15T09:04:39.724127Z"
    }
   },
   "outputs": [],
   "source": [
    "# signal names\n",
    "sig_names= ['Acc','Gyr']\n",
    "\n",
    "# filter properties according to Crema\n",
    "cutoff = 10 # [Hz]\n",
    "order = 6 # butterworth order\n",
    "\n",
    "# number of sections to split the signal\n",
    "number_sections = 10\n",
    "\n",
    "# window start increment\n",
    "win_start_inc = 0.2 # [s]\n",
    "\n",
    "# window stretch increment\n",
    "win_stretch_inc = 0.2 # [s]\n",
    "\n",
    "# minimum window length\n",
    "win_min_len = 1 # [s]\n",
    "\n",
    "# maximim window length\n",
    "win_max_len = 5 # [s]\n",
    "\n",
    "# window start time\n",
    "win_start = 0 # [s]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:04:51.953827Z",
     "start_time": "2019-01-15T09:04:39.926139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate feature map... 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(210966, 60)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_map, signal_len = signal_windowing_via_indices(test_subject_path,\n",
    "                                                         number_sections=number_sections,\n",
    "                                                         sig_names=sig_names,\n",
    "                                                         sampling_rate=sampling_rate,\n",
    "                                                         cutoff=cutoff,\n",
    "                                                         order=order,\n",
    "                                                         win_start_inc=win_start_inc,\n",
    "                                                         win_stretch_inc=win_stretch_inc,\n",
    "                                                         win_min_len=win_min_len,\n",
    "                                                         win_max_len=win_max_len,\n",
    "                                                         win_start=win_start)\n",
    "np.shape(feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:04:51.975828Z",
     "start_time": "2019-01-15T09:04:51.966827Z"
    }
   },
   "outputs": [],
   "source": [
    "# last window start time --> time where the minimum window length just fits into the sensor data\n",
    "win_last_start = signal_len/sampling_rate - win_min_len\n",
    "\n",
    "# number of different window sizes\n",
    "num_win_sizes = len(np.arange(win_min_len, win_max_len+win_stretch_inc, win_stretch_inc))\n",
    "\n",
    "# number of different window start points\n",
    "num_start_points = len(np.arange(win_start, win_last_start+win_start_inc, win_start_inc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 45,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "### Making predictions with the trained ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:05:06.049633Z",
     "start_time": "2019-01-15T09:04:51.978828Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 60,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210966, 11)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pred_probs = voting_clf.predict_proba(feature_map)\n",
    "pred_probs = rnd_clf.predict_proba(feature_map)\n",
    "np.shape(pred_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 60,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "### Filling the prediction matrices (images) with probability values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:05:09.426826Z",
     "start_time": "2019-01-15T09:05:06.061634Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 64,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 100%\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "max_count = len(feature_map)\n",
    "prev_progress = 0 # previous progress\n",
    "\n",
    "# dictionary with matrices to save predicted values for all classes\n",
    "pred_matrix = {}\n",
    "for ex in exercise_abbrs:\n",
    "    pred_matrix[ex] = np.zeros([num_start_points, num_win_sizes])\n",
    "\n",
    "# going through all window start points\n",
    "for ii, win_pos in enumerate(np.arange(win_start, win_last_start+win_start_inc, win_start_inc)):\n",
    "    # going through all window lengths  (+win_stretch_inc to include end point)\n",
    "    for jj, win_len in enumerate(np.arange(win_min_len, win_max_len+win_stretch_inc, win_stretch_inc)):\n",
    "        \n",
    "        for kk, ex in enumerate(exercise_abbrs):\n",
    "            pred_matrix[ex][ii,jj] = pred_probs[count][kk]\n",
    "            \n",
    "        count += 1\n",
    "        prev_progress = fmpm.print_progress(count, max_count, prev_progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:05:09.440827Z",
     "start_time": "2019-01-15T09:05:09.430826Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10046, 21)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(pred_matrix['RF'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find peaks of prediction matrices and evaluate them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:05:09.584835Z",
     "start_time": "2019-01-15T09:05:09.447827Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage.filters import maximum_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:05:09.749844Z",
     "start_time": "2019-01-15T09:05:09.589835Z"
    }
   },
   "outputs": [],
   "source": [
    "def detect_prob_map_peaks(prob_map):\n",
    "    '''\n",
    "    Function to detect the local peaks of a probability map.\n",
    "    !! Global variables are used !!\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    prob_map : 2d-array\n",
    "        Matrix with predicted probabilities.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    array \n",
    "        array[0] ... peak time indices\n",
    "        array[1] ... peak window length indices\n",
    "        e.g. ([[ 390, 723, 1331, ...], [4, 4, 10, ...]], dtype=int64)\n",
    "    '''\n",
    "    \n",
    "    # find only peaks with a minimum probability (threshold)\n",
    "    threshold_prob = 0.5\n",
    "    \n",
    "    # length and height of the footprint for the maximum_filter (see below)\n",
    "    footprint_length = 1.5 # [s]\n",
    "    footprint_length_indices = int(footprint_length / win_start_inc)\n",
    "    footprint_height = num_win_sizes * 2  # take twice the number of all window sizes for footprint height\n",
    "    \n",
    "    footprint=np.ones((footprint_length_indices,footprint_height))\n",
    "    \n",
    "    # applying a maximum filter and generating a boolean map for local maxima\n",
    "    local_max = maximum_filter(prob_map, footprint=footprint)==prob_map\n",
    "    \n",
    "    # removing all maxima below the threshold\n",
    "    local_max = (prob_map>=threshold_prob) & local_max\n",
    "    \n",
    "    # check if there are several points with the same probability at one local maxima (within footprint length)\n",
    "    #   --> remove them, otherwise we get more than one local maxima\n",
    "    peak_indices_check = np.argwhere(local_max)\n",
    "    if len(peak_indices_check) > 1:\n",
    "        for ii in range(len(peak_indices_check)-1):\n",
    "            row_ind, col_ind = peak_indices_check[ii]\n",
    "            row_ind_next, col_ind_next = peak_indices_check[ii+1]\n",
    "            if row_ind_next-row_ind <= footprint_length_indices/2:\n",
    "                local_max[row_ind,col_ind] = False\n",
    "    \n",
    "    # get the maxima indices of the probability map\n",
    "    peak_indices = np.argwhere(local_max).transpose()\n",
    "    \n",
    "    return peak_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:05:10.075863Z",
     "start_time": "2019-01-15T09:05:09.752845Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_peaks(peak_ind, pred_matrix):\n",
    "    '''\n",
    "    Function to evaluate the detected peaks.\n",
    "    (see function detect_prob_map_peaks(prob_map))\n",
    "    \n",
    "    --> assign peaks to repetition blocks with min two repetitions\n",
    "    --> if blocks are overlapping, keep only the block with the highest predicted probabilities (sum)\n",
    "    \n",
    "    !! Global variables are used !!\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    peak_ind : dict\n",
    "        Exercise-abbreviations as keys (e.g. 'RF', 'RO', ...)\n",
    "        --> values: 2d-array \n",
    "        array[0] ... peak time indices\n",
    "        array[1] ... peak window length indices\n",
    "        e.g. ([[ 390, 723, 1331, ...], [4, 4, 10, ...]], dtype=int64)\n",
    "        \n",
    "    pred_matrix : dict\n",
    "        Exercise-abbreviations as keys (e.g. 'RF', 'RO', ...)\n",
    "        --> values: 2d-array \n",
    "        Matrices with predicted probabilities.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary with exercise abbreviations as keys --> repetition blocks\n",
    "        \n",
    "        Example: rep_blocks['RF'][0]   (first block of exercise 'RF'):\n",
    "        [[4121, 9],\n",
    "         [4135, 11],\n",
    "         [4150, 11],\n",
    "         [4166, 9],\n",
    "         [4179, 10],\n",
    "         [4193, 10],\n",
    "         [4207, 10],\n",
    "         [4221, 12],\n",
    "         [4236, 13],\n",
    "         [4251, 13]]\n",
    "           --> 1st column: indices corresponding to horizontal axis (window start position)\n",
    "           --> 2nd column: indices corresponding to vertical axis (window stretching)\n",
    "           --> 10 rows --> 10 repetitions in this block\n",
    "    '''\n",
    "    \n",
    "    # define the maximum time between two peaks in a block\n",
    "    max_time_between_peaks = 10 # [s]\n",
    "    max_ind_between_peaks = int(max_time_between_peaks / win_start_inc)\n",
    "    \n",
    "    exercise_only_abbrs = [*peak_ind]\n",
    "    \n",
    "    # assign peaks to repetition blocks with min two repetitions (check previous and next peak distance)\n",
    "    rep_blocks = {}\n",
    "    for ii, ex in enumerate(exercise_only_abbrs):\n",
    "        rep_blocks[ex] = []\n",
    "        current_block = []\n",
    "        first_of_block = True # remember if current peak is the first of the current block\n",
    "        \n",
    "        # going through all peaks of the current exercise if there are minimum two peaks\n",
    "        if len(peak_ind[ex][0]) >= 2:\n",
    "            for jj in range(len(peak_ind[ex][0])-1):\n",
    "                \n",
    "                # time index of the current peak\n",
    "                time_index = peak_ind[ex][0][jj]\n",
    "                \n",
    "                # time index of the next peak\n",
    "                next_time_index = peak_ind[ex][0][jj+1]\n",
    "\n",
    "                # looking for first peak of current block\n",
    "                if first_of_block is True: # omit the first one --> no block possible\n",
    "                    if next_time_index-time_index <= max_ind_between_peaks:\n",
    "                        current_block.append([peak_ind[ex][0][jj], peak_ind[ex][1][jj]]) # add the current peak\n",
    "                        current_block.append([peak_ind[ex][0][jj+1], peak_ind[ex][1][jj+1]]) # and the next peak\n",
    "                        first_of_block = False\n",
    "\n",
    "                # first peak of current block already found\n",
    "                elif first_of_block is False:\n",
    "                    if next_time_index-time_index <= max_ind_between_peaks:\n",
    "                        current_block.append([peak_ind[ex][0][jj+1], peak_ind[ex][1][jj+1]]) # add the next peak\n",
    "                    else:\n",
    "                        first_of_block = True\n",
    "                        rep_blocks[ex].append(current_block)\n",
    "                        current_block = []\n",
    "\n",
    "            # one additional time at the end of the loop if something is stored in the current block\n",
    "            if first_of_block is False:\n",
    "                rep_blocks[ex].append(current_block)\n",
    "    \n",
    "    \n",
    "    # if blocks are overlapping --> keep only the block with the highest predicted probabilities (sum)\n",
    "    #    --> the more peaks in the block, the higher the sum of probabilities (in general)\n",
    "    blocks_to_remove = []\n",
    "\n",
    "    for ex1, ex2 in itertools.combinations(exercise_only_abbrs, 2):\n",
    "        for ii in range(len(rep_blocks[ex1])):\n",
    "            for jj in range(len(rep_blocks[ex2])):\n",
    "                start_1 = rep_blocks[ex1][ii][0][0] # time index of the first peak in the current block 1\n",
    "                stop_1 = rep_blocks[ex1][ii][-1][0] # time index of the last peak in the current block 1\n",
    "                start_2 = rep_blocks[ex2][jj][0][0] # time index of the first peak in the current block 2\n",
    "                stop_2 = rep_blocks[ex2][jj][-1][0] # time index of the last peak in the current block 2\n",
    "\n",
    "                # check if the two blocks overlap\n",
    "                if (start_1 >= start_2 and start_1 <= stop_2) or (stop_1 >= start_2 and stop_1 <= stop_2) \\\n",
    "                or (start_2 >= start_1 and start_2 <= stop_1) or (stop_2 >= start_1 and stop_2 <= stop_1):\n",
    "\n",
    "                    # selecet the corresponding probability values of pred_matrix and sum them up\n",
    "                    sum_prob_block_1 = pred_matrix[ex1][np.array(rep_blocks[ex1][ii])[:,0], \n",
    "                                                        np.array(rep_blocks[ex1][ii])[:,1]].sum()\n",
    "\n",
    "                    sum_prob_block_2 = pred_matrix[ex2][np.array(rep_blocks[ex2][jj])[:,0], \n",
    "                                                        np.array(rep_blocks[ex2][jj])[:,1]].sum()\n",
    "\n",
    "                    # compare the sum of the probabilities of the two blocks\n",
    "                    if sum_prob_block_1 < sum_prob_block_2:\n",
    "                        blocks_to_remove.append([ex1, ii])\n",
    "                    else:\n",
    "                        blocks_to_remove.append([ex2, jj])\n",
    "    \n",
    "    # ensure that there are no duplicates in the nested list\n",
    "    blocks_to_remove_unique = []\n",
    "    for sublist in blocks_to_remove:\n",
    "        if sublist not in blocks_to_remove_unique:\n",
    "            blocks_to_remove_unique.append(sublist)\n",
    "    \n",
    "    # by removing the blocks take the reversed sorted order of the block index\n",
    "    #    --> so it is possible to remove all blocks without \"refreshing\" the indices\n",
    "    #        (if one block is removed, higher indices of all other blocks are changing)\n",
    "    for ex, block_ind in sorted(blocks_to_remove_unique, key=lambda x: x[1])[::-1]:\n",
    "        rep_blocks[ex].pop(block_ind)\n",
    "        \n",
    "    return rep_blocks\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:05:10.254873Z",
     "start_time": "2019-01-15T09:05:10.079863Z"
    }
   },
   "outputs": [],
   "source": [
    "# function to convert indices to time strings\n",
    "def indices_to_time(start_index, stop_index):\n",
    "    '''\n",
    "    Function convert indices to time string.\n",
    "    !! Global variables are used !!\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    start_index : int\n",
    "        \n",
    "    stop_index : int\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        String with start and stop time (e.g. '14:39.6 - 15:19.4').\n",
    "    '''\n",
    "    start_time_text = '{0:02}:{1:04.1f}'.format(int(start_index*win_start_inc/60), \n",
    "                                               (start_index*win_start_inc)%60)\n",
    "    stop_time_text = '{0:02}:{1:04.1f}'.format(int(stop_index*win_start_inc/60), \n",
    "                                               (stop_index*win_start_inc)%60)\n",
    "    return start_time_text + ' - ' + stop_time_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:05:10.406882Z",
     "start_time": "2019-01-15T09:05:10.262874Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_rep_blocks(rep_blocks):\n",
    "    '''\n",
    "    Function to print the repetition blocks of each exercise \n",
    "    with time range and number of repetitons.\n",
    "    !! Global variables are used !!\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rep_blocks : dict\n",
    "        Dictionary with nested lists of repetition blocks.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    no returns\n",
    "    '''\n",
    "    exercise_only_abbrs = ['RF','RO','RS','LR','BC','TC','MP','SA','P1','P2']\n",
    "    \n",
    "    # going through all exercises\n",
    "    for ex in exercise_only_abbrs:\n",
    "        print('\\nExercise: ' + ex)\n",
    "        print('Number of blocks: {}\\n'.format(len(rep_blocks[ex])))\n",
    "        \n",
    "        # going through all repetition blocks of the current exercise\n",
    "        for block_num in range(len(rep_blocks[ex])):\n",
    "            print('\\tBlock #{}:'.format(block_num+1))\n",
    "            print('\\t\\tRepetitions: {}'.format(np.shape(np.array(rep_blocks[ex][block_num]))[0]))\n",
    "            start_index = rep_blocks[ex][block_num][0][0]\n",
    "            stop_index = rep_blocks[ex][block_num][-1][0]\n",
    "            # for the stop index we have to consider the length of the last repetition\n",
    "            stop_index += int((rep_blocks[ex][block_num][-1][1]*win_stretch_inc + win_min_len) / win_start_inc)\n",
    "            print('\\t\\tTime range: ' + indices_to_time(start_index, stop_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:05:10.720900Z",
     "start_time": "2019-01-15T09:05:10.413882Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4121, 9],\n",
       " [4135, 11],\n",
       " [4150, 11],\n",
       " [4166, 9],\n",
       " [4179, 10],\n",
       " [4193, 10],\n",
       " [4207, 10],\n",
       " [4221, 12],\n",
       " [4236, 13],\n",
       " [4251, 13]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the functions for peak evaluation\n",
    "\n",
    "exercise_only_abbrs = ['RF','RO','RS','LR','BC','TC','MP','SA','P1','P2']\n",
    "\n",
    "peak_ind = {}\n",
    "for ex in exercise_only_abbrs:\n",
    "    peak_ind[ex] = detect_prob_map_peaks(pred_matrix[ex])\n",
    "    \n",
    "rep_blocks = evaluate_peaks(peak_ind, pred_matrix) \n",
    "\n",
    "# show first block of exercise 'RF':\n",
    "#   --> 1st column: indices corresponding to horizontal axis (window start position)\n",
    "#   --> 2nd column: indices corresponding to vertical axis (window stretching)\n",
    "rep_blocks['RF'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:05:10.787904Z",
     "start_time": "2019-01-15T09:05:10.724900Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exercise: RF\n",
      "Number of blocks: 3\n",
      "\n",
      "\tBlock #1:\n",
      "\t\tRepetitions: 10\n",
      "\t\tTime range: 13:44.2 - 14:13.8\n",
      "\tBlock #2:\n",
      "\t\tRepetitions: 15\n",
      "\t\tTime range: 14:39.8 - 15:19.2\n",
      "\tBlock #3:\n",
      "\t\tRepetitions: 5\n",
      "\t\tTime range: 16:08.4 - 16:22.6\n",
      "\n",
      "Exercise: RO\n",
      "Number of blocks: 3\n",
      "\n",
      "\tBlock #1:\n",
      "\t\tRepetitions: 15\n",
      "\t\tTime range: 01:17.4 - 01:57.0\n",
      "\tBlock #2:\n",
      "\t\tRepetitions: 5\n",
      "\t\tTime range: 02:20.8 - 02:36.2\n",
      "\tBlock #3:\n",
      "\t\tRepetitions: 9\n",
      "\t\tTime range: 02:54.0 - 03:22.6\n",
      "\n",
      "Exercise: RS\n",
      "Number of blocks: 3\n",
      "\n",
      "\tBlock #1:\n",
      "\t\tRepetitions: 15\n",
      "\t\tTime range: 20:12.2 - 20:59.4\n",
      "\tBlock #2:\n",
      "\t\tRepetitions: 5\n",
      "\t\tTime range: 21:24.2 - 21:39.6\n",
      "\tBlock #3:\n",
      "\t\tRepetitions: 10\n",
      "\t\tTime range: 22:09.0 - 22:37.2\n",
      "\n",
      "Exercise: LR\n",
      "Number of blocks: 3\n",
      "\n",
      "\tBlock #1:\n",
      "\t\tRepetitions: 5\n",
      "\t\tTime range: 10:42.4 - 10:56.0\n",
      "\tBlock #2:\n",
      "\t\tRepetitions: 10\n",
      "\t\tTime range: 11:24.6 - 11:50.8\n",
      "\tBlock #3:\n",
      "\t\tRepetitions: 15\n",
      "\t\tTime range: 12:11.4 - 12:51.6\n",
      "\n",
      "Exercise: BC\n",
      "Number of blocks: 3\n",
      "\n",
      "\tBlock #1:\n",
      "\t\tRepetitions: 15\n",
      "\t\tTime range: 16:49.8 - 17:29.2\n",
      "\tBlock #2:\n",
      "\t\tRepetitions: 11\n",
      "\t\tTime range: 18:00.6 - 18:31.4\n",
      "\tBlock #3:\n",
      "\t\tRepetitions: 5\n",
      "\t\tTime range: 18:58.0 - 19:11.2\n",
      "\n",
      "Exercise: TC\n",
      "Number of blocks: 3\n",
      "\n",
      "\tBlock #1:\n",
      "\t\tRepetitions: 15\n",
      "\t\tTime range: 07:31.4 - 08:14.2\n",
      "\tBlock #2:\n",
      "\t\tRepetitions: 5\n",
      "\t\tTime range: 08:48.8 - 09:03.6\n",
      "\tBlock #3:\n",
      "\t\tRepetitions: 10\n",
      "\t\tTime range: 09:45.2 - 10:11.8\n",
      "\n",
      "Exercise: MP\n",
      "Number of blocks: 3\n",
      "\n",
      "\tBlock #1:\n",
      "\t\tRepetitions: 39\n",
      "\t\tTime range: 29:39.0 - 30:36.2\n",
      "\tBlock #2:\n",
      "\t\tRepetitions: 25\n",
      "\t\tTime range: 31:12.0 - 31:46.6\n",
      "\tBlock #3:\n",
      "\t\tRepetitions: 10\n",
      "\t\tTime range: 32:11.2 - 32:28.0\n",
      "\n",
      "Exercise: SA\n",
      "Number of blocks: 3\n",
      "\n",
      "\tBlock #1:\n",
      "\t\tRepetitions: 5\n",
      "\t\tTime range: 26:48.0 - 27:04.2\n",
      "\tBlock #2:\n",
      "\t\tRepetitions: 16\n",
      "\t\tTime range: 27:24.6 - 28:15.2\n",
      "\tBlock #3:\n",
      "\t\tRepetitions: 10\n",
      "\t\tTime range: 28:40.4 - 29:09.8\n",
      "\n",
      "Exercise: P1\n",
      "Number of blocks: 3\n",
      "\n",
      "\tBlock #1:\n",
      "\t\tRepetitions: 10\n",
      "\t\tTime range: 23:43.0 - 24:15.0\n",
      "\tBlock #2:\n",
      "\t\tRepetitions: 15\n",
      "\t\tTime range: 24:41.4 - 25:24.2\n",
      "\tBlock #3:\n",
      "\t\tRepetitions: 5\n",
      "\t\tTime range: 25:48.0 - 26:02.2\n",
      "\n",
      "Exercise: P2\n",
      "Number of blocks: 3\n",
      "\n",
      "\tBlock #1:\n",
      "\t\tRepetitions: 10\n",
      "\t\tTime range: 04:26.4 - 04:53.2\n",
      "\tBlock #2:\n",
      "\t\tRepetitions: 5\n",
      "\t\tTime range: 05:23.6 - 05:38.0\n",
      "\tBlock #3:\n",
      "\t\tRepetitions: 16\n",
      "\t\tTime range: 06:24.6 - 07:09.0\n"
     ]
    }
   ],
   "source": [
    "print_rep_blocks(rep_blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 64,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "## Comparing predicted probabilities with actual classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 68,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "### First we have to load the actual time ranges of the exercises of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:05:10.939913Z",
     "start_time": "2019-01-15T09:05:10.793904Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 17,
        "hidden": false,
        "row": 72,
        "width": 5
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raises Oblique</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>01:18.6</td>\n",
       "      <td>01:58.3</td>\n",
       "      <td>02:22.1</td>\n",
       "      <td>02:37.1</td>\n",
       "      <td>02:54.8</td>\n",
       "      <td>03:23.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PNF Diagonal 2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>04:27.1</td>\n",
       "      <td>04:54.3</td>\n",
       "      <td>05:24.5</td>\n",
       "      <td>05:38.9</td>\n",
       "      <td>06:25.8</td>\n",
       "      <td>07:05.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Triceps Curls</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>07:32.3</td>\n",
       "      <td>08:14.8</td>\n",
       "      <td>08:49.5</td>\n",
       "      <td>09:04.9</td>\n",
       "      <td>09:46.1</td>\n",
       "      <td>10:12.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rotation Wrist</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>10:43.1</td>\n",
       "      <td>10:57.3</td>\n",
       "      <td>11:25.6</td>\n",
       "      <td>11:51.8</td>\n",
       "      <td>12:12.1</td>\n",
       "      <td>12:52.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Raises Front</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>13:44.8</td>\n",
       "      <td>14:14</td>\n",
       "      <td>14:40.6</td>\n",
       "      <td>15:20</td>\n",
       "      <td>16:09.5</td>\n",
       "      <td>16:23.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Biceps Curls</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>16:50.8</td>\n",
       "      <td>17:30.2</td>\n",
       "      <td>18:01.3</td>\n",
       "      <td>18:32.2</td>\n",
       "      <td>18:58.6</td>\n",
       "      <td>19:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Raises Side</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>20:13</td>\n",
       "      <td>21:00.2</td>\n",
       "      <td>21:24.9</td>\n",
       "      <td>21:40.2</td>\n",
       "      <td>22:09.6</td>\n",
       "      <td>22:38.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PNF Diagonal 1</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>23:43.9</td>\n",
       "      <td>24:15.9</td>\n",
       "      <td>24:42</td>\n",
       "      <td>25:25.1</td>\n",
       "      <td>25:48.7</td>\n",
       "      <td>26:04.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shoulder Adduct.</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>26:48.5</td>\n",
       "      <td>27:05.3</td>\n",
       "      <td>27:25.4</td>\n",
       "      <td>28:16.5</td>\n",
       "      <td>28:41.2</td>\n",
       "      <td>29:10.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Military Press</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>29:45.6</td>\n",
       "      <td>30:37.4</td>\n",
       "      <td>31:14.6</td>\n",
       "      <td>31:47.3</td>\n",
       "      <td>32:13.6</td>\n",
       "      <td>32:28.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0   1   2   3        4        5        6        7        8  \\\n",
       "0    Raises Oblique  15   5  10  01:18.6  01:58.3  02:22.1  02:37.1  02:54.8   \n",
       "1    PNF Diagonal 2  10   5  15  04:27.1  04:54.3  05:24.5  05:38.9  06:25.8   \n",
       "2     Triceps Curls  15   5  10  07:32.3  08:14.8  08:49.5  09:04.9  09:46.1   \n",
       "3    Rotation Wrist   5  10  15  10:43.1  10:57.3  11:25.6  11:51.8  12:12.1   \n",
       "4      Raises Front  10  15   5  13:44.8    14:14  14:40.6    15:20  16:09.5   \n",
       "5      Biceps Curls  15  10   5  16:50.8  17:30.2  18:01.3  18:32.2  18:58.6   \n",
       "6       Raises Side  15   5  10    20:13  21:00.2  21:24.9  21:40.2  22:09.6   \n",
       "7    PNF Diagonal 1  10  15   5  23:43.9  24:15.9    24:42  25:25.1  25:48.7   \n",
       "8  Shoulder Adduct.   5  15  10  26:48.5  27:05.3  27:25.4  28:16.5  28:41.2   \n",
       "9    Military Press  15  10   5  29:45.6  30:37.4  31:14.6  31:47.3  32:13.6   \n",
       "\n",
       "         9  \n",
       "0  03:23.3  \n",
       "1  07:05.1  \n",
       "2  10:12.6  \n",
       "3  12:52.4  \n",
       "4  16:23.1  \n",
       "5    19:12  \n",
       "6  22:38.4  \n",
       "7  26:04.6  \n",
       "8  29:10.9  \n",
       "9  32:28.1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the actual time ranges of the exercises of the test data for the subsequent plot \n",
    "# to compare with predicted values\n",
    "\n",
    "# select file with timetable (csv) of the test subject\n",
    "timetable_file_dir = r'E:\\Physio_Data\\Exercise_time_tables'\n",
    "timetable_file_name = 'Timetable_subject{:02}.txt'.format(test_data_subject)\n",
    "timetable_data_path = os.path.join(timetable_file_dir, timetable_file_name)\n",
    "\n",
    "# read in time table\n",
    "timetable_data = pd.read_csv(timetable_data_path, skiprows=0, sep='\\t', header=None)\n",
    "num_exercises = timetable_data.shape[0] # number of exercises\n",
    "timetable_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 68,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "### Plotting of the predicted probabilities and actual classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:32:57.641242Z",
     "start_time": "2019-01-15T09:32:56.262164Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 5,
        "height": 4,
        "hidden": false,
        "row": 72,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib auto\n",
    "\n",
    "# text for current subject\n",
    "sub_text = 'Subject {}\\n'.format(test_data_subject)\n",
    "\n",
    "yticks = np.arange(0, win_max_len-win_min_len+win_stretch_inc, 2) / win_stretch_inc\n",
    "ylabels = ['{}'.format(yticks[ii] * win_stretch_inc + win_min_len) for ii in range(len(yticks))]\n",
    "\n",
    "fig, axis = plt.subplots(12,1,figsize=(18,9), sharex=True)\n",
    "\n",
    "# image color settings for RFC probabilities\n",
    "cmap = plt.cm.seismic\n",
    "vmin=0\n",
    "vmax=1\n",
    "\n",
    "for ax, ex in zip(axis, exercise_abbrs):\n",
    "    s = ax.imshow(pred_matrix[ex].transpose(), interpolation='nearest', \n",
    "                  aspect='auto', cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_yticks(yticks)\n",
    "    ax.set_yticklabels(ylabels, fontsize=7)\n",
    "    ax.set_ylabel(ex, rotation=0, fontsize=13)\n",
    "    ax.yaxis.labelpad = 32\n",
    "    ax.xaxis.set_ticklabels([])\n",
    "    \n",
    "# dictionary for cross plots (in order to toggle visibility)\n",
    "cross_plot = {}\n",
    "\n",
    "# plot crosses for image peaks\n",
    "for ax, ex in zip(axis, exercise_only_abbrs):\n",
    "    #ax.plot(peak_ind[ex][0], peak_ind[ex][1], '+g', markersize=8, markeredgewidth=1.5)\n",
    "    cross_plot[ex] = []\n",
    "    for ii in range(len(rep_blocks[ex])):\n",
    "        x_peak = np.array(rep_blocks[ex][ii])[:,0]\n",
    "        y_peak = np.array(rep_blocks[ex][ii])[:,1]\n",
    "        cross_plot[ex].append(ax.plot(x_peak, y_peak, '+g', markersize=8, markeredgewidth=1.5))\n",
    "        \n",
    "def toggle_cross(val):\n",
    "    # This function is called by a button to hide/show the crosses\n",
    "    for ex in exercise_only_abbrs:\n",
    "        for ii in range(len(rep_blocks[ex])):\n",
    "            cross_plot[ex][ii][0].set_visible(not cross_plot[ex][ii][0].get_visible())\n",
    "    plt.draw()\n",
    "    \n",
    "Button_showCross_ax = plt.axes([0.78, 0.12, 0.05, 0.03])\n",
    "Button_showCross = Button(Button_showCross_ax, 'Show rep.')\n",
    "Button_showCross.on_clicked(toggle_cross)\n",
    "    \n",
    "plt.gcf().text(0.1, 0.6, r'window length $[s]$', fontsize=10, rotation=90)\n",
    "# plt.gcf().text(0.078, 0.6, r'window length $[s]$', fontsize=10, rotation=90) # for half the window size\n",
    "\n",
    "#axis[-1].plot(range(num_start_points), np.zeros(num_start_points), 'k', alpha=0.0)\n",
    "formatter = FuncFormatter(lambda i, x: time.strftime('%M:%S', time.gmtime(i*win_start_inc+win_start)))\n",
    "axis[-1].xaxis.set_major_formatter(formatter)\n",
    "axis[-1].set_xlabel(r'time $[min:sec]$', fontsize=13)\n",
    "axis[-1].set_yticks([])\n",
    "axis[-1].set_ylim([0,1])\n",
    "\n",
    "fig.subplots_adjust(bottom=0.2, right=0.9) # make space for buttons and color bar\n",
    "cbar_ax = fig.add_axes([0.93, 0.255, 0.01, 0.625])\n",
    "fig.colorbar(s, cax=cbar_ax)\n",
    "\n",
    "# add slider for selections on the x axis\n",
    "Slider_shiftX_ax = plt.axes([0.125, 0.07, 0.775, 0.025])\n",
    "Slider_zoomX_ax = plt.axes([0.125, 0.035, 0.775, 0.025])\n",
    "\n",
    "axcolor = 'cornflowerblue'\n",
    "Slider_shiftX = Slider(Slider_shiftX_ax, 'time shift [%]', 0.0, 100.0, valinit=0, facecolor=axcolor)\n",
    "Slider_zoomX = Slider(Slider_zoomX_ax, 'time scale [%]', 0.1, 100.0, valinit=100, facecolor=axcolor)\n",
    "Slider_zoomX_ax.xaxis.set_visible(True)\n",
    "Slider_zoomX_ax.set_xticks(np.arange(0,105,5)) \n",
    "\n",
    "def updateX(val):\n",
    "    start_index = int(Slider_shiftX.val / 100 * num_start_points)\n",
    "    stop_index = start_index + Slider_zoomX.val / 100 * num_start_points\n",
    "    axis[-1].set_xlim((start_index, stop_index))\n",
    "    fig.suptitle('Predicted Probabilities ' + sub_text + indices_to_time(start_index, stop_index), fontsize=20)\n",
    "    plt.draw()\n",
    "\n",
    "Slider_shiftX.on_changed(updateX)\n",
    "Slider_zoomX.on_changed(updateX)\n",
    "\n",
    "# add button to reset view\n",
    "def resetX(val):\n",
    "    start_index = 0\n",
    "    stop_index = num_start_points\n",
    "    axis[-1].set_xlim((start_index, stop_index))\n",
    "    Slider_shiftX.reset()\n",
    "    Slider_zoomX.reset()\n",
    "    fig.suptitle('Predicted Probabilities ' + sub_text + indices_to_time(start_index, stop_index), fontsize=20)\n",
    "    plt.draw()\n",
    "\n",
    "Button_resetX_ax = plt.axes([0.85, 0.12, 0.05, 0.03])\n",
    "Button_resetX = Button(Button_resetX_ax, 'Reset view')\n",
    "Button_resetX.on_clicked(resetX)\n",
    "\n",
    "start_index = 0\n",
    "stop_index = num_start_points\n",
    "\n",
    "fig.suptitle('Predicted Probabilities ' + sub_text + indices_to_time(start_index, stop_index), fontsize=20)\n",
    "\n",
    "axis[-1].set_xlim(0, num_start_points)\n",
    "\n",
    "\n",
    "# Plotting the actual classes (exercises) on the last axis:\n",
    "\n",
    "# dictionary to get exercise abbreviations from exercise names in timetable\n",
    "exercise_names = {'Raises Front':'RF',\n",
    "                  'Raises Oblique':'RO',\n",
    "                  'Raises Side':'RS',\n",
    "                  'Rotation Wrist':'LR',\n",
    "                  'Biceps Curls':'BC',\n",
    "                  'Triceps Curls':'TC',\n",
    "                  'Military Press':'MP',\n",
    "                  'Shoulder Adduct.':'SA',\n",
    "                  'PNF Diagonal 1':'P1',\n",
    "                  'PNF Diagonal 2':'P2'}\n",
    "\n",
    "# going through all exercises in the timetable\n",
    "for ii, ex_name in enumerate(timetable_data.values[:,0]):\n",
    "    \n",
    "    # going through all repetition blocks in the timetable (5, 10 and 15 rep. blocks)\n",
    "    for rep_col, start_col, stop_col in zip([1,2,3],[4,6,8],[5,7,9]): # corresponding columns\n",
    "        rep_num = timetable_data.values[ii,rep_col]\n",
    "        left_border = fmpm.convert_time_format_to_index(timetable_data.values[ii,start_col], \n",
    "                                                        sampling_rate=1/win_start_inc)\n",
    "        right_border = fmpm.convert_time_format_to_index(timetable_data.values[ii,stop_col], \n",
    "                                                         sampling_rate=1/win_start_inc)\n",
    "        # mark the corresponding area\n",
    "        axis[-1].axvspan(left_border, right_border, color='y', alpha=0.3, lw=0)\n",
    "        # write text to the corresponding area\n",
    "        x_center = left_border + (right_border-left_border)/2 # x center of marked area\n",
    "        axis[-1].text(x_center, 0.5, str(rep_num) + '\\n' + exercise_names[ex_name], \n",
    "                      horizontalalignment='center', verticalalignment='center', fontsize=10, clip_on=True)\n",
    "        \n",
    "axis[-1].set_ylabel('Actual classes', rotation=0, fontsize=11)\n",
    "axis[-1].yaxis.labelpad = 50\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting only a small section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:05:13.436055Z",
     "start_time": "2019-01-15T09:04:29.048Z"
    }
   },
   "outputs": [],
   "source": [
    "# window start increment\n",
    "win_start_inc = 0.2 # [s]\n",
    "\n",
    "# window stretch increment\n",
    "win_stretch_inc = 0.2 # [s]\n",
    "\n",
    "# minimum window length\n",
    "win_min_len = 1 # [s]\n",
    "\n",
    "# maximim window length\n",
    "win_max_len = 5 # [s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:05:13.449056Z",
     "start_time": "2019-01-15T09:04:29.054Z"
    }
   },
   "outputs": [],
   "source": [
    "# 5 BC appr. at 18:56 - 19:11\n",
    "example_start_time_s = 18*60 + 56\n",
    "example_stop_time_s = 19*60 + 11\n",
    "\n",
    "example_start_ind = int(example_start_time_s / win_start_inc)\n",
    "example_stop_ind = int(example_stop_time_s / win_start_inc)\n",
    "\n",
    "example_pred_matrix = np.copy(pred_matrix['BC'][example_start_ind:example_stop_ind, :])\n",
    "np.shape(example_pred_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T09:07:32.057984Z",
     "start_time": "2019-01-15T09:07:31.828971Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'example_pred_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-181a9e9239e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mfig_example\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots_adjust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbottom\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# make space for buttons and color bar\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m ax_example.imshow(example_pred_matrix.transpose(), \n\u001b[0m\u001b[0;32m     13\u001b[0m                   interpolation='nearest',aspect='auto', cmap=cmap, vmin=vmin, vmax=vmax)\n\u001b[0;32m     14\u001b[0m \u001b[0max_example\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvert_yaxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'example_pred_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "# image color settings for RFC probabilities\n",
    "cmap = plt.cm.seismic\n",
    "vmin=0\n",
    "vmax=1\n",
    "\n",
    "yticks_example = np.arange(0, win_max_len-win_min_len+win_stretch_inc, 0.5) / win_stretch_inc\n",
    "ylabels_example = ['{}'.format(yticks_example[ii] * win_stretch_inc + win_min_len) for ii in range(len(yticks_example))]\n",
    "\n",
    "fig_example, ax_example = plt.subplots(figsize=(18,5.8))\n",
    "fig_example.subplots_adjust(bottom=0.2, right=0.9) # make space for buttons and color bar\n",
    "\n",
    "ax_example.imshow(example_pred_matrix.transpose(), \n",
    "                  interpolation='nearest',aspect='auto', cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "ax_example.invert_yaxis()\n",
    "ax_example.set_yticks(yticks_example)\n",
    "ax_example.set_yticklabels(ylabels_example, fontsize=16)\n",
    "ax_example.set_ylabel(r'window length $[s]$', fontsize=20)\n",
    "ax_example.yaxis.labelpad = 15\n",
    "ax_example.xaxis.set_ticklabels([])\n",
    "\n",
    "win_start_example = example_start_time_s\n",
    "formatter_example = matplotlib.ticker.FuncFormatter(lambda i,\n",
    "                                                    x: time.strftime('%M:%S', time.gmtime(i*win_start_inc+win_start_example)))\n",
    "ax_example.xaxis.set_major_formatter(formatter_example)\n",
    "ax_example.tick_params(labelsize=16)\n",
    "ax_example.set_xlabel(r'window start time $[min:sec]$', fontsize=20)\n",
    "ax_example.xaxis.labelpad = 12\n",
    "\n",
    "cbar_ax = fig_example.add_axes([0.94, 0.2, 0.02, 0.68])\n",
    "cbar_ax = fig_example.colorbar(s, cax=cbar_ax)\n",
    "cbar_ax.ax.tick_params(labelsize=16)\n",
    "cbar_ax.ax.set_ylabel('predicted probability', fontsize=20)\n",
    "cbar_ax.ax.yaxis.labelpad = -90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "grid_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
