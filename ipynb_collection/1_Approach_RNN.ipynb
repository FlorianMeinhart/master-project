{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T22:54:30.322124Z",
     "start_time": "2018-12-26T22:54:30.312123Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "from datetime import datetime\n",
    "import functionsMasterProjectMeinhart as fmpm\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T00:13:45.775120Z",
     "start_time": "2018-12-27T00:13:45.763120Z"
    }
   },
   "outputs": [],
   "source": [
    "# define some parameters\n",
    "element_size = 6\n",
    "time_steps = 48 # number of steps for 6 s at 8 Hz\n",
    "num_classes = 11\n",
    "batch_size = 128\n",
    "hidden_layer_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T22:54:30.626141Z",
     "start_time": "2018-12-26T22:54:30.455131Z"
    }
   },
   "outputs": [],
   "source": [
    "def one_hot(vec, vals=num_classes):\n",
    "    n = len(vec)\n",
    "    out = np.zeros((n, vals))\n",
    "    out[range(n), vec] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T22:54:30.785150Z",
     "start_time": "2018-12-26T22:54:30.634142Z"
    }
   },
   "outputs": [],
   "source": [
    "#one_hot(y_test_all.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T22:54:31.024164Z",
     "start_time": "2018-12-26T22:54:30.793151Z"
    }
   },
   "outputs": [],
   "source": [
    "# load all data, except data from one subject (test data)\n",
    "test_data_subject = 1\n",
    "\n",
    "db_name='DataBase_Physio_with_nonEx.db' # database name\n",
    "exercise_abbrs = ['RF','RO','RS','LR','BC','TC','MP','SA','P1','P2','NE'] # exercise abbreviations\n",
    "# Connect to an existing database\n",
    "conn = sqlite3.connect(db_name)\n",
    "cur = conn.cursor()\n",
    "train_data_points = {} # dictionary with the exercise abbreviation as key\n",
    "test_data_points = {}\n",
    "\n",
    "for key in exercise_abbrs:\n",
    "    # sql command to extract data\n",
    "    query_sql = \"\"\"\n",
    "        SELECT r.start_time, r.stop_time, e.csv_file\n",
    "        FROM subjects s\n",
    "        INNER JOIN exercises e\n",
    "        ON s.id = e.subject_id\n",
    "        INNER JOIN paradigms p\n",
    "        ON p.id = e.paradigm_id\n",
    "        INNER JOIN repetitions r\n",
    "        ON e.id = r.exercise_id\n",
    "        WHERE p.abbreviation = '{}'\n",
    "        AND NOT s.id = {}\n",
    "        \"\"\".format(key, test_data_subject)\n",
    "    # get data from data base and close connection\n",
    "    train_data_points[key] = pd.read_sql_query(query_sql, conn)\n",
    "\n",
    "for key in exercise_abbrs:\n",
    "    # sql command to extract data\n",
    "    query_sql = \"\"\"\n",
    "        SELECT r.start_time, r.stop_time, e.csv_file\n",
    "        FROM subjects s\n",
    "        INNER JOIN exercises e\n",
    "        ON s.id = e.subject_id\n",
    "        INNER JOIN paradigms p\n",
    "        ON p.id = e.paradigm_id\n",
    "        INNER JOIN repetitions r\n",
    "        ON e.id = r.exercise_id\n",
    "        WHERE p.abbreviation = '{}'\n",
    "        AND s.id = {}\n",
    "        \"\"\".format(key, test_data_subject)\n",
    "    # get data from data base and close connection\n",
    "    test_data_points[key] = pd.read_sql_query(query_sql, conn)\n",
    "    \n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T22:54:31.113169Z",
     "start_time": "2018-12-26T22:54:31.027164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points (repetitions) for training:\n",
      "RF:\t239\n",
      "RO:\t240\n",
      "RS:\t240\n",
      "LR:\t241\n",
      "BC:\t242\n",
      "TC:\t243\n",
      "MP:\t242\n",
      "SA:\t242\n",
      "P1:\t240\n",
      "P2:\t239\n",
      "NE:\t3712\n",
      "total:\t6120\n",
      "\n",
      "Number of data points (repetitions) for testing:\n",
      "RF:\t30\n",
      "RO:\t30\n",
      "RS:\t30\n",
      "LR:\t30\n",
      "BC:\t31\n",
      "TC:\t30\n",
      "MP:\t30\n",
      "SA:\t31\n",
      "P1:\t30\n",
      "P2:\t30\n",
      "NE:\t407\n",
      "total:\t709\n"
     ]
    }
   ],
   "source": [
    "print('Number of data points (repetitions) for training:')\n",
    "count = 0\n",
    "for key in exercise_abbrs:\n",
    "    print(key + ':\\t' + str(train_data_points[key].shape[0]))\n",
    "    count += train_data_points[key].shape[0]\n",
    "print('total:\\t' + str(count))\n",
    "\n",
    "print('\\nNumber of data points (repetitions) for testing:')\n",
    "count = 0\n",
    "for key in exercise_abbrs:\n",
    "    print(key + ':\\t' + str(test_data_points[key].shape[0]))\n",
    "    count += test_data_points[key].shape[0]\n",
    "print('total:\\t' + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T22:54:31.309180Z",
     "start_time": "2018-12-26T22:54:31.120170Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>stop_time</th>\n",
       "      <th>csv_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.6097522701321</td>\n",
       "      <td>subject02_00_nonEx.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.6097522701321</td>\n",
       "      <td>5.98056861437206</td>\n",
       "      <td>subject02_00_nonEx.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.98056861437206</td>\n",
       "      <td>7.84471642992804</td>\n",
       "      <td>subject02_00_nonEx.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.84471642992804</td>\n",
       "      <td>12.3377339822144</td>\n",
       "      <td>subject02_00_nonEx.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.3377339822144</td>\n",
       "      <td>15.5979262935134</td>\n",
       "      <td>subject02_00_nonEx.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         start_time         stop_time                csv_file\n",
       "0                 0   3.6097522701321  subject02_00_nonEx.csv\n",
       "1   3.6097522701321  5.98056861437206  subject02_00_nonEx.csv\n",
       "2  5.98056861437206  7.84471642992804  subject02_00_nonEx.csv\n",
       "3  7.84471642992804  12.3377339822144  subject02_00_nonEx.csv\n",
       "4  12.3377339822144  15.5979262935134  subject02_00_nonEx.csv"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Head of one loaded data frame as an example:\n",
    "train_data_points['NE'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T22:54:31.450188Z",
     "start_time": "2018-12-26T22:54:31.317181Z"
    }
   },
   "outputs": [],
   "source": [
    "# dictionary for labels\n",
    "ex_abbr2ind = { 'RF':0,\n",
    "                'RO':1,\n",
    "                'RS':2,\n",
    "                'LR':3,\n",
    "                'BC':4,\n",
    "                'TC':5,\n",
    "                'MP':6,\n",
    "                'SA':7,\n",
    "                'P1':8,\n",
    "                'P2':9,\n",
    "                'NE':10}\n",
    "\n",
    "ex_ind2abbr = {index: abbr for abbr, index in ex_abbr2ind.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T22:54:31.616198Z",
     "start_time": "2018-12-26T22:54:31.457189Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ex_abbr2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T22:54:31.761206Z",
     "start_time": "2018-12-26T22:54:31.621198Z"
    }
   },
   "outputs": [],
   "source": [
    "# putting all train data and labels together\n",
    "all_train_data = np.concatenate([train_data_points[ex_ind2abbr[ii]] for ii in range(len(ex_ind2abbr))], axis=0)\n",
    "\n",
    "y_train_all = np.zeros(np.shape(all_train_data)[0])\n",
    "start_ind = 0\n",
    "for ii in range(len(ex_ind2abbr)):\n",
    "    stop_ind = len(train_data_points[ex_ind2abbr[ii]]) + start_ind\n",
    "    y_train_all[start_ind:stop_ind] = ii\n",
    "    start_ind = stop_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T22:54:31.919215Z",
     "start_time": "2018-12-26T22:54:31.764206Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6120"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T22:54:32.067224Z",
     "start_time": "2018-12-26T22:54:31.925216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0.6509139384920637' '3.911928323412699' 'subject02_RF_05.csv']\n",
      " ['3.911928323412699' '7.031159474206351' 'subject02_RF_05.csv']\n",
      " ['7.031159474206351' '10.398511284722224' 'subject02_RF_05.csv']]\n"
     ]
    }
   ],
   "source": [
    "print(all_train_data[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T22:54:32.229233Z",
     "start_time": "2018-12-26T22:54:32.073224Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_dir  = 'E:\\Physio_Features'\n",
    "X_train_name = 'RNN_X_train_without_subject{0:02}_8Hz.csv'.format(\n",
    "                    test_data_subject)\n",
    "y_train_name = 'RNN_y_train_without_subject{0:02}_8Hz.csv'.format(\n",
    "                    test_data_subject)\n",
    "seqlens_train_name = 'RNN_seqlens_train_without_subject{0:02}_8Hz.csv'.format(\n",
    "                    test_data_subject)\n",
    "\n",
    "X_train_path = os.path.join(X_train_dir, X_train_name)\n",
    "y_train_path = os.path.join(X_train_dir, y_train_name)\n",
    "seqlens_train_path = os.path.join(X_train_dir, seqlens_train_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T22:54:34.475361Z",
     "start_time": "2018-12-26T22:54:32.234233Z"
    }
   },
   "outputs": [],
   "source": [
    "# only generate the train data if they do not already exist\n",
    "if not os.path.isfile(X_train_path):\n",
    "    \n",
    "    # Generating one corresponding matrix for train data\n",
    "    X_train_all = []\n",
    "    seqlens_train_all = []\n",
    "\n",
    "    factor_256_to_8Hz = 32\n",
    "    steps_6s_256Hz = 6 * 256\n",
    "\n",
    "    # directory of csv file\n",
    "    csv_dir='E:\\Physio_Data_Split_Ex_and_NonEx'\n",
    "\n",
    "    for ii in range(len(all_train_data)):\n",
    "\n",
    "        data = all_train_data[ii]\n",
    "\n",
    "        signal_data = fmpm.get_sensor_data(os.path.join(csv_dir, data[2]),\n",
    "                    signals=['Acc','Gyr'], \n",
    "                    sampling_rate=256,\n",
    "                    start_time=float(data[0]), \n",
    "                    stop_time=float(data[1]))\n",
    "\n",
    "        X_one = np.zeros((time_steps, element_size))\n",
    "        seqlens_train_all.append(int(len(signal_data['Acc'][:,0]) / factor_256_to_8Hz)) # all columns have same length\n",
    "\n",
    "        col_inc = 0\n",
    "        for sig in ['Acc','Gyr']:\n",
    "            for col in [0,1,2]:\n",
    "                puffer_6s_256Hz = np.zeros(steps_6s_256Hz) # 6 s at sampling rate 256 Hz\n",
    "                puffer_6s_256Hz[:len(signal_data[sig][:,col])] = signal_data[sig][:,col]\n",
    "                puffer_6s_8Hz = puffer_6s_256Hz.reshape(-1, factor_256_to_8Hz).mean(axis=1)\n",
    "                X_one[:,col+col_inc] = puffer_6s_8Hz\n",
    "\n",
    "            col_inc += 3\n",
    "\n",
    "        X_train_all.append(X_one)\n",
    "    \n",
    "    X_train_all_save = np.array(X_train_all).reshape(6120,-1)\n",
    "    \n",
    "    np.savetxt(X_train_path, X_train_all_save, delimiter=\";\")\n",
    "    np.savetxt(y_train_path, y_train_all, delimiter=\";\")\n",
    "    np.savetxt(seqlens_train_path, seqlens_train_all, delimiter=\";\")\n",
    "    \n",
    "# otherwise load them\n",
    "else:\n",
    "    X_train_all_loaded = np.loadtxt(open(X_train_path), delimiter=\";\")\n",
    "    X_train_all = X_train_all_loaded.reshape(-1, time_steps, element_size)\n",
    "\n",
    "    y_train_all = np.loadtxt(open(y_train_path), delimiter=\";\")\n",
    "    seqlens_train_all = np.loadtxt(open(seqlens_train_path), delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T00:13:04.217743Z",
     "start_time": "2018-12-27T00:13:04.189742Z"
    }
   },
   "outputs": [],
   "source": [
    "# putting all test data and labels together\n",
    "all_test_data = np.concatenate([test_data_points[ex_ind2abbr[ii]] for ii in range(len(ex_ind2abbr))], axis=0)\n",
    "\n",
    "y_test_all = np.zeros(np.shape(all_test_data)[0])\n",
    "start_ind = 0\n",
    "for ii in range(len(ex_ind2abbr)):\n",
    "    stop_ind = len(test_data_points[ex_ind2abbr[ii]]) + start_ind\n",
    "    y_test_all[start_ind:stop_ind] = ii\n",
    "    start_ind = stop_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T00:25:07.940138Z",
     "start_time": "2018-12-27T00:24:40.663578Z"
    }
   },
   "outputs": [],
   "source": [
    "# define some parameters\n",
    "element_size = 6\n",
    "time_steps = 48 # number of steps for 6 s at 8 Hz\n",
    "num_classes = 11\n",
    "batch_size = 128\n",
    "hidden_layer_size = 128\n",
    "\n",
    "# Generating one corresponding matrix for test data\n",
    "X_test_all = []\n",
    "seqlens_test_all = []\n",
    "\n",
    "factor_256_to_8Hz = 32\n",
    "steps_6s_256Hz = 6 * 256\n",
    "\n",
    "# directory of csv file\n",
    "csv_dir='E:\\Physio_Data_Split_Ex_and_NonEx'\n",
    "\n",
    "for ii in range(len(all_test_data)):\n",
    "\n",
    "    data = all_test_data[ii]\n",
    "\n",
    "    signal_data = fmpm.get_sensor_data(os.path.join(csv_dir, data[2]),\n",
    "                signals=['Acc','Gyr'], \n",
    "                sampling_rate=256,\n",
    "                start_time=float(data[0]), \n",
    "                stop_time=float(data[1]))\n",
    "\n",
    "    X_one = np.zeros((time_steps, element_size))\n",
    "    seqlens_test_all.append(int(len(signal_data['Acc'][:,0]) / factor_256_to_8Hz)) # all columns have same length\n",
    "\n",
    "    col_inc = 0\n",
    "    for sig in ['Acc','Gyr']:\n",
    "        for col in [0,1,2]:\n",
    "            puffer_6s_256Hz = np.zeros(steps_6s_256Hz) # 6 s at sampling rate 256 Hz\n",
    "            puffer_6s_256Hz[:len(signal_data[sig][:,col])] = signal_data[sig][:,col]\n",
    "            puffer_6s_8Hz = puffer_6s_256Hz.reshape(-1, factor_256_to_8Hz).mean(axis=1)\n",
    "            X_one[:,col+col_inc] = puffer_6s_8Hz\n",
    "\n",
    "        col_inc += 3\n",
    "\n",
    "    X_test_all.append(X_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T22:55:01.443904Z",
     "start_time": "2018-12-26T22:55:01.432903Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(709, 48, 6)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T00:28:56.505211Z",
     "start_time": "2018-12-27T00:28:29.173648Z"
    }
   },
   "outputs": [],
   "source": [
    "# define some parameters\n",
    "element_size = 6\n",
    "time_steps = 96 # number of steps for 6 s at 16 Hz\n",
    "num_classes = 11\n",
    "batch_size = 128\n",
    "hidden_layer_size = 128\n",
    "\n",
    "# Generating one corresponding matrix for test data\n",
    "X_test_all = []\n",
    "seqlens_test_all = []\n",
    "\n",
    "factor_256_to_8Hz = 16\n",
    "steps_6s_256Hz = 6 * 256\n",
    "\n",
    "# directory of csv file\n",
    "csv_dir='E:\\Physio_Data_Split_Ex_and_NonEx'\n",
    "\n",
    "for ii in range(len(all_test_data)):\n",
    "\n",
    "    data = all_test_data[ii]\n",
    "\n",
    "    signal_data = fmpm.get_sensor_data(os.path.join(csv_dir, data[2]),\n",
    "                signals=['Acc','Gyr'], \n",
    "                sampling_rate=256,\n",
    "                start_time=float(data[0]), \n",
    "                stop_time=float(data[1]))\n",
    "\n",
    "    X_one = np.zeros((time_steps, element_size))\n",
    "    seqlens_test_all.append(int(len(signal_data['Acc'][:,0]) / factor_256_to_8Hz)) # all columns have same length\n",
    "\n",
    "    col_inc = 0\n",
    "    for sig in ['Acc','Gyr']:\n",
    "        for col in [0,1,2]:\n",
    "            puffer_6s_256Hz = np.zeros(steps_6s_256Hz) # 6 s at sampling rate 256 Hz\n",
    "            puffer_6s_256Hz[:len(signal_data[sig][:,col])] = signal_data[sig][:,col]\n",
    "            puffer_6s_8Hz = puffer_6s_256Hz.reshape(-1, factor_256_to_8Hz).mean(axis=1)\n",
    "            X_one[:,col+col_inc] = puffer_6s_8Hz\n",
    "\n",
    "        col_inc += 3\n",
    "\n",
    "    X_test_all.append(X_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T00:29:11.646077Z",
     "start_time": "2018-12-27T00:29:11.627076Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(709, 96, 6)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-16T21:31:36.050041Z",
     "start_time": "2018-12-16T21:31:36.044040Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T00:29:19.910550Z",
     "start_time": "2018-12-27T00:29:19.886548Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_train_batch(batch_size, X_train_all, y_train_all, seqlens_train_all):\n",
    "    \n",
    "    instance_indices = list(range(len(all_train_data)))\n",
    "    np.random.shuffle(instance_indices)\n",
    "    batch_indices = instance_indices[:batch_size]\n",
    "\n",
    "    X = np.array(X_train_all)[batch_indices]\n",
    "    y = y_train_all[batch_indices]\n",
    "    seqlens = np.array(seqlens_train_all)[batch_indices]\n",
    "    \n",
    "    return X, y, seqlens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T00:29:20.300572Z",
     "start_time": "2018-12-27T00:29:20.275571Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y, seqlens = get_train_batch(batch_size, X_train_all, y_train_all, seqlens_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T00:29:20.659593Z",
     "start_time": "2018-12-27T00:29:20.649592Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 48, 6)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T00:29:21.766656Z",
     "start_time": "2018-12-27T00:29:21.753655Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Jupyter_Notebooks\\\\Master_Project_Meinhart'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T00:29:26.154907Z",
     "start_time": "2018-12-27T00:29:26.139906Z"
    }
   },
   "outputs": [],
   "source": [
    "# where to save TensorBoard model summaries\n",
    "\n",
    "LOG_DIR_ALL = \"logs/RNN_with_summaries\"\n",
    "\n",
    "# tensorboard --logdir=logs/RNN_with_summaries\n",
    "\n",
    "#  http://FlorianMeinhart:6006\n",
    "\n",
    "# define some parameters\n",
    "#element_size = 6\n",
    "#time_steps = 48 # number of steps for 6 s at 8 Hz\n",
    "#num_classes = 11\n",
    "#batch_size = 128\n",
    "#hidden_layer_size = 128\n",
    "\n",
    "batch_size = 256\n",
    "time_steps = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T22:43:36.468726Z",
     "start_time": "2018-12-26T22:43:36.456725Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T00:37:29.288541Z",
     "start_time": "2018-12-27T00:37:28.700507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard --logdir=logs/RNN_with_summaries\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "LOG_DIR_TRAIN = LOG_DIR_ALL + now.strftime('/%Y%m%d-%H%M%S' + '_train')\n",
    "LOG_DIR_TEST = LOG_DIR_ALL + now.strftime('/%Y%m%d-%H%M%S' + '_test')\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.name_scope('data'):\n",
    "    inputs = tf.placeholder(tf.float32, shape=[None, time_steps, element_size], name='inputs')\n",
    "    labels = tf.placeholder(tf.int32, shape=[None, num_classes], name='labels')\n",
    "    seqlens = tf.placeholder(tf.int32, shape=[None], name='seqlens')\n",
    "\n",
    "with tf.name_scope('RNN_layer'):\n",
    "    #rnn_cell = tf.nn.rnn_cell.BasicRNNCell(hidden_layer_size)\n",
    "    rnn_cell = tf.nn.rnn_cell.BasicLSTMCell(hidden_layer_size)\n",
    "    outputs, states = tf.nn.dynamic_rnn(rnn_cell, inputs, sequence_length=seqlens, dtype=tf.float32)\n",
    "\n",
    "with tf.name_scope('linear_layer'):\n",
    "    W1 = tf.Variable(tf.truncated_normal([hidden_layer_size, num_classes], mean=0, stddev=0.1), name='weights_linear')\n",
    "    b1 = tf.Variable(tf.truncated_normal([num_classes], mean=0, stddev=0.1), name='biases_linear')\n",
    "    #final_output = tf.matmul(states, W1) + b1\n",
    "    final_output = tf.matmul(states[0], W1) + b1\n",
    "    \n",
    "    softmax = tf.nn.softmax_cross_entropy_with_logits_v2(logits=final_output, labels=labels)\n",
    "    cross_entropy = tf.reduce_mean(softmax)\n",
    "    tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "\n",
    "\n",
    "train_step = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cross_entropy)\n",
    "#train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)\n",
    "\n",
    "with tf.name_scope('evaluation'):\n",
    "    correct_prediction = tf.equal(tf.argmax(labels,1), tf.argmax(final_output,1), name='correct_prediction')\n",
    "    accuracy = (tf.reduce_mean(tf.cast(correct_prediction, tf.float32)))*100\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "train_writer = tf.summary.FileWriter(LOG_DIR_TRAIN)\n",
    "test_writer = tf.summary.FileWriter(LOG_DIR_TEST)\n",
    "\n",
    "print('tensorboard --logdir=' + LOG_DIR_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T00:42:46.476683Z",
     "start_time": "2018-12-27T00:37:29.339543Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy at step 0\n",
      "\tTrain Set: 17.188\n",
      "\tTest Set:  20.733\n",
      "Accuracy at step 20\n",
      "\tTrain Set: 50.000\n",
      "\tTest Set:  42.454\n",
      "Accuracy at step 40\n",
      "\tTrain Set: 78.516\n",
      "\tTest Set:  67.419\n",
      "Accuracy at step 60\n",
      "\tTrain Set: 88.281\n",
      "\tTest Set:  76.023\n",
      "Accuracy at step 80\n",
      "\tTrain Set: 88.672\n",
      "\tTest Set:  78.420\n",
      "Accuracy at step 100\n",
      "\tTrain Set: 91.016\n",
      "\tTest Set:  84.344\n",
      "Accuracy at step 120\n",
      "\tTrain Set: 94.141\n",
      "\tTest Set:  84.062\n",
      "Accuracy at step 140\n",
      "\tTrain Set: 94.531\n",
      "\tTest Set:  82.934\n",
      "Accuracy at step 160\n",
      "\tTrain Set: 98.047\n",
      "\tTest Set:  88.011\n",
      "Accuracy at step 180\n",
      "\tTrain Set: 99.609\n",
      "\tTest Set:  89.704\n",
      "Accuracy at step 200\n",
      "\tTrain Set: 99.609\n",
      "\tTest Set:  89.281\n",
      "Accuracy at step 220\n",
      "\tTrain Set: 96.875\n",
      "\tTest Set:  88.152\n",
      "Accuracy at step 240\n",
      "\tTrain Set: 99.609\n",
      "\tTest Set:  91.537\n",
      "Accuracy at step 260\n",
      "\tTrain Set: 96.484\n",
      "\tTest Set:  92.525\n",
      "Accuracy at step 280\n",
      "\tTrain Set: 99.609\n",
      "\tTest Set:  88.716\n",
      "Accuracy at step 300\n",
      "\tTrain Set: 99.219\n",
      "\tTest Set:  90.832\n",
      "Accuracy at step 320\n",
      "\tTrain Set: 99.219\n",
      "\tTest Set:  91.961\n",
      "Accuracy at step 340\n",
      "\tTrain Set: 99.609\n",
      "\tTest Set:  90.127\n",
      "Accuracy at step 360\n",
      "\tTrain Set: 100.000\n",
      "\tTest Set:  91.678\n",
      "Accuracy at step 380\n",
      "\tTrain Set: 100.000\n",
      "\tTest Set:  90.268\n",
      "Accuracy at step 400\n",
      "\tTrain Set: 99.609\n",
      "\tTest Set:  92.525\n",
      "Accuracy at step 420\n",
      "\tTrain Set: 96.094\n",
      "\tTest Set:  91.114\n",
      "Accuracy at step 440\n",
      "\tTrain Set: 99.609\n",
      "\tTest Set:  91.819\n",
      "Accuracy at step 460\n",
      "\tTrain Set: 100.000\n",
      "\tTest Set:  91.255\n",
      "Accuracy at step 480\n",
      "\tTrain Set: 100.000\n",
      "\tTest Set:  92.666\n",
      "Accuracy at step 500\n",
      "\tTrain Set: 99.609\n",
      "\tTest Set:  92.807\n",
      "Accuracy at step 520\n",
      "\tTrain Set: 99.609\n",
      "\tTest Set:  91.678\n",
      "Accuracy at step 540\n",
      "\tTrain Set: 100.000\n",
      "\tTest Set:  91.819\n",
      "Accuracy at step 560\n",
      "\tTrain Set: 100.000\n",
      "\tTest Set:  90.973\n",
      "Accuracy at step 580\n",
      "\tTrain Set: 98.438\n",
      "\tTest Set:  91.537\n",
      "Accuracy at step 600\n",
      "\tTrain Set: 99.609\n",
      "\tTest Set:  92.666\n",
      "Accuracy at step 620\n",
      "\tTrain Set: 100.000\n",
      "\tTest Set:  92.243\n",
      "Accuracy at step 640\n",
      "\tTrain Set: 100.000\n",
      "\tTest Set:  91.255\n",
      "Accuracy at step 660\n",
      "\tTrain Set: 100.000\n",
      "\tTest Set:  92.948\n",
      "Accuracy at step 680\n",
      "\tTrain Set: 100.000\n",
      "\tTest Set:  92.525\n",
      "Accuracy at step 700\n",
      "\tTrain Set: 100.000\n",
      "\tTest Set:  92.948\n",
      "Accuracy at step 720\n",
      "\tTrain Set: 100.000\n",
      "\tTest Set:  91.678\n",
      "Accuracy at step 740\n",
      "\tTrain Set: 100.000\n",
      "\tTest Set:  92.384\n",
      "Accuracy at step 760\n",
      "\tTrain Set: 99.219\n",
      "\tTest Set:  93.089\n",
      "Accuracy at step 780\n",
      "\tTrain Set: 100.000\n",
      "\tTest Set:  92.384\n",
      "Accuracy at step 800\n",
      "\tTrain Set: 99.609\n",
      "\tTest Set:  91.961\n",
      "Accuracy at step 820\n",
      "\tTrain Set: 100.000\n",
      "\tTest Set:  91.961\n",
      "Accuracy at step 840\n",
      "\tTrain Set: 100.000\n",
      "\tTest Set:  91.961\n",
      "Accuracy at step 860\n",
      "\tTrain Set: 100.000\n",
      "\tTest Set:  92.807\n",
      "Accuracy at step 880\n",
      "\tTrain Set: 100.000\n",
      "\tTest Set:  92.666\n",
      "Accuracy at step 900\n",
      "\tTrain Set: 100.000\n",
      "\tTest Set:  92.666\n",
      "Accuracy at step 920\n",
      "\tTrain Set: 100.000\n",
      "\tTest Set:  93.089\n",
      "Accuracy at step 940\n",
      "\tTrain Set: 99.219\n",
      "\tTest Set:  92.666\n",
      "Accuracy at step 960\n",
      "\tTrain Set: 100.000\n",
      "\tTest Set:  91.961\n",
      "Accuracy at step 980\n",
      "\tTrain Set: 100.000\n",
      "\tTest Set:  91.819\n",
      "Accuracy at step 1000\n",
      "\tTrain Set: 98.047\n",
      "\tTest Set:  92.948\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    train_writer.add_graph(sess.graph)\n",
    "    test_writer.add_graph(sess.graph)\n",
    "    \n",
    "    y_test_all_one_hot = one_hot(y_test_all.astype(int), vals=num_classes)\n",
    "    \n",
    "    for step in range(1001):\n",
    "        x_batch, y_batch, seqlens_batch = get_train_batch(batch_size, X_train_all, y_train_all, seqlens_train_all)\n",
    "        \n",
    "        y_batch_one_hot = one_hot(y_batch.astype(int), vals=num_classes)\n",
    "        \n",
    "        sess.run(train_step, feed_dict={inputs:x_batch, labels:y_batch_one_hot, seqlens:seqlens_batch})\n",
    "        \n",
    "        if step % 20 == 0:\n",
    "            summary_train, accuracy_train = sess.run([merged, accuracy], \n",
    "                                                      feed_dict={inputs:x_batch, \n",
    "                                                                 labels:y_batch_one_hot, \n",
    "                                                                 seqlens:seqlens_batch})\n",
    "            print('Accuracy at step {}'.format(step))\n",
    "            print('\\tTrain Set: {:.3f}'.format(accuracy_train))\n",
    "            train_writer.add_summary(summary_train, step)\n",
    "    \n",
    "            summary_test, batch_pred, accuracy_test = sess.run([merged, tf.argmax(final_output,1), accuracy],\n",
    "                                                                feed_dict={inputs:X_test_all, \n",
    "                                                                           labels:y_test_all_one_hot, \n",
    "                                                                           seqlens:seqlens_test_all})\n",
    "            test_writer.add_summary(summary_test, step)\n",
    "    \n",
    "            print('\\tTest Set:  {:.3f}'.format(accuracy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T23:03:26.762807Z",
     "start_time": "2018-12-26T23:03:26.745806Z"
    }
   },
   "outputs": [],
   "source": [
    "def one_hot_back(mat_one_hot, vals=num_classes):\n",
    "    n = np.shape(mat_one_hot)[0]\n",
    "    out = np.zeros(n)\n",
    "    for ii in range(num_classes):\n",
    "        ind = np.where(mat_one_hot[:,ii])\n",
    "        out[ind] = ii\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T23:03:27.171830Z",
     "start_time": "2018-12-26T23:03:26.765807Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.,  7.,  3., 10.,  0.,  3., 10., 10., 10., 10., 10., 10., 10.,\n",
       "       10., 10., 10., 10.,  2.,  2., 10., 10.,  8.,  3., 10.,  1., 10.,\n",
       "        0.,  7., 10., 10.,  9., 10.,  8., 10., 10.,  7.,  9.,  0.,  0.,\n",
       "       10., 10., 10., 10., 10., 10., 10.,  0.,  8.,  5.,  3.,  5., 10.,\n",
       "        6.,  5.,  5.,  8., 10., 10., 10., 10.,  4., 10., 10., 10.,  7.,\n",
       "        5.,  3., 10., 10.,  4., 10.,  4., 10., 10., 10., 10., 10., 10.,\n",
       "        0.,  3., 10., 10., 10., 10.,  6., 10., 10., 10., 10., 10., 10.,\n",
       "        9., 10., 10., 10., 10., 10., 10., 10., 10.,  4.,  9., 10., 10.,\n",
       "        6., 10., 10., 10., 10., 10.,  8., 10.,  7., 10.,  2.,  1., 10.,\n",
       "       10., 10., 10., 10.,  1., 10.,  3.,  3., 10.,  6., 10.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_back(y_batch_one_hot, vals=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T23:13:56.978853Z",
     "start_time": "2018-12-26T23:13:56.919849Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_precision_recall_accuracy(y_pred, y_test):\n",
    "    '''\n",
    "    This function prints precision, recall and accuracy for each exercise.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_pred : array\n",
    "        Prediceted classes (0...10).\n",
    "    \n",
    "    y_test : array\n",
    "        Actual classes (0...10).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    '''\n",
    "    \n",
    "    # exercise abbreviations\n",
    "    exercise_abbrs = ['RF','RO','RS','LR','BC','TC','MP','SA','P1','P2','NE']\n",
    "    \n",
    "    # dictionary for labels\n",
    "    label_ex = {'RF':0,'RO':1,'RS':2,'LR':3,'BC':4,'TC':5,'MP':6,'SA':7,'P1':8,'P2':9,'NE':10}\n",
    "\n",
    "    \n",
    "    print('Exercise\\tPrecision [%]\\tRecall [%]\\tAccuracy[%]')\n",
    "    \n",
    "    for ex in exercise_abbrs:\n",
    "        TP = sum((y_pred == label_ex[ex]) & (np.array(y_test) == label_ex[ex])) # True Positives\n",
    "        TN = sum((y_pred != label_ex[ex]) & (np.array(y_test) != label_ex[ex])) # True Negatives\n",
    "        FP = sum((y_pred == label_ex[ex]) & (np.array(y_test) != label_ex[ex])) # False Positives\n",
    "        FN = sum((y_pred != label_ex[ex]) & (np.array(y_test) == label_ex[ex])) # False Negatives\n",
    "\n",
    "        precision = TP / (TP+FP)\n",
    "        recall = TP / (TP+FN)\n",
    "        accuracy = (TP+TN) / (TP+TN+FP+FN)\n",
    "        \n",
    "        print('  '+ ex +'\\t\\t  {:6.2f}'.format(precision*100)+ \\\n",
    "              '\\t  {:6.2f}'.format(recall*100)+'\\t  {:6.2f}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T23:13:57.374875Z",
     "start_time": "2018-12-26T23:13:57.223867Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_misclassified_data_points(y_pred, y_test):\n",
    "    '''\n",
    "    This funciton prints all misclassified data points.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_pred : array\n",
    "        Prediceted classes (0...9).\n",
    "    \n",
    "    y_test : array\n",
    "        Actual classes (0...9).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    '''\n",
    "    \n",
    "    # exercise abbreviations\n",
    "    exercise_abbrs = ['RF','RO','RS','LR','BC','TC','MP','SA','P1','P2','NE'] \n",
    "    \n",
    "    # indices of misclassified data points\n",
    "    ind_misclassified = np.flatnonzero(y_test != y_pred) \n",
    "\n",
    "    # print misclassified data points\n",
    "    print('{0} misclassified ({1} test data points):'.format(sum(y_test != y_pred), len(y_test)))\n",
    "    for ii in ind_misclassified:\n",
    "        print(exercise_abbrs[y_test[ii]] + ' classified as ' + exercise_abbrs[y_pred[ii]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T00:42:46.680694Z",
     "start_time": "2018-12-27T00:42:46.493684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise\tPrecision [%]\tRecall [%]\tAccuracy[%]\n",
      "  RF\t\t   50.00\t  100.00\t   95.77\n",
      "  RO\t\t     nan\t    0.00\t   95.77\n",
      "  RS\t\t   74.29\t   86.67\t   98.17\n",
      "  LR\t\t  100.00\t   96.67\t   99.86\n",
      "  BC\t\t  100.00\t  100.00\t  100.00\n",
      "  TC\t\t  100.00\t  100.00\t  100.00\n",
      "  MP\t\t   96.43\t   90.00\t   99.44\n",
      "  SA\t\t  100.00\t  100.00\t  100.00\n",
      "  P1\t\t   96.77\t  100.00\t   99.86\n",
      "  P2\t\t   91.30\t   70.00\t   98.45\n",
      "  NE\t\t   98.30\t   99.26\t   98.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Programme\\WinPython-64bit-3.6.2.0Qt5\\python-3.6.2.amd64\\lib\\site-packages\\ipykernel_launcher.py:33: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    }
   ],
   "source": [
    "print_precision_recall_accuracy(batch_pred, y_test_all.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T00:43:00.752499Z",
     "start_time": "2018-12-27T00:43:00.718497Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 misclassified (709 test data points):\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RO classified as RF\n",
      "RS classified as P2\n",
      "RS classified as P2\n",
      "RS classified as NE\n",
      "RS classified as NE\n",
      "LR classified as RS\n",
      "MP classified as NE\n",
      "MP classified as NE\n",
      "MP classified as NE\n",
      "P2 classified as NE\n",
      "P2 classified as NE\n",
      "P2 classified as RS\n",
      "P2 classified as RS\n",
      "P2 classified as RS\n",
      "P2 classified as RS\n",
      "P2 classified as RS\n",
      "P2 classified as RS\n",
      "P2 classified as RS\n",
      "NE classified as RS\n",
      "NE classified as P1\n",
      "NE classified as MP\n"
     ]
    }
   ],
   "source": [
    "print_misclassified_data_points(batch_pred, y_test_all.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "227px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
