{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 0,
        "width": 12
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "# First Machine Learning Approach with Exercise and Non-Ex. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:08:49.903290Z",
     "start_time": "2018-12-17T22:08:49.884288Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import time\n",
    "import itertools\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider, TextBox, Button\n",
    "from IPython.display import clear_output\n",
    "import functionsMasterProjectMeinhart as fmpm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 4,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:08:50.136303Z",
     "start_time": "2018-12-17T22:08:49.959293Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# load all data, except data from one subject (test data)\n",
    "test_data_subject = 1\n",
    "\n",
    "db_name='DataBase_Physio_with_nonEx.db' # database name\n",
    "exercise_abbrs = ['RF','RO','RS','LR','BC','TC','MP','SA','P1','P2','NE'] # exercise abbreviations\n",
    "# Connect to an existing database\n",
    "conn = sqlite3.connect(db_name)\n",
    "cur = conn.cursor()\n",
    "train_data_points = {} # dictionary with the exercise abbreviation as key\n",
    "for key in exercise_abbrs:\n",
    "    # sql command to extract data\n",
    "    query_sql = \"\"\"\n",
    "        SELECT r.start_time, r.stop_time, e.csv_file\n",
    "        FROM subjects s\n",
    "        INNER JOIN exercises e\n",
    "        ON s.id = e.subject_id\n",
    "        INNER JOIN paradigms p\n",
    "        ON p.id = e.paradigm_id\n",
    "        INNER JOIN repetitions r\n",
    "        ON e.id = r.exercise_id\n",
    "        WHERE p.abbreviation = '{}'\n",
    "        AND NOT s.id = {}\n",
    "        \"\"\".format(key, test_data_subject)\n",
    "    # get data from data base and close connection\n",
    "    train_data_points[key] = pd.read_sql_query(query_sql, conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:08:50.228308Z",
     "start_time": "2018-12-17T22:08:50.190306Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 7,
        "hidden": false,
        "row": 4,
        "width": 5
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>stop_time</th>\n",
       "      <th>csv_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.6097522701321</td>\n",
       "      <td>subject02_00_nonEx.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.6097522701321</td>\n",
       "      <td>5.98056861437206</td>\n",
       "      <td>subject02_00_nonEx.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.98056861437206</td>\n",
       "      <td>7.84471642992804</td>\n",
       "      <td>subject02_00_nonEx.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.84471642992804</td>\n",
       "      <td>12.3377339822144</td>\n",
       "      <td>subject02_00_nonEx.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.3377339822144</td>\n",
       "      <td>15.5979262935134</td>\n",
       "      <td>subject02_00_nonEx.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         start_time         stop_time                csv_file\n",
       "0                 0   3.6097522701321  subject02_00_nonEx.csv\n",
       "1   3.6097522701321  5.98056861437206  subject02_00_nonEx.csv\n",
       "2  5.98056861437206  7.84471642992804  subject02_00_nonEx.csv\n",
       "3  7.84471642992804  12.3377339822144  subject02_00_nonEx.csv\n",
       "4  12.3377339822144  15.5979262935134  subject02_00_nonEx.csv"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Head of one loaded data frame as an example:\n",
    "train_data_points['NE'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:08:50.364316Z",
     "start_time": "2018-12-17T22:08:50.284311Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 9,
        "hidden": false,
        "row": 8,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the individual data frames:\n",
      "RF:\t239\n",
      "RO:\t240\n",
      "RS:\t240\n",
      "LR:\t241\n",
      "BC:\t242\n",
      "TC:\t243\n",
      "MP:\t242\n",
      "SA:\t242\n",
      "P1:\t240\n",
      "P2:\t239\n",
      "NE:\t3712\n",
      "total:\t6120\n"
     ]
    }
   ],
   "source": [
    "print('Length of the individual data frames:')\n",
    "count = 0\n",
    "for key in exercise_abbrs:\n",
    "    print(key + ':\\t' + str(train_data_points[key].shape[0]))\n",
    "    count += train_data_points[key].shape[0]\n",
    "print('total:\\t' + str(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 11,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "## Generate and save features for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:08:50.533326Z",
     "start_time": "2018-12-17T22:08:50.419319Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 11,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Physio_Features\\features_without_subject01_Ex_nonEx_sections10.csv\n"
     ]
    }
   ],
   "source": [
    "# number of sections to split the signals\n",
    "number_sections = 10\n",
    "\n",
    "# directory of csv file\n",
    "csv_dir='E:\\Physio_Data_Split_Ex_and_NonEx'\n",
    "\n",
    "#  csv-file to save the features\n",
    "save_dir  = 'E:\\Physio_Features'\n",
    "save_file_name = 'features_without_subject{0:02}_Ex_nonEx_sections{1:02}.csv'.format(\n",
    "    test_data_subject, number_sections)\n",
    "feature_csv_file = os.path.join(save_dir, save_file_name)\n",
    "print(feature_csv_file)\n",
    "\n",
    "sampling_rate = 256 # [Hz]\n",
    "sig_names = ['Acc','Gyr'] # signals which shall be considered for the mean calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T12:05:12.986721Z",
     "start_time": "2018-12-10T12:05:12.965719Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 15,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "***Cell below is only executed if feature csv-file does not already exist***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:08:50.718336Z",
     "start_time": "2018-12-17T22:08:50.588329Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# this cell shall only be executed if the feature file does not already exist\n",
    "if not os.path.isfile(feature_csv_file):\n",
    "\n",
    "    # putting the header of the feature-file together\n",
    "    header_string = 'label;' # first column contains the labels\n",
    "\n",
    "    for sig in sig_names:\n",
    "        for ax in ['_x','_y','_z']:\n",
    "            for ii in range(number_sections):\n",
    "                header_string +=  sig + ax + '_{:02}'.format(ii+1) + ';'\n",
    "\n",
    "    # remove last separator (;)\n",
    "    idx_last_sep = header_string.rfind(\";\")\n",
    "    header_string =  header_string[:idx_last_sep]\n",
    "\n",
    "    # write header to file\n",
    "    with open(feature_csv_file, 'w') as feature_file:\n",
    "        feature_file.writelines(header_string + '\\n')\n",
    "\n",
    "    # go through all exercises\n",
    "    for ex in exercise_abbrs:\n",
    "\n",
    "        # go through all repetitions (data points) of the current exercise\n",
    "        for ii in range(len(train_data_points[ex])):\n",
    "\n",
    "            # join file path\n",
    "            file_path = os.path.join(csv_dir, train_data_points[ex]['csv_file'][ii])\n",
    "\n",
    "            # load the signal data of the corresponding time range of the current repetition\n",
    "            selected_data = fmpm.get_sensor_data(in_file = file_path, \n",
    "                                                 signals = sig_names, \n",
    "                                                 sampling_rate = sampling_rate, \n",
    "                                                 start_time = float(train_data_points[ex]['start_time'][ii]), \n",
    "                                                 stop_time = float(train_data_points[ex]['stop_time'][ii]))\n",
    "\n",
    "            # calculate the corresponding section means of the current repetition\n",
    "            section_means = fmpm.split_range_into_sections(signal_data = selected_data,\n",
    "                                                           num_sec = number_sections,\n",
    "                                                           signals = sig_names)\n",
    "\n",
    "            # string to write data of the current data point to the csv-file\n",
    "            data_point_string = ex + ';' # first column contains the label\n",
    "\n",
    "            # copy section mean values to string\n",
    "            for sig in sig_names:\n",
    "                for jj in [0,1,2]: # x, y, z comp. of the corresponding signal\n",
    "                    for ll in range(number_sections):\n",
    "\n",
    "                        # append to string for writing to csv file (5 decimals)\n",
    "                        data_point_string += \"{:.5f};\".format(section_means[sig][ll,jj])\n",
    "\n",
    "            # remove last separator (;)\n",
    "            idx_last_sep = data_point_string.rfind(\";\")\n",
    "            data_point_string =  data_point_string[:idx_last_sep]\n",
    "\n",
    "            # append values of current data point to file\n",
    "            with open(feature_csv_file, 'a') as feature_file:\n",
    "                feature_file.writelines(data_point_string + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 15,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "## Load the generated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:08:51.505381Z",
     "start_time": "2018-12-17T22:08:50.772339Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 12,
        "hidden": false,
        "row": 17,
        "width": 4
       },
       "report_default": {}
      }
     }
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6120 entries, 0 to 6119\n",
      "Data columns (total 61 columns):\n",
      "label       6120 non-null object\n",
      "Acc_x_01    6120 non-null float64\n",
      "Acc_x_02    6120 non-null float64\n",
      "Acc_x_03    6120 non-null float64\n",
      "Acc_x_04    6120 non-null float64\n",
      "Acc_x_05    6120 non-null float64\n",
      "Acc_x_06    6120 non-null float64\n",
      "Acc_x_07    6120 non-null float64\n",
      "Acc_x_08    6120 non-null float64\n",
      "Acc_x_09    6120 non-null float64\n",
      "Acc_x_10    6120 non-null float64\n",
      "Acc_y_01    6120 non-null float64\n",
      "Acc_y_02    6120 non-null float64\n",
      "Acc_y_03    6120 non-null float64\n",
      "Acc_y_04    6120 non-null float64\n",
      "Acc_y_05    6120 non-null float64\n",
      "Acc_y_06    6120 non-null float64\n",
      "Acc_y_07    6120 non-null float64\n",
      "Acc_y_08    6120 non-null float64\n",
      "Acc_y_09    6120 non-null float64\n",
      "Acc_y_10    6120 non-null float64\n",
      "Acc_z_01    6120 non-null float64\n",
      "Acc_z_02    6120 non-null float64\n",
      "Acc_z_03    6120 non-null float64\n",
      "Acc_z_04    6120 non-null float64\n",
      "Acc_z_05    6120 non-null float64\n",
      "Acc_z_06    6120 non-null float64\n",
      "Acc_z_07    6120 non-null float64\n",
      "Acc_z_08    6120 non-null float64\n",
      "Acc_z_09    6120 non-null float64\n",
      "Acc_z_10    6120 non-null float64\n",
      "Gyr_x_01    6120 non-null float64\n",
      "Gyr_x_02    6120 non-null float64\n",
      "Gyr_x_03    6120 non-null float64\n",
      "Gyr_x_04    6120 non-null float64\n",
      "Gyr_x_05    6120 non-null float64\n",
      "Gyr_x_06    6120 non-null float64\n",
      "Gyr_x_07    6120 non-null float64\n",
      "Gyr_x_08    6120 non-null float64\n",
      "Gyr_x_09    6120 non-null float64\n",
      "Gyr_x_10    6120 non-null float64\n",
      "Gyr_y_01    6120 non-null float64\n",
      "Gyr_y_02    6120 non-null float64\n",
      "Gyr_y_03    6120 non-null float64\n",
      "Gyr_y_04    6120 non-null float64\n",
      "Gyr_y_05    6120 non-null float64\n",
      "Gyr_y_06    6120 non-null float64\n",
      "Gyr_y_07    6120 non-null float64\n",
      "Gyr_y_08    6120 non-null float64\n",
      "Gyr_y_09    6120 non-null float64\n",
      "Gyr_y_10    6120 non-null float64\n",
      "Gyr_z_01    6120 non-null float64\n",
      "Gyr_z_02    6120 non-null float64\n",
      "Gyr_z_03    6120 non-null float64\n",
      "Gyr_z_04    6120 non-null float64\n",
      "Gyr_z_05    6120 non-null float64\n",
      "Gyr_z_06    6120 non-null float64\n",
      "Gyr_z_07    6120 non-null float64\n",
      "Gyr_z_08    6120 non-null float64\n",
      "Gyr_z_09    6120 non-null float64\n",
      "Gyr_z_10    6120 non-null float64\n",
      "dtypes: float64(60), object(1)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "feature_train_data = pd.read_csv(feature_csv_file, skiprows=0, sep=';')\n",
    "feature_train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:08:51.596386Z",
     "start_time": "2018-12-17T22:08:51.560384Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 8,
        "hidden": false,
        "row": 29,
        "width": 12
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Acc_x_01</th>\n",
       "      <th>Acc_x_02</th>\n",
       "      <th>Acc_x_03</th>\n",
       "      <th>Acc_x_04</th>\n",
       "      <th>Acc_x_05</th>\n",
       "      <th>Acc_x_06</th>\n",
       "      <th>Acc_x_07</th>\n",
       "      <th>Acc_x_08</th>\n",
       "      <th>Acc_x_09</th>\n",
       "      <th>...</th>\n",
       "      <th>Gyr_z_01</th>\n",
       "      <th>Gyr_z_02</th>\n",
       "      <th>Gyr_z_03</th>\n",
       "      <th>Gyr_z_04</th>\n",
       "      <th>Gyr_z_05</th>\n",
       "      <th>Gyr_z_06</th>\n",
       "      <th>Gyr_z_07</th>\n",
       "      <th>Gyr_z_08</th>\n",
       "      <th>Gyr_z_09</th>\n",
       "      <th>Gyr_z_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>-0.94862</td>\n",
       "      <td>-0.96133</td>\n",
       "      <td>-0.39374</td>\n",
       "      <td>0.35776</td>\n",
       "      <td>0.44864</td>\n",
       "      <td>0.05871</td>\n",
       "      <td>-0.50909</td>\n",
       "      <td>-0.86553</td>\n",
       "      <td>-0.91736</td>\n",
       "      <td>...</td>\n",
       "      <td>33.96461</td>\n",
       "      <td>119.09226</td>\n",
       "      <td>134.11672</td>\n",
       "      <td>45.16518</td>\n",
       "      <td>-20.69654</td>\n",
       "      <td>-83.85617</td>\n",
       "      <td>-101.04688</td>\n",
       "      <td>-79.37651</td>\n",
       "      <td>-28.57366</td>\n",
       "      <td>1.50226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>-0.91875</td>\n",
       "      <td>-0.90737</td>\n",
       "      <td>-0.56951</td>\n",
       "      <td>0.10319</td>\n",
       "      <td>0.40801</td>\n",
       "      <td>0.21426</td>\n",
       "      <td>-0.33080</td>\n",
       "      <td>-0.83806</td>\n",
       "      <td>-0.93589</td>\n",
       "      <td>...</td>\n",
       "      <td>21.89922</td>\n",
       "      <td>90.21641</td>\n",
       "      <td>118.35156</td>\n",
       "      <td>74.62266</td>\n",
       "      <td>-0.48750</td>\n",
       "      <td>-49.51187</td>\n",
       "      <td>-109.20234</td>\n",
       "      <td>-101.00547</td>\n",
       "      <td>-50.23281</td>\n",
       "      <td>-6.03594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>-0.93875</td>\n",
       "      <td>-0.93639</td>\n",
       "      <td>-0.60812</td>\n",
       "      <td>0.12386</td>\n",
       "      <td>0.46588</td>\n",
       "      <td>0.39421</td>\n",
       "      <td>-0.02835</td>\n",
       "      <td>-0.61382</td>\n",
       "      <td>-0.91854</td>\n",
       "      <td>...</td>\n",
       "      <td>15.96221</td>\n",
       "      <td>83.73110</td>\n",
       "      <td>123.72845</td>\n",
       "      <td>78.51526</td>\n",
       "      <td>9.25073</td>\n",
       "      <td>-30.06541</td>\n",
       "      <td>-83.66424</td>\n",
       "      <td>-102.55460</td>\n",
       "      <td>-72.67878</td>\n",
       "      <td>-8.51526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>-0.91961</td>\n",
       "      <td>-0.87408</td>\n",
       "      <td>-0.46247</td>\n",
       "      <td>0.17987</td>\n",
       "      <td>0.45833</td>\n",
       "      <td>0.28772</td>\n",
       "      <td>-0.27465</td>\n",
       "      <td>-0.78274</td>\n",
       "      <td>-0.88386</td>\n",
       "      <td>...</td>\n",
       "      <td>30.38491</td>\n",
       "      <td>94.18287</td>\n",
       "      <td>116.64787</td>\n",
       "      <td>70.11052</td>\n",
       "      <td>2.69985</td>\n",
       "      <td>-46.96799</td>\n",
       "      <td>-106.49924</td>\n",
       "      <td>-99.39024</td>\n",
       "      <td>-43.10108</td>\n",
       "      <td>-3.91768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF</td>\n",
       "      <td>-0.89435</td>\n",
       "      <td>-0.92486</td>\n",
       "      <td>-0.64687</td>\n",
       "      <td>0.03317</td>\n",
       "      <td>0.46411</td>\n",
       "      <td>0.44731</td>\n",
       "      <td>0.05423</td>\n",
       "      <td>-0.60571</td>\n",
       "      <td>-0.92647</td>\n",
       "      <td>...</td>\n",
       "      <td>13.04983</td>\n",
       "      <td>87.60167</td>\n",
       "      <td>130.50169</td>\n",
       "      <td>99.33333</td>\n",
       "      <td>20.78632</td>\n",
       "      <td>-28.67314</td>\n",
       "      <td>-86.20250</td>\n",
       "      <td>-126.16892</td>\n",
       "      <td>-94.74250</td>\n",
       "      <td>-11.61824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  Acc_x_01  Acc_x_02  Acc_x_03  Acc_x_04  Acc_x_05  Acc_x_06  Acc_x_07  \\\n",
       "0    RF  -0.94862  -0.96133  -0.39374   0.35776   0.44864   0.05871  -0.50909   \n",
       "1    RF  -0.91875  -0.90737  -0.56951   0.10319   0.40801   0.21426  -0.33080   \n",
       "2    RF  -0.93875  -0.93639  -0.60812   0.12386   0.46588   0.39421  -0.02835   \n",
       "3    RF  -0.91961  -0.87408  -0.46247   0.17987   0.45833   0.28772  -0.27465   \n",
       "4    RF  -0.89435  -0.92486  -0.64687   0.03317   0.46411   0.44731   0.05423   \n",
       "\n",
       "   Acc_x_08  Acc_x_09    ...     Gyr_z_01   Gyr_z_02   Gyr_z_03  Gyr_z_04  \\\n",
       "0  -0.86553  -0.91736    ...     33.96461  119.09226  134.11672  45.16518   \n",
       "1  -0.83806  -0.93589    ...     21.89922   90.21641  118.35156  74.62266   \n",
       "2  -0.61382  -0.91854    ...     15.96221   83.73110  123.72845  78.51526   \n",
       "3  -0.78274  -0.88386    ...     30.38491   94.18287  116.64787  70.11052   \n",
       "4  -0.60571  -0.92647    ...     13.04983   87.60167  130.50169  99.33333   \n",
       "\n",
       "   Gyr_z_05  Gyr_z_06   Gyr_z_07   Gyr_z_08  Gyr_z_09  Gyr_z_10  \n",
       "0 -20.69654 -83.85617 -101.04688  -79.37651 -28.57366   1.50226  \n",
       "1  -0.48750 -49.51187 -109.20234 -101.00547 -50.23281  -6.03594  \n",
       "2   9.25073 -30.06541  -83.66424 -102.55460 -72.67878  -8.51526  \n",
       "3   2.69985 -46.96799 -106.49924  -99.39024 -43.10108  -3.91768  \n",
       "4  20.78632 -28.67314  -86.20250 -126.16892 -94.74250 -11.61824  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 19,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "### Generate feature matrix of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:08:51.802398Z",
     "start_time": "2018-12-17T22:08:51.652390Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 19,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6120, 60)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get feature matrix\n",
    "X_train = feature_train_data.values[:,1:]\n",
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T12:25:41.106965Z",
     "start_time": "2018-12-10T12:25:41.100965Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 23,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "### Generate label array of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:08:51.986409Z",
     "start_time": "2018-12-17T22:08:51.858401Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 23,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6120,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dictionary for labels\n",
    "label_ex = {'RF':0,\n",
    "            'RO':1,\n",
    "            'RS':2,\n",
    "            'LR':3,\n",
    "            'BC':4,\n",
    "            'TC':5,\n",
    "            'MP':6,\n",
    "            'SA':7,\n",
    "            'P1':8,\n",
    "            'P2':9,\n",
    "            'NE':10}\n",
    "\n",
    "# get label array with labels (0 ... 10)\n",
    "labels_str = feature_train_data.values[:,0]\n",
    "y_train = [label_ex[labels_str[ii]] for ii in range(len(feature_train_data.values[:,0]))]\n",
    "np.shape(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 37,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "## Training of ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:08:52.077414Z",
     "start_time": "2018-12-17T22:08:52.046412Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 37,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "***Voting Classifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:08:52.250424Z",
     "start_time": "2018-12-17T22:08:52.130417Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#LogReg_clf = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, n_jobs=-1, random_state=42)\n",
    "#RF_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=40, n_jobs=-1, random_state=42)\n",
    "\n",
    "#voting_clf = VotingClassifier(estimators=[('lr', LogReg_clf), ('rf', RF_clf)], voting='soft')\n",
    "#voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 37,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "***Random Forest Classifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:08:57.703736Z",
     "start_time": "2018-12-17T22:08:52.304427Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 8,
        "hidden": false,
        "row": 41,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=50,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=-1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create random forest classifier model\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=50, n_jobs=-1, random_state=42)\n",
    "\n",
    "# train the model\n",
    "rnd_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 41,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "## Test Data\n",
    "\n",
    "Loading all sensor data from the test subject,\n",
    "without knowing the start and stop times of the exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:08:59.508839Z",
     "start_time": "2018-12-17T22:08:57.764739Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# select file (csv) of test subject\n",
    "file_dir  = r'E:\\Physio_Data\\Subject_{:02}'.format(test_data_subject)\n",
    "file_name = 'subject{:02}.csv'.format(test_data_subject)\n",
    "data_path = os.path.join(file_dir, file_name)\n",
    "\n",
    "# the following (commented) lines are only necessary, if we want to load a certain time range\n",
    "## selecet time range [min:sec]\n",
    "#start_min_sec = '01:36.0' # Raises Oblique\n",
    "#stop_min_sec  = '02:00.3'\n",
    "## split time string and convert to float\n",
    "#start_min = float(start_min_sec.split(':')[0])\n",
    "#start_sec = float(start_min_sec.split(':')[1])\n",
    "#stop_min = float(stop_min_sec.split(':')[0])\n",
    "#stop_sec = float(stop_min_sec.split(':')[1])\n",
    "## start and stop time in seconds\n",
    "#start_time = start_min*60 + start_sec # [s]\n",
    "#stop_time = stop_min*60 + stop_sec # [s]\n",
    "\n",
    "# we load all data, hence we set start_time and stop_time None\n",
    "start_time = None\n",
    "stop_time = None\n",
    "\n",
    "# get data from selected file\n",
    "sensor_data = fmpm.get_sensor_data(in_file=data_path,\n",
    "                                   sampling_rate=sampling_rate,\n",
    "                                   start_time=start_time,\n",
    "                                   stop_time=stop_time)\n",
    "\n",
    "\n",
    "# filtering the data (but not necessary, because filtered data are not used so far)\n",
    "\n",
    "# filter properties\n",
    "cutoff = 10 # [Hz]\n",
    "order = 6 # butterworth order\n",
    "\n",
    "# filter data with butterworth filter and save to new dictionary\n",
    "signal_keys = ['Acc', 'Gyr']\n",
    "sensor_data_filt = {}\n",
    "for signal in signal_keys:\n",
    "    sensor_data_filt[signal] = fmpm.butter_lowpass_filter(sensor_data[signal], \n",
    "                                                          cutoff=cutoff, \n",
    "                                                          fs=sampling_rate, \n",
    "                                                          order=order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T13:33:05.585296Z",
     "start_time": "2018-12-10T13:33:05.580296Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 11,
        "hidden": false,
        "row": 49,
        "width": 12
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "## Windowing the test data\n",
    "\n",
    "The windowing follows a certain procedure:\n",
    "\n",
    ">•\tTaking a 1 s block of the data\n",
    "\n",
    ">•\tVarying the block length from 1 s to 5 s with an increment of 200 ms (starting point remains the same for all blocks)\n",
    "\n",
    ">•\tSectioning and feature generation for all blocks\n",
    "\n",
    ">•\tFor each block class probabilities are calculated (ML classifier) \n",
    "\n",
    ">•\tSliding the starting point with an increment of 200 ms and starting again with a 1 s block varying to 5 s\n",
    "\n",
    "*see animation below*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:08:59.569842Z",
     "start_time": "2018-12-17T22:08:59.561842Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 9,
        "hidden": false,
        "row": 60,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"windowing_procedure.gif\" width=600 >"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<img src=\"windowing_procedure.gif\" width=600 >')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:08:59.779854Z",
     "start_time": "2018-12-17T22:08:59.625846Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# commented parameters are already defined\n",
    "\n",
    "## sampling rate of the signals\n",
    "#sampling_rate = 256 # [Hz]\n",
    "\n",
    "## signal names\n",
    "#sig_names= ['Acc','Gyr']\n",
    "\n",
    "## number of sections to split the signal\n",
    "#number_sections = 10\n",
    "\n",
    "## abbreviations for exercises / non-exercise\n",
    "#exercise_abbrs = ['RF','RO','RS','LR','BC','TC','MP','SA','P1','P2','NE']\n",
    "\n",
    "\n",
    "# window start increment\n",
    "win_start_inc = 0.2 # [s]\n",
    "\n",
    "# window stretch increment\n",
    "win_stretch_inc = 0.2 # [s]\n",
    "\n",
    "# minimum window length\n",
    "win_min_len = 1 # [s]\n",
    "\n",
    "# maximim window length\n",
    "win_max_len = 5 # [s]\n",
    "\n",
    "# signal length (all sensor data must have same length --> Acc, Gyr, ...)\n",
    "signal_len = len(sensor_data[sig_names[0]])\n",
    "\n",
    "# window start time\n",
    "win_start = 0 # [s]\n",
    "\n",
    "# last window start time --> time where the minimum window length just fits into the sensor data\n",
    "win_last_start = signal_len/sampling_rate - win_min_len\n",
    "\n",
    "# number of different window sizes\n",
    "num_win_sizes = len(np.arange(win_min_len, win_max_len+win_stretch_inc, win_stretch_inc))\n",
    "\n",
    "# number of different window start points\n",
    "num_start_points = len(np.arange(win_start, win_last_start, win_start_inc))\n",
    "\n",
    "# dictionary with matrices to save predicted values for all classes\n",
    "pred_matrix = {}\n",
    "for ex in exercise_abbrs:\n",
    "    pred_matrix[ex] = np.zeros([num_start_points, num_win_sizes])\n",
    "\n",
    "# matrix with all generated features\n",
    "feature_map = np.zeros([num_start_points * num_win_sizes, number_sections*6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:08:59.918862Z",
     "start_time": "2018-12-17T22:08:59.833858Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    " def print_progress(current_num, max_num, prev_prog):\n",
    "    '''\n",
    "    Function to print progress [%] in a loop.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    current_num : int\n",
    "        Number of the current run in a loop.\n",
    "        \n",
    "    max_num : int\n",
    "        Maximum number of runs in a loop.\n",
    "        \n",
    "    prev_prog : int\n",
    "        Previous progress, to print only if necessary.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        Previous progress, important for next run.\n",
    "    '''\n",
    "    new_prog = int(current_num/max_num*100)\n",
    "    \n",
    "    if new_prog > prev_prog:\n",
    "        clear_output(wait=True)\n",
    "        print('Progress: {:3d}%'.format(new_prog))\n",
    "        \n",
    "    return new_prog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 41,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "### Generating the feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:09:00.070871Z",
     "start_time": "2018-12-17T22:08:59.973866Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# first let's check if the feature map already exists\n",
    "feature_map_dir  = 'E:\\Physio_Features'\n",
    "feature_map_name = 'feature_map_subject{0:02}_sections{1:02}.csv'.format(\n",
    "                    test_data_subject, number_sections)\n",
    "feature_map_path = os.path.join(feature_map_dir, feature_map_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 9,
        "height": 4,
        "hidden": false,
        "row": 4,
        "width": null
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "***Feature map is only generated if it does not already exist $\\rightarrow$ otherwise it is loaded***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:09:20.263026Z",
     "start_time": "2018-12-17T22:09:00.124874Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 45,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature map loaded.\n",
      "\n",
      "Shape:\n",
      "(210945, 60)\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "max_count = len(feature_map)\n",
    "prev_progress = 0 # previous progress\n",
    "\n",
    "# only generate the feature map if it does not already exist\n",
    "if not os.path.isfile(feature_map_path):\n",
    "\n",
    "    # going through all window start points\n",
    "    for ii, win_pos in enumerate(np.arange(win_start, win_last_start, win_start_inc)):\n",
    "\n",
    "        # going through all window lengths  (+win_stretch_inc to include end point)\n",
    "        for jj, win_len in enumerate(np.arange(win_min_len, win_max_len+win_stretch_inc, win_stretch_inc)):\n",
    "\n",
    "            # call fun function to get the corresponding indices of the selected range \n",
    "            [idx_start, idx_stop] = fmpm.get_window_indices(signal_len, \n",
    "                                                            window_length = win_len, \n",
    "                                                            start_time = win_pos,\n",
    "                                                            sampling_rate = sampling_rate, \n",
    "                                                            auto_end = True)\n",
    "\n",
    "            # call fun function to split the selected range into sections\n",
    "            section_means = fmpm.split_range_into_sections(sensor_data, \n",
    "                                                           num_sec = number_sections, \n",
    "                                                           signals = sig_names, \n",
    "                                                           start_index = idx_start, \n",
    "                                                           stop_index = idx_stop)\n",
    "\n",
    "            # putting together the feature map\n",
    "            feature_map[count,:] = np.concatenate((section_means[sig_names[0]].transpose(), \n",
    "                                                   section_means[sig_names[1]].transpose())).flatten().reshape(1, -1)\n",
    "\n",
    "            count += 1\n",
    "\n",
    "        prev_progress = print_progress(count, max_count, prev_progress)\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print('Saving the feature map...')\n",
    "    \n",
    "    # save feature map of test subject\n",
    "    np.savetxt(feature_map_path, feature_map, delimiter=\";\")\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print('Feature map saved.')\n",
    "    \n",
    "    print('\\nShape:')\n",
    "    print(np.shape(feature_map))\n",
    "    \n",
    "# else --> feature map already exists --> load it\n",
    "else:\n",
    "    print('Loading the feature map...')\n",
    "    \n",
    "    feature_map = np.loadtxt(open(feature_map_path), delimiter=\";\")\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print('Feature map loaded.')\n",
    "    \n",
    "    print('\\nShape:')\n",
    "    print(np.shape(feature_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 45,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "### Making predictions with the trained ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:09:33.789800Z",
     "start_time": "2018-12-17T22:09:20.322029Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 60,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210945, 11)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pred_probs = voting_clf.predict_proba(feature_map)\n",
    "pred_probs = rnd_clf.predict_proba(feature_map)\n",
    "np.shape(pred_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 60,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "### Filling the prediction matrices (images) with probability values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:09:36.852975Z",
     "start_time": "2018-12-17T22:09:33.843803Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 64,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 100%\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "max_count = len(feature_map)\n",
    "prev_progress = 0 # previous progress\n",
    "\n",
    "# going through all window start points\n",
    "for ii, win_pos in enumerate(np.arange(win_start, win_last_start, win_start_inc)):\n",
    "    # going through all window lengths  (+win_stretch_inc to include end point)\n",
    "    for jj, win_len in enumerate(np.arange(win_min_len, win_max_len+win_stretch_inc, win_stretch_inc)):\n",
    "        \n",
    "        for kk, ex in enumerate(exercise_abbrs):\n",
    "            pred_matrix[ex][ii,jj] = pred_probs[count][kk]\n",
    "            \n",
    "        count += 1\n",
    "        prev_progress = print_progress(count, max_count, prev_progress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find peaks of prediction matrices and evaluate them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:09:36.915979Z",
     "start_time": "2018-12-17T22:09:36.907978Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage.filters import maximum_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:09:37.081988Z",
     "start_time": "2018-12-17T22:09:36.971982Z"
    }
   },
   "outputs": [],
   "source": [
    "def detect_prob_map_peaks(prob_map):\n",
    "    '''\n",
    "    Function to detect the local peaks of a probability map.\n",
    "    !! Global variables are used !!\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    prob_map : 2d-array\n",
    "        Matrix with predicted probabilities.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    array \n",
    "        array[0] ... peak time indices\n",
    "        array[1] ... peak window length indices\n",
    "        e.g. ([[ 390, 723, 1331, ...], [4, 4, 10, ...]], dtype=int64)\n",
    "    '''\n",
    "    \n",
    "    # find only peaks with a minimum probability (threshold)\n",
    "    threshold_prob = 0.5\n",
    "    \n",
    "    # length and height of the footprint for the maximum_filter (see below)\n",
    "    footprint_length = 1 # [s]\n",
    "    footprint_length_indices = int(footprint_length / win_start_inc)\n",
    "    footprint_height = num_win_sizes * 2  # take number of all window sizes for footprint\n",
    "    \n",
    "    footprint=np.ones((footprint_length_indices,footprint_height))\n",
    "    \n",
    "    # applying a maximum filter and generating a boolean map for local maxima\n",
    "    local_max = maximum_filter(prob_map, footprint=footprint)==prob_map\n",
    "    \n",
    "    # removing all maxima below the threshold\n",
    "    local_max = (prob_map>=threshold_prob) & local_max\n",
    "    \n",
    "    # check if there are several points with the same probability at one local maxima\n",
    "    #   --> remove them, otherwise we get more than one local maxima\n",
    "    peak_indices_check = np.argwhere(local_max)\n",
    "    if len(peak_indices_check) > 1:\n",
    "        for ii in range(len(peak_indices_check)-1):\n",
    "            row_ind, col_ind = peak_indices_check[ii]\n",
    "            row_ind_next, col_ind_next = peak_indices_check[ii+1]\n",
    "            if prob_map[row_ind,col_ind] == prob_map[row_ind_next,col_ind_next] and \\\n",
    "            row_ind_next-row_ind < footprint_length_indices:\n",
    "                local_max[row_ind,col_ind] = False\n",
    "    \n",
    "    # get the maxima indices of the probability map\n",
    "    peak_indices = np.argwhere(local_max).transpose()\n",
    "    \n",
    "    return peak_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:09:37.466010Z",
     "start_time": "2018-12-17T22:09:37.135991Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_peaks(peak_ind, pred_matrix):\n",
    "    '''\n",
    "    Function to evaluate the detected peaks.\n",
    "    (see function detect_prob_map_peaks(prob_map))\n",
    "    !! Global variables are used !!\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    peak_ind : 2d-array \n",
    "        array[0] ... peak time indices\n",
    "        array[1] ... peak window length indices\n",
    "        e.g. ([[ 390, 723, 1331, ...], [4, 4, 10, ...]], dtype=int64)\n",
    "        \n",
    "    pred_matrix : 2d-array\n",
    "        Matrix with predicted probabilities.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary with exercise abbreviations as keys --> repetition blocks\n",
    "    '''\n",
    "    \n",
    "    # define the maximum time between two peaks in a block\n",
    "    max_time_between_peaks = 10 # [s]\n",
    "    max_ind_between_peaks = int(max_time_between_peaks / win_start_inc)\n",
    "    \n",
    "    exercise_only_abbrs = [*peak_ind]\n",
    "    \n",
    "    # assign peaks to repetition blocks with min two repetitions (check previous and next peak distance)\n",
    "    rep_blocks = {}\n",
    "    for ii, ex in enumerate(exercise_only_abbrs):\n",
    "        rep_blocks[ex] = []\n",
    "        current_block = []\n",
    "        first_of_block = True # remember if current peak is the first of the current block\n",
    "        \n",
    "        # going through all peaks of the current exercise if there are minimum two peaks\n",
    "        if len(peak_ind[ex][0]) >= 2:\n",
    "            for jj in range(len(peak_ind[ex][0])-1):\n",
    "                \n",
    "                # time index of the current peak\n",
    "                time_index = peak_ind[ex][0][jj]\n",
    "                \n",
    "                # time index of the next peak\n",
    "                next_time_index = peak_ind[ex][0][jj+1]\n",
    "\n",
    "                # looking for first peak of current block\n",
    "                if first_of_block is True: # omit the lst one --> no block possible\n",
    "                    next_time_index = peak_ind[ex][0][jj+1]\n",
    "                    if next_time_index-time_index <= max_ind_between_peaks:\n",
    "                        current_block.append([peak_ind[ex][0][jj], peak_ind[ex][1][jj]]) # add the current peak\n",
    "                        current_block.append([peak_ind[ex][0][jj+1], peak_ind[ex][1][jj+1]]) # and the next peak\n",
    "                        first_of_block = False\n",
    "\n",
    "                # first peak of current block already found\n",
    "                elif first_of_block is False:\n",
    "                    if next_time_index-time_index <= max_ind_between_peaks:\n",
    "                        current_block.append([peak_ind[ex][0][jj+1], peak_ind[ex][1][jj+1]]) # add the next peak\n",
    "                    else:\n",
    "                        first_of_block = True\n",
    "                        rep_blocks[ex].append(current_block)\n",
    "                        current_block = []\n",
    "\n",
    "            # one additional time at the end of the loop if something is stored in the current block\n",
    "            if first_of_block is False:\n",
    "                rep_blocks[ex].append(current_block)\n",
    "    \n",
    "    \n",
    "    # if blocks are overlapping --> keep only the block with the highest predicted probabilities (sum)\n",
    "    #    --> the more peaks in the block, the higher the sum of probabilities\n",
    "    blocks_to_remove = []\n",
    "\n",
    "    for ex1, ex2 in itertools.combinations(exercise_only_abbrs, 2):\n",
    "        for ii in range(len(rep_blocks[ex1])):\n",
    "            for jj in range(len(rep_blocks[ex2])):\n",
    "                start_1 = rep_blocks[ex1][ii][0][0] # time index of the first peak in the current block 1\n",
    "                stop_1 = rep_blocks[ex1][ii][-1][0] # time index of the last peak in the current block 1\n",
    "                start_2 = rep_blocks[ex2][jj][0][0] # time index of the first peak in the current block 2\n",
    "                stop_2 = rep_blocks[ex2][jj][-1][0] # time index of the last peak in the current block 2\n",
    "\n",
    "                # check if the two blocks overlap\n",
    "                if (start_1 >= start_2 and start_1 <= stop_2) or (stop_1 >= start_2 and stop_1 <= stop_2) \\\n",
    "                or (start_2 >= start_1 and start_2 <= stop_1) or (stop_2 >= start_1 and stop_2 <= stop_1):\n",
    "\n",
    "                    # selecet the corresponding probability values of pred_matrix and sum them up\n",
    "                    sum_prob_block_1 = pred_matrix[ex1][np.array(rep_blocks[ex1][ii])[:,0], \n",
    "                                                        np.array(rep_blocks[ex1][ii])[:,1]].sum()\n",
    "\n",
    "                    sum_prob_block_2 = pred_matrix[ex2][np.array(rep_blocks[ex2][jj])[:,0], \n",
    "                                                        np.array(rep_blocks[ex2][jj])[:,1]].sum()\n",
    "\n",
    "                    # compare the sum of the probabilities of the two blocks\n",
    "                    if sum_prob_block_1 < sum_prob_block_2:\n",
    "                        blocks_to_remove.append([ex1, ii])\n",
    "                    else:\n",
    "                        blocks_to_remove.append([ex2, jj])\n",
    "    \n",
    "    # ensure that there are no duplicates in the nested list\n",
    "    blocks_to_remove_unique = []\n",
    "    for sublist in blocks_to_remove:\n",
    "        if sublist not in blocks_to_remove_unique:\n",
    "            blocks_to_remove_unique.append(sublist)\n",
    "    \n",
    "    # by removing the blocks take the reversed sorted order of the block index\n",
    "    #    --> so it is possible to remove all block without \"refreshing\" the indices\n",
    "    #        (if one block is removed, higher indices of all other blocks are changing)\n",
    "    for ex, block_ind in sorted(blocks_to_remove_unique, key=lambda x: x[1])[::-1]:\n",
    "        rep_blocks[ex].pop(block_ind)\n",
    "        \n",
    "    return rep_blocks\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:09:37.665021Z",
     "start_time": "2018-12-17T22:09:37.520013Z"
    }
   },
   "outputs": [],
   "source": [
    "# function to convert indices to time strings\n",
    "def indices_to_time(start_index, stop_index):\n",
    "    '''\n",
    "    Function convert indices to time string.\n",
    "    !! Global variables are used !!\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    start_index : int\n",
    "        \n",
    "    stop_index : int\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        String with start and stop time (e.g. '14:39.6 - 15:19.4').\n",
    "    '''\n",
    "    start_time_text = '{0:02}:{1:04.1f}'.format(int(start_index*win_start_inc/60), \n",
    "                                               (start_index*win_start_inc)%60)\n",
    "    stop_time_text = '{0:02}:{1:04.1f}'.format(int(stop_index*win_start_inc/60), \n",
    "                                               (stop_index*win_start_inc)%60)\n",
    "    return start_time_text + ' - ' + stop_time_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:09:37.826031Z",
     "start_time": "2018-12-17T22:09:37.722025Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_rep_blocks(rep_blocks):\n",
    "    '''\n",
    "    Function to print progress [%] in a loop.\n",
    "    !! Global variables are used !!\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rep_blocks : dict\n",
    "        Dictionary with nested list of repetition blocks.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    no returns\n",
    "    '''\n",
    "    exercise_only_abbrs = ['RF','RO','RS','LR','BC','TC','MP','SA','P1','P2']\n",
    "    \n",
    "    for ex in exercise_only_abbrs:\n",
    "        print('\\nExercise: ' + ex)\n",
    "        print('Number of blocks: {}\\n'.format(len(rep_blocks[ex])))\n",
    "        for block_num in range(len(rep_blocks[ex])):\n",
    "            print('\\tBlock #{}:'.format(block_num+1))\n",
    "            print('\\t\\tRepetitions: {}'.format(np.shape(np.array(rep_blocks[ex][block_num]))[0]))\n",
    "            start_index = rep_blocks[ex][block_num][0][0]\n",
    "            stop_index = rep_blocks[ex][block_num][-1][0]\n",
    "            # for the stop index we have to consider the length of the last repetition\n",
    "            stop_index += int((rep_blocks[ex][block_num][-1][1]*win_stretch_inc + win_min_len) / win_start_inc)\n",
    "            print('\\t\\tTime range: ' + indices_to_time(start_index, stop_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:09:38.160050Z",
     "start_time": "2018-12-17T22:09:37.883034Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exercise: RF\n",
      "Number of blocks: 3\n",
      "\n",
      "\tBlock #1:\n",
      "\t\tRepetitions: 10\n",
      "\t\tTime range: 13:43.8 - 14:13.6\n",
      "\tBlock #2:\n",
      "\t\tRepetitions: 15\n",
      "\t\tTime range: 14:39.6 - 15:19.4\n",
      "\tBlock #3:\n",
      "\t\tRepetitions: 5\n",
      "\t\tTime range: 16:08.2 - 16:22.6\n",
      "\n",
      "Exercise: RO\n",
      "Number of blocks: 3\n",
      "\n",
      "\tBlock #1:\n",
      "\t\tRepetitions: 15\n",
      "\t\tTime range: 01:17.4 - 01:57.0\n",
      "\tBlock #2:\n",
      "\t\tRepetitions: 5\n",
      "\t\tTime range: 02:20.8 - 02:36.2\n",
      "\tBlock #3:\n",
      "\t\tRepetitions: 10\n",
      "\t\tTime range: 02:54.0 - 03:22.4\n",
      "\n",
      "Exercise: RS\n",
      "Number of blocks: 3\n",
      "\n",
      "\tBlock #1:\n",
      "\t\tRepetitions: 15\n",
      "\t\tTime range: 20:12.2 - 20:59.4\n",
      "\tBlock #2:\n",
      "\t\tRepetitions: 5\n",
      "\t\tTime range: 21:24.0 - 21:39.6\n",
      "\tBlock #3:\n",
      "\t\tRepetitions: 10\n",
      "\t\tTime range: 22:08.8 - 22:37.4\n",
      "\n",
      "Exercise: LR\n",
      "Number of blocks: 3\n",
      "\n",
      "\tBlock #1:\n",
      "\t\tRepetitions: 5\n",
      "\t\tTime range: 10:42.4 - 10:56.0\n",
      "\tBlock #2:\n",
      "\t\tRepetitions: 10\n",
      "\t\tTime range: 11:24.4 - 11:51.0\n",
      "\tBlock #3:\n",
      "\t\tRepetitions: 15\n",
      "\t\tTime range: 12:11.2 - 12:51.4\n",
      "\n",
      "Exercise: BC\n",
      "Number of blocks: 3\n",
      "\n",
      "\tBlock #1:\n",
      "\t\tRepetitions: 15\n",
      "\t\tTime range: 16:49.8 - 17:29.2\n",
      "\tBlock #2:\n",
      "\t\tRepetitions: 11\n",
      "\t\tTime range: 18:00.6 - 18:31.4\n",
      "\tBlock #3:\n",
      "\t\tRepetitions: 5\n",
      "\t\tTime range: 18:58.0 - 19:11.2\n",
      "\n",
      "Exercise: TC\n",
      "Number of blocks: 3\n",
      "\n",
      "\tBlock #1:\n",
      "\t\tRepetitions: 15\n",
      "\t\tTime range: 07:31.2 - 08:14.2\n",
      "\tBlock #2:\n",
      "\t\tRepetitions: 5\n",
      "\t\tTime range: 08:48.6 - 09:03.6\n",
      "\tBlock #3:\n",
      "\t\tRepetitions: 10\n",
      "\t\tTime range: 09:45.0 - 10:11.8\n",
      "\n",
      "Exercise: MP\n",
      "Number of blocks: 3\n",
      "\n",
      "\tBlock #1:\n",
      "\t\tRepetitions: 45\n",
      "\t\tTime range: 29:39.0 - 30:36.0\n",
      "\tBlock #2:\n",
      "\t\tRepetitions: 26\n",
      "\t\tTime range: 31:12.0 - 31:46.6\n",
      "\tBlock #3:\n",
      "\t\tRepetitions: 14\n",
      "\t\tTime range: 32:09.8 - 32:27.6\n",
      "\n",
      "Exercise: SA\n",
      "Number of blocks: 3\n",
      "\n",
      "\tBlock #1:\n",
      "\t\tRepetitions: 5\n",
      "\t\tTime range: 26:47.6 - 27:04.0\n",
      "\tBlock #2:\n",
      "\t\tRepetitions: 16\n",
      "\t\tTime range: 27:24.4 - 28:15.6\n",
      "\tBlock #3:\n",
      "\t\tRepetitions: 10\n",
      "\t\tTime range: 28:40.2 - 29:09.8\n",
      "\n",
      "Exercise: P1\n",
      "Number of blocks: 3\n",
      "\n",
      "\tBlock #1:\n",
      "\t\tRepetitions: 10\n",
      "\t\tTime range: 23:42.8 - 24:15.0\n",
      "\tBlock #2:\n",
      "\t\tRepetitions: 15\n",
      "\t\tTime range: 24:41.2 - 25:24.2\n",
      "\tBlock #3:\n",
      "\t\tRepetitions: 5\n",
      "\t\tTime range: 25:47.8 - 26:02.4\n",
      "\n",
      "Exercise: P2\n",
      "Number of blocks: 3\n",
      "\n",
      "\tBlock #1:\n",
      "\t\tRepetitions: 10\n",
      "\t\tTime range: 04:26.2 - 04:53.0\n",
      "\tBlock #2:\n",
      "\t\tRepetitions: 5\n",
      "\t\tTime range: 05:23.4 - 05:37.8\n",
      "\tBlock #3:\n",
      "\t\tRepetitions: 16\n",
      "\t\tTime range: 06:24.6 - 07:08.6\n"
     ]
    }
   ],
   "source": [
    "# apply the functions for the peak evaluation\n",
    "exercise_only_abbrs = ['RF','RO','RS','LR','BC','TC','MP','SA','P1','P2']\n",
    "\n",
    "peak_ind = {}\n",
    "for ex in exercise_only_abbrs:\n",
    "    peak_ind[ex] = detect_prob_map_peaks(pred_matrix[ex])\n",
    "    \n",
    "rep_blocks = evaluate_peaks(peak_ind, pred_matrix)   \n",
    "\n",
    "print_rep_blocks(rep_blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 64,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "## Comparing predicted probabilities with actual classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 68,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "### First we have to load the actual time ranges of the exercises of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:09:38.276056Z",
     "start_time": "2018-12-17T22:09:38.216053Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 17,
        "hidden": false,
        "row": 72,
        "width": 5
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raises Oblique</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>01:18.6</td>\n",
       "      <td>01:58.3</td>\n",
       "      <td>02:22.1</td>\n",
       "      <td>02:37.1</td>\n",
       "      <td>02:54.8</td>\n",
       "      <td>03:23.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PNF Diagonal 2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>04:27.1</td>\n",
       "      <td>04:54.3</td>\n",
       "      <td>05:24.5</td>\n",
       "      <td>05:38.9</td>\n",
       "      <td>06:25.8</td>\n",
       "      <td>07:05.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Triceps Curls</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>07:32.3</td>\n",
       "      <td>08:14.8</td>\n",
       "      <td>08:49.5</td>\n",
       "      <td>09:04.9</td>\n",
       "      <td>09:46.1</td>\n",
       "      <td>10:12.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rotation Wrist</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>10:43.1</td>\n",
       "      <td>10:57.3</td>\n",
       "      <td>11:25.6</td>\n",
       "      <td>11:51.8</td>\n",
       "      <td>12:12.1</td>\n",
       "      <td>12:52.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Raises Front</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>13:44.8</td>\n",
       "      <td>14:14</td>\n",
       "      <td>14:40.6</td>\n",
       "      <td>15:20</td>\n",
       "      <td>16:09.5</td>\n",
       "      <td>16:23.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Biceps Curls</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>16:50.8</td>\n",
       "      <td>17:30.2</td>\n",
       "      <td>18:01.3</td>\n",
       "      <td>18:32.2</td>\n",
       "      <td>18:58.6</td>\n",
       "      <td>19:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Raises Side</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>20:13</td>\n",
       "      <td>21:00.2</td>\n",
       "      <td>21:24.9</td>\n",
       "      <td>21:40.2</td>\n",
       "      <td>22:09.6</td>\n",
       "      <td>22:38.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PNF Diagonal 1</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>23:43.9</td>\n",
       "      <td>24:15.9</td>\n",
       "      <td>24:42</td>\n",
       "      <td>25:25.1</td>\n",
       "      <td>25:48.7</td>\n",
       "      <td>26:04.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shoulder Adduct.</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>26:48.5</td>\n",
       "      <td>27:05.3</td>\n",
       "      <td>27:25.4</td>\n",
       "      <td>28:16.5</td>\n",
       "      <td>28:41.2</td>\n",
       "      <td>29:10.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Military Press</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>29:45.6</td>\n",
       "      <td>30:37.4</td>\n",
       "      <td>31:14.6</td>\n",
       "      <td>31:47.3</td>\n",
       "      <td>32:13.6</td>\n",
       "      <td>32:28.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0   1   2   3        4        5        6        7        8  \\\n",
       "0    Raises Oblique  15   5  10  01:18.6  01:58.3  02:22.1  02:37.1  02:54.8   \n",
       "1    PNF Diagonal 2  10   5  15  04:27.1  04:54.3  05:24.5  05:38.9  06:25.8   \n",
       "2     Triceps Curls  15   5  10  07:32.3  08:14.8  08:49.5  09:04.9  09:46.1   \n",
       "3    Rotation Wrist   5  10  15  10:43.1  10:57.3  11:25.6  11:51.8  12:12.1   \n",
       "4      Raises Front  10  15   5  13:44.8    14:14  14:40.6    15:20  16:09.5   \n",
       "5      Biceps Curls  15  10   5  16:50.8  17:30.2  18:01.3  18:32.2  18:58.6   \n",
       "6       Raises Side  15   5  10    20:13  21:00.2  21:24.9  21:40.2  22:09.6   \n",
       "7    PNF Diagonal 1  10  15   5  23:43.9  24:15.9    24:42  25:25.1  25:48.7   \n",
       "8  Shoulder Adduct.   5  15  10  26:48.5  27:05.3  27:25.4  28:16.5  28:41.2   \n",
       "9    Military Press  15  10   5  29:45.6  30:37.4  31:14.6  31:47.3  32:13.6   \n",
       "\n",
       "         9  \n",
       "0  03:23.3  \n",
       "1  07:05.1  \n",
       "2  10:12.6  \n",
       "3  12:52.4  \n",
       "4  16:23.1  \n",
       "5    19:12  \n",
       "6  22:38.4  \n",
       "7  26:04.6  \n",
       "8  29:10.9  \n",
       "9  32:28.1  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the actual time ranges of the exercises of the test data for the subsequent plot \n",
    "# to compare with predicted values\n",
    "\n",
    "# select file with timetable (csv) of the test subject\n",
    "timetable_file_dir = r'E:\\Physio_Data\\Exercise_time_tables'\n",
    "timetable_file_name = 'Timetable_subject{:02}.txt'.format(test_data_subject)\n",
    "timetable_data_path = os.path.join(timetable_file_dir, timetable_file_name)\n",
    "\n",
    "# read in time table\n",
    "timetable_data = pd.read_csv(timetable_data_path, skiprows=0, sep='\\t', header=None)\n",
    "num_exercises = timetable_data.shape[0] # number of exercises\n",
    "timetable_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 68,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "### Plotting of the predicted probabilities and actual classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T22:09:39.488126Z",
     "start_time": "2018-12-17T22:09:38.333060Z"
    },
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 5,
        "height": 4,
        "hidden": false,
        "row": 72,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib auto\n",
    "\n",
    "# text for current subject\n",
    "sub_text = 'Subject {}\\n'.format(test_data_subject)\n",
    "\n",
    "yticks = np.arange(0, win_max_len-win_min_len+win_stretch_inc, 2) / win_stretch_inc\n",
    "ylabels = ['{}'.format(yticks[ii] * win_stretch_inc + win_min_len) for ii in range(len(yticks))]\n",
    "\n",
    "fig, axis = plt.subplots(12,1,figsize=(18,9), sharex=True)\n",
    "\n",
    "# image color settings for RFC probabilities\n",
    "cmap = plt.cm.seismic\n",
    "vmin=0\n",
    "vmax=1\n",
    "\n",
    "for ax, ex in zip(axis, exercise_abbrs):\n",
    "    s = ax.imshow(pred_matrix[ex].transpose(), interpolation='nearest', \n",
    "                  aspect='auto', cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_yticks(yticks)\n",
    "    ax.set_yticklabels(ylabels, fontsize=7)\n",
    "    ax.set_ylabel(ex, rotation=0, fontsize=13)\n",
    "    ax.yaxis.labelpad = 32\n",
    "    ax.xaxis.set_ticklabels([])\n",
    "    \n",
    "# plot crosses for image peaks\n",
    "for ax, ex in zip(axis, exercise_only_abbrs):\n",
    "    #ax.plot(peak_ind[ex][0], peak_ind[ex][1], '+g', markersize=8, markeredgewidth=1.5)\n",
    "    for ii in range(len(rep_blocks[ex])):\n",
    "        x_peak = np.array(rep_blocks[ex][ii])[:,0]\n",
    "        y_peak = np.array(rep_blocks[ex][ii])[:,1]\n",
    "        ax.plot(x_peak, y_peak, '+g', markersize=8, markeredgewidth=1.5)\n",
    "    \n",
    "plt.gcf().text(0.1, 0.6, r'window length $[s]$', fontsize=10, rotation=90)\n",
    "\n",
    "axis[-1].plot(range(num_start_points), np.zeros(num_start_points), 'k', alpha=0.0)\n",
    "formatter = matplotlib.ticker.FuncFormatter(lambda i, x: time.strftime('%M:%S', time.gmtime(i*win_start_inc+win_start)))\n",
    "axis[-1].xaxis.set_major_formatter(formatter)\n",
    "axis[-1].set_xlabel(r'time $[min:sec]$', fontsize=13)\n",
    "axis[-1].set_yticks([])\n",
    "axis[-1].set_ylim([0,1])\n",
    "\n",
    "fig.subplots_adjust(bottom=0.2, right=0.9) # make space for buttons and color bar\n",
    "cbar_ax = fig.add_axes([0.93, 0.255, 0.01, 0.625])\n",
    "fig.colorbar(s, cax=cbar_ax)\n",
    "\n",
    "# add slider for selections on the x axis\n",
    "Slider_shiftX_ax = plt.axes([0.125, 0.07, 0.775, 0.025])\n",
    "Slider_zoomX_ax = plt.axes([0.125, 0.035, 0.775, 0.025])\n",
    "\n",
    "axcolor = 'cornflowerblue'\n",
    "Slider_shiftX = Slider(Slider_shiftX_ax, 'time shift [%]', 0.0, 100.0, valinit=0, facecolor=axcolor)\n",
    "Slider_zoomX = Slider(Slider_zoomX_ax, 'time scale [%]', 0.1, 100.0, valinit=100, facecolor=axcolor)\n",
    "Slider_zoomX_ax.xaxis.set_visible(True)\n",
    "Slider_zoomX_ax.set_xticks(np.arange(0,105,5)) \n",
    "\n",
    "def updateX(val):\n",
    "    start_index = int(Slider_shiftX.val / 100 * num_start_points)\n",
    "    stop_index = start_index + Slider_zoomX.val / 100 * num_start_points\n",
    "    axis[-1].set_xlim((start_index, stop_index))\n",
    "    fig.suptitle('Predicted Probabilities ' + sub_text + indices_to_time(start_index, stop_index), fontsize=20)\n",
    "    plt.draw()\n",
    "\n",
    "Slider_shiftX.on_changed(updateX)\n",
    "Slider_zoomX.on_changed(updateX)\n",
    "\n",
    "# add button to reset view\n",
    "def resetX(val):\n",
    "    start_index = 0\n",
    "    stop_index = num_start_points\n",
    "    axis[-1].set_xlim((start_index, stop_index))\n",
    "    Slider_shiftX.reset()\n",
    "    Slider_zoomX.reset()\n",
    "    fig.suptitle('Predicted Probabilities ' + sub_text + indices_to_time(start_index, stop_index), fontsize=20)\n",
    "    plt.draw()\n",
    "\n",
    "Button_resetX_ax = plt.axes([0.85, 0.12, 0.05, 0.03])\n",
    "Button_resetX = Button(Button_resetX_ax, 'Reset view')\n",
    "Button_resetX.on_clicked(resetX)\n",
    "\n",
    "start_index = 0\n",
    "stop_index = num_start_points\n",
    "\n",
    "fig.suptitle('Predicted Probabilities ' + sub_text + indices_to_time(start_index, stop_index), fontsize=20)\n",
    "\n",
    "axis[-1].set_xlim(0, num_start_points)\n",
    "\n",
    "\n",
    "# Plotting the actual classes (exercises) on the last axis:\n",
    "\n",
    "# dictionary to get exercise abbreviations from exercise names in timetable\n",
    "exercise_names = {'Raises Front':'RF',\n",
    "                  'Raises Oblique':'RO',\n",
    "                  'Raises Side':'RS',\n",
    "                  'Rotation Wrist':'LR',\n",
    "                  'Biceps Curls':'BC',\n",
    "                  'Triceps Curls':'TC',\n",
    "                  'Military Press':'MP',\n",
    "                  'Shoulder Adduct.':'SA',\n",
    "                  'PNF Diagonal 1':'P1',\n",
    "                  'PNF Diagonal 2':'P2'}\n",
    "\n",
    "# going through all exercises in the timetable\n",
    "for ii, ex_name in enumerate(timetable_data.values[:,0]):\n",
    "    \n",
    "    # going through all repetition blocks in the timetable (5, 10 and 15 rep. blocks)\n",
    "    for rep_col, start_col, stop_col in zip([1,2,3],[4,6,8],[5,7,9]): # corresponding columns\n",
    "        rep_num = timetable_data.values[ii,rep_col]\n",
    "        left_border = fmpm.convert_time_format_to_index(timetable_data.values[ii,start_col], \n",
    "                                                        sampling_rate=1/win_start_inc)\n",
    "        right_border = fmpm.convert_time_format_to_index(timetable_data.values[ii,stop_col], \n",
    "                                                         sampling_rate=1/win_start_inc)\n",
    "        # mark the corresponding area\n",
    "        axis[-1].axvspan(left_border, right_border, color='y', alpha=0.3, lw=0)\n",
    "        # write text to the corresponding area\n",
    "        x_center = left_border + (right_border-left_border)/2 # x center of marked area\n",
    "        axis[-1].text(x_center, 0.5, str(rep_num) + '\\n' + exercise_names[ex_name], \n",
    "                      horizontalalignment='center', verticalalignment='center', fontsize=10, clip_on=True)\n",
    "        \n",
    "axis[-1].set_ylabel('Actual classes', rotation=0, fontsize=11)\n",
    "axis[-1].yaxis.labelpad = 50\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "grid_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
